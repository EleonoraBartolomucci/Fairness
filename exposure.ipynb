{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exposure.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EleonoraBartolomucci/Fairness/blob/master/exposure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPpCkgv0271l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from lxml import html\n",
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import datetime\n",
        "import math\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkoXGrGIEQB3",
        "colab_type": "code",
        "outputId": "52c07dbf-9541-45a7-9f3d-2deb9748e833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COSfvffRFRRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "root_path = 'gdrive/My Drive/Tesi/Fairness/data/fairness_data/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol7PR_gGjwNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CONSTANTS\n",
        "business_headers = ['index', 'business_id', 'name', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars', 'review_count', 'is_open', 'attributes', 'categories', 'hours']\n",
        "FOLDER = {'WbJ1LRQdOuYYlRLyTkuuxw':\n",
        "            {'FID_RANKING': '1U0Ml5puObfOk3qHCKhO9bQ06WyhJoffW',\n",
        "             'FID_G1': '1cauvqKXzF5VhiveP84aL3U0oDrXP32XV',\n",
        "             'FID_G2': '1vC1fc2owpCis_PTl1ABKT6BfG6-2yoiJ',\n",
        "             'FID_G3': '1_iKbmJkBwWEEIIh73UvR431Ss6xnGb2f',\n",
        "             'FID_G4': '1m_feamMvpx5B5mTe_lH6qlhoZFEpwlSs',\n",
        "             'FID_G5': '1qJgFbR4FUX5t7O9h5cHgp6aE6lpfbdOs',\n",
        "             'FID_G6': '1BSQrghVusO_eNbe10fFE4-bVfRK8ly0y',\n",
        "             'FID_G7': '1fJD4WIErH-u5plesyTePCAQ3IyfjoOKf',\n",
        "             },\n",
        "          'T2tEMLpTeSMxLKpxwFdS3g':\n",
        "            {'FID_RANKING': '136FZ0Y90Zx-4UYDyW50cX8zUa_DhN3XS',\n",
        "             'FID_G1': '1eiju1aTzsRi4QQZ8XrSouqcLtFSN-tbj',\n",
        "             'FID_G2': '1VuU8MAcXgN_E85q9SH_P1HsHVkeJakwH',\n",
        "             'FID_G3': '1L240ycUElvmF0R4l8PbnuoBbqQY6q1og',\n",
        "             'FID_G4': '1S4oTf-ZSD8q9aTOjrDEA2KeNJ99uh-2n',\n",
        "             'FID_G5': '1u9ZFeCwmol1uXRH-l8djJ2hst0B01VI3',\n",
        "             'FID_G6': '19TgwV3uHOtDDJ0a8krpvLUeooe9rhQFJ',\n",
        "             'FID_G7': '11YpFHw34cDglPD87W8yWvRM1VAOWXPtF',\n",
        "             },\n",
        "          'ALwAlxItASeEs2vYAeLXHA':\n",
        "            {'FID_RANKING': '12zXi3XyQaNgukGHW_805cyrkHhSdF7Df',\n",
        "             'FID_G1': '1NB-isOm1cDArAlwIMDMou1Q_XAap09KA',\n",
        "             'FID_G2': '1ELMUBbKGryblHDnbh7ghiIgMdZ48pBG1',\n",
        "             'FID_G3': '1QZ90pwDjBoaU41P8wP8v_I9tsuhObEUP',\n",
        "             'FID_G4': '1MXivbV9VGB0vBGGuLhYu0zJlpv6O-2Xb',\n",
        "             'FID_G5': '1bTetFx3Jhy5QbRKYGV09muMy7D1NKmJT',\n",
        "             'FID_G6': '1F_7bdMS5MW4sIpyUbDz62ZTYJtHoouGG',\n",
        "             'FID_G7': '1uRFceNIlYk5vQXEGd2H6yanrlwrSIM9V',\n",
        "             },\n",
        "          'OVTZNSkSfbl3gVB9XQIJfw':\n",
        "            {'FID_RANKING': '1ZyNQavpG0akr3ca3PJjjl_D89IA5wlcc',\n",
        "             'FID_G1': '1kQkAi_9V3mSld1LlP50j6uw0bwqnkLrR',\n",
        "             'FID_G2': '1hGR4eZiP3Q9Etn7RdlY58IsNsTMMTydz',\n",
        "             'FID_G3': '1YcAPHxioFpiVXWndO5tK17US1h36cWgK',\n",
        "             'FID_G4': '1NxzzH0l18fGaO4bZ35D9NMq2CeW5BRVP',\n",
        "             'FID_G5': '1HC1wZGPtbb8UvRlfbGoHl_ijl3G67Ei4',\n",
        "             'FID_G6': '1J_15pO-CFbHR_0YsHK5kDnKp49kDL0kZ',\n",
        "             'FID_G7': '1RTwCqhYzB3djzpe3-uwbQ3Ur5P8YoECa',\n",
        "             },\n",
        "          'Sovgwq-E-n6wLqNh3X_rXg':\n",
        "            {'FID_RANKING': '1EZqvt9x5PN07BgUad1RtNIUXTVqujA0g',\n",
        "             'FID_G1': '1pkUEBYeZ66GfIvXoTkzZ28gGFlZNWmEq',\n",
        "             'FID_G2': '1lJzHAfBlvL9_EgNizH4vnyPTn-j-Vbrx',\n",
        "             'FID_G3': '1NRYqjUsQJTwgB0JXtcCx7lQErirMH1TK',\n",
        "             'FID_G4': '1nLtZbS0NGXKAs6aETNs7EWasNs8omaw6',\n",
        "             'FID_G5': '14w-jVhOuod3s_EYSipvS92SPx_3zT_FD',\n",
        "             'FID_G6': '1tbUyiamFmyAoeA3W6j51x97h3MjUSVsd',\n",
        "             'FID_G7': '1TNAmibHwJHkvNajHhRffN1gEY0-QnBZH',\n",
        "             },\n",
        "          'j5nPiTwWEFr-VsePew7Sjg':\n",
        "            {'FID_RANKING': '18bQVXYZ03vIpfEFLPh8I2i7cPTlokGxv',\n",
        "             'FID_G1': '1U8STZ7irZLPcUpP1ALR6QYIFnoXB2tbE',\n",
        "             'FID_G2': '1xScKc0_DlnQZucHLeb26hLqpgjqMA3RH',\n",
        "             'FID_G3': '1JFYl2eKtDyWbsyVdBpTXsvPn2h6MO3Cr',\n",
        "             'FID_G4': '1aFYpJmymdnHxquuqbbMwXzN5wG-3Zf2O',\n",
        "             'FID_G5': '1NfHlsBTk87jscmZfagtnd--kcdpy8t_8',\n",
        "             'FID_G6': '1b88afNqrZSRptYA0pL3lCEV49mFaEP6Q',\n",
        "             'FID_G7': '15rDbY-MTUBVjHxOedbenZIjTxQ_wEAZW',\n",
        "             },\n",
        "          'aiX_WP7NKPTdF9CfI-M-wg':\n",
        "            {'FID_RANKING': '1nl6A997UnuR5ceYRZS1242JJCvK',\n",
        "             'FID_G1': '1hrssLlhPmnS48yVxXpwBBIuhL1YdDNhj',\n",
        "             'FID_G2': '1shLPc3aUsVaxeZhZ_SvDS3agPFlMw1dn',\n",
        "             'FID_G3': '13eUtYFVp-KKjxV6-mhCsxQGHkKFOgB82',\n",
        "             'FID_G4': '1nQVPHZT4sHpBXD32qX_x41VywkmyppFj',\n",
        "             'FID_G5': '1gJpfGhb721Q64gynq4jSGMis5pDA7qAx',\n",
        "             'FID_G6': '1WbZvolaSwambWOKHx4v4eFIV-KUzygGF',\n",
        "             'FID_G7': '1IWyQpgMjLny2JTbw0nUuHkNRPV5CCA_A',\n",
        "             },\n",
        "          'e4NQLZynhSmvwl38hC4m-A':\n",
        "            {'FID_RANKING': '1K566Y5Q2N6Lw7S6yDicKC_R-zFVRqnFr',\n",
        "             'FID_G1': '1RNxub2faGfc4NAFvau5SsMADAzBlQd2j',\n",
        "             'FID_G2': '16tjv4k5CJSOxwgvC0wDJU67MEjRaw_0o',\n",
        "             'FID_G3': '1p-9HrVncD_FZOxO0YzHiY7KTe47ugSTQ',\n",
        "             'FID_G4': '1qGpECepAyJjqyfPx8Q94odPOCHbOixtZ',\n",
        "             'FID_G5': '15AGLE1YT0v8tQ3r6i6k7j5XaNORToUct',\n",
        "             'FID_G6': '1nNbAPulqJCzO6urHNsqc4qzSM7Yih8uk',\n",
        "             'FID_G7': '1o9Ew39-Q9VO3wjEyv4qGJ9YlfRmkzTed',\n",
        "             },\n",
        "          'S-oLPRdhlyL5HAknBKTUcQ':\n",
        "            {'FID_RANKING': '1FJqfJgaJinXS3oIvdA53FMuO9O7bCDVn',\n",
        "             'FID_G1': '1CcLHVEA41AgSzJKl37YlcJKf-o5NaCUo',\n",
        "             'FID_G2': '1j-lp1gcu6YGTwcOV4aYiY7dh2G9_TL6J',\n",
        "             'FID_G3': '1I-Qn9oz4VopXbpj5i8_iqLvcSp8jpb2_',\n",
        "             'FID_G4': '1gsS9uFbRyI18ifF5yLp20WHhP66gdr57',\n",
        "             'FID_G5': '1LJIVm9tCZMcgzBkGilYem0nqKoUHpdpX',\n",
        "             'FID_G6': '1syB0wF48fiSo0_uW9dedS-ZlFfXUv1B8',\n",
        "             'FID_G7': '1cBPjBprJ19RxI6-Bcpb-Fifv0s1bQSV2',\n",
        "             }\n",
        "        }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JgvcYwsfpy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# READ JSON\n",
        "def read_json(json_path):\n",
        "  data = []\n",
        "  with open(json_path, \"r\") as my_file: \n",
        "    for line in my_file:\n",
        "      line_json = json.loads(line)\n",
        "      data.append(line_json)\n",
        "  return data\n",
        "\n",
        "\n",
        "# PARSE JSON IN CSV\n",
        "def json2csv(csv_path, json_path):\n",
        "  data = read_json(json_path)\n",
        "  df = pd.DataFrame(data)\n",
        "  df.to_csv(csv_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyIm6NR55FGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AUTHENTICATE IN GOOGLE DRIVE\n",
        "def authenticate():\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  return drive\n",
        "drive = authenticate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bw0Twhc3qgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upload_file(filename, folder_id):\n",
        "  drive = authenticate()\n",
        "  fileList = drive.ListFile({'q': \"'\" + folder_id + \"' in parents and trashed=false\"}).GetList()\n",
        "  drive_file = drive.CreateFile({'title': filename, 'parents': [{'id': folder_id}]})\n",
        "  # Check if file already exists in Google Drive (prevents duplicates)\n",
        "  for file in fileList:\n",
        "      if file['title'] == filename:  # The file already exists, then overwrite it\n",
        "          fileID = file['id']\n",
        "          drive_file = drive.CreateFile({'id': fileID, 'title': filename, 'parents': [{'id': folder_id}]})\n",
        "\n",
        "  # Create a local copy of user picture\n",
        "  # Already created!\n",
        "\n",
        "  # Upload user picture on Google Drive\n",
        "  drive_file.SetContentFile(filename)  # path of local file content\n",
        "  drive_file.Upload()  # Upload the file.\n",
        "  \n",
        "  # Delete local user pictures\n",
        "  #if os.path.exists(filename):\n",
        "  #    os.remove(filename)\n",
        "  #else:\n",
        "  #    print(\"The file does not exist\")\n",
        "\n",
        "def set_file_destination(lst, id):\n",
        "  if lst == ['review_count']:\n",
        "    return FOLDER[id]['FID_G1']\n",
        "  if lst == ['review_count', 'fans', 'average_stars', 'useful', 'funny', 'cool']:\n",
        "    return FOLDER[id]['FID_G2']\n",
        "  if lst == ['loc1', 'loc2', 'loc3']:\n",
        "    return FOLDER[id]['FID_G3']\n",
        "  if lst == ['age', 'gender', 'ethnicity']:\n",
        "    return FOLDER[id]['FID_G4']\n",
        "  if lst == ['fans']:\n",
        "    return FOLDER[id]['FID_G6']\n",
        "  if lst == ['useful','funny', 'cool']:\n",
        "    return FOLDER[id]['FID_G7']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBrfK_M25rAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOWNLOAD user.json FROM DRIVE\n",
        "users_dataset_id = '1JokoV68YD5Iq2l4Y_IV2RJzBpD_mSCyq'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': users_dataset_id})\n",
        "download.GetContentFile('user.json')\n",
        "users = read_json('user.json')\n",
        "users = pd.DataFrame(users)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMGOW-SHRrP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOWNLOAD business.json FROM DRIVE\n",
        "business_dataset_id = '1Qoy132gb205xAIFjkBbZ2CyYDeaz9yqU'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': business_dataset_id})\n",
        "download.GetContentFile('business.json')\n",
        "business = read_json('business.json')\n",
        "business = pd.DataFrame(business)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3tkQRFfw16x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOWNLOAD review.json FROM DRIVE\n",
        "review_dataset_id = '1mW1WbpMFjN0qQpLnM-R_TzNpAkFsBLHQ'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': review_dataset_id})\n",
        "download.GetContentFile('review.json')\n",
        "reviews = read_json('review.json')\n",
        "reviews = pd.DataFrame(reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYF2ESayjKVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOWNLOAD DEMOGRAPHICS\n",
        "id_list = ['WbJ1LRQdOuYYlRLyTkuuxw','T2tEMLpTeSMxLKpxwFdS3g','ALwAlxItASeEs2vYAeLXHA',\n",
        "          'OVTZNSkSfbl3gVB9XQIJfw','Sovgwq-E-n6wLqNh3X_rXg','j5nPiTwWEFr-VsePew7Sjg',\n",
        "          'aiX_WP7NKPTdF9CfI-M-wg', 'e4NQLZynhSmvwl38hC4m-A']\n",
        "#id_list = ['WbJ1LRQdOuYYlRLyTkuuxw']\n",
        "file_id_list = {'WbJ1LRQdOuYYlRLyTkuuxw':['13amOFvuku27snF8mea8Yp7rH36Mve42N',\n",
        "                                          '1VskD_0Ijwe3_fzVbgYqK9Bk-YOCK046t',\n",
        "                                          '1uuA0QH-DJklvtiekxS-7yaXfKRi9ux06'],\n",
        "                'T2tEMLpTeSMxLKpxwFdS3g':['11fM_aHYkCLQ2z3g7Z76aZZ3cAsIrpezN',\n",
        "                                          '1TPexYC2YHq_8ywZSuRRIJkrUCstwoxSp',\n",
        "                                          '1ObvjBbxRNIp1vOQipUGZxZEi_eQH7kJQ'],\n",
        "                'ALwAlxItASeEs2vYAeLXHA':['1crTNpDR2VjBdGSgavIvN4QNhwTUR3-Bk',\n",
        "                                          '1sJOKR7-__9dKJG0ewVQyfmV6i_dLpcRk',\n",
        "                                          '1tgJnMW0ZImx1vbDzWpvFBRX0FJu1Kdbt'],\n",
        "                'OVTZNSkSfbl3gVB9XQIJfw':['1Vmkzpdi_0m9CGcyp5ggeNsUsueBzqufH',\n",
        "                                          '12aiPnkvuUtyc8B2UmJEu2BpeXVYbPumF',\n",
        "                                          '1qecYhCBytq1Z6lm_ueCWIuithvRG0wIq'],\n",
        "                'Sovgwq-E-n6wLqNh3X_rXg':['1VVePrvWR7e5XkRmhp5Q5qOPXPskVmnnt',\n",
        "                                          '1fSqJYcczjUsbryfI7ekeqANaz-xD4PFT',\n",
        "                                          '1R5GFYo2c2YC_AOB9G0pdOfROTyglePDI'],\n",
        "                'j5nPiTwWEFr-VsePew7Sjg':['1txkAzGKMRjXku18rv9222q-FqVo42A9o',\n",
        "                                          '1e8iSM3SpyB2Y_h6rzRSVVgphjHEIJnZU',\n",
        "                                          '16H267f71Y_1l8O5-n5JlF5v8GNpnt_kc'],\n",
        "                'aiX_WP7NKPTdF9CfI-M-wg':['1VrVgBoJp5cRVMH4I-5uKvdF3b-PSfbmL',\n",
        "                                          '1f7T7ksdCCGxhVF_RJU9zu38-r8aTTJcD',\n",
        "                                          '1ApgXp06OyhQSgFg4pyxaH_vF6djUFmNc'],\n",
        "                'e4NQLZynhSmvwl38hC4m-A':['1yYG8ftjE1i9prP61ej5EdGfJDlweiK3C',\n",
        "                                          '1KSdN24eXC-Bnk2_mTQR6oNaGll1KP5hO',\n",
        "                                          '1PA2eYsYj2bj4Mo7ofbnvbQgYjmd2SwRG'],\n",
        "                'S-oLPRdhlyL5HAknBKTUcQ':['1qcX9pGfmogOokbBOPnZY-NbroolffAlg',\n",
        "                                          '1YVdSND3VNit4ieORXC_mVzcv4mphGUnY',\n",
        "                                          '1XrZViuuarqibJmaURcb0SHU5nd_3zGpo']}\n",
        "for business_id in id_list:\n",
        "  df = pd.DataFrame()\n",
        "  for file_id in file_id_list[business_id]:\n",
        "    download = drive.CreateFile({'id': file_id})\n",
        "    download.GetContentFile('demographics_' + business_id + '.csv')\n",
        "    df_temp = pd.read_csv('demographics_' + business_id + '.csv')\n",
        "    df = df.append(df_temp)\n",
        "  df = df.drop_duplicates('id',keep='first').reset_index(drop=True)\n",
        "  df = df.rename(columns={'id':'user_id'})\n",
        "  df.to_csv('demographics_' + business_id + '.csv')\n",
        "  upload_file('demographics_' + business_id + '.csv',FOLDER[business_id]['FID_G4'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40JdFbw0Qqmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FILTER RESTAURANTS\n",
        "is_restaurant = business['categories'].str.contains('Restaurants', regex=False, na=False)\n",
        "restaurants = business[is_restaurant]\n",
        "\n",
        "# Filter closed restaurants\n",
        "restaurants = restaurants[restaurants['is_open'] == 1]\n",
        "\n",
        "# Order restaurants by review_count\n",
        "restaurants = restaurants.sort_values('review_count')\n",
        "\n",
        "restaurants.to_csv('restaurants_input.csv')\n",
        "# NOW CHOOSE THE RESTAURANTS AND SAVE THEIR IDS INTO TXT FILE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKYSaLtPHqsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXEC IN LOCAL THE DOWNLOAD OF REVIEW RANKINGS OF EACH RESTAURANT\n",
        "# UPLOAD CSV IN COLAB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFbM06dpOYYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################# EXECUTE IN LOCAL (if not blocked by yelp) #############################################\n",
        "def get_ranking_from_call(url_business, lang, sort, query):\n",
        "    headers = [{\"name\": \"Accept\", \"value\": \"*/*\"}, {\"name\": \"Accept-Encoding\", \"value\": \"gzip, deflate, br\"},\n",
        "               {\"name\": \"Accept-Language\", \"value\": \"it-IT,it;q=0.8,en-US;q=0.5,en;q=0.3\"},\n",
        "               {\"name\": \"Connection\", \"value\": \"keep-alive\"},\n",
        "               {\"name\": \"Content-Type\", \"value\": \"application/x-www-form-urlencoded; charset=utf-8\"}, {\"name\": \"Cookie\",\n",
        "                                                                                                       \"value\": \"qntcst=D; hl=en_US; wdi=1|3C26116D69138F61|0x1.78d019f71a444p+30|a7756ff94751d3a9; _ga=GA1.2.3C26116D69138F61; location=%7B%22city%22%3A+%22New+York%22%2C+%22state%22%3A+%22NY%22%2C+%22country%22%3A+%22US%22%2C+%22latitude%22%3A+40.713%2C+%22longitude%22%3A+-74.0072%2C+%22max_latitude%22%3A+40.8523%2C+%22min_latitude%22%3A+40.5597%2C+%22max_longitude%22%3A+-73.7938%2C+%22min_longitude%22%3A+-74.1948%2C+%22zip%22%3A+%22%22%2C+%22address1%22%3A+%22%22%2C+%22address2%22%3A+%22%22%2C+%22address3%22%3A+null%2C+%22neighborhood%22%3A+null%2C+%22borough%22%3A+null%2C+%22provenance%22%3A+%22YELP_GEOCODING_ENGINE%22%2C+%22display%22%3A+%22New+York%2C+NY%22%2C+%22unformatted%22%3A+%22New+York%2C+NY%2C+US%22%2C+%22accuracy%22%3A+4.0%2C+%22language%22%3A+null%7D; xcj=1|Ptt9P03gfc75x_PBT9zmqCkUuSuyB7PR-wWUBvABNi4; __qca=P0-60561249-1581956668708; G_ENABLED_IDPS=google; __cfduid=db8764ff59d8028a6c2e1b214867927d81583160194; _gid=GA1.2.2014867238.1583835527; bse=05dcd9d5de304ef0b1d9a76fa768b10f; sc=8a1ca0dbc2; pid=505721aa4569e7bb\"},\n",
        "               {\"name\": \"Host\", \"value\": \"www.yelp.com\"},\n",
        "               {\"name\": \"Referer\", \"value\": \"https://www.yelp.com/biz/noche-de-margaritas-new-york\"},\n",
        "               {\"name\": \"TE\", \"value\": \"Trailers\"}, {\"name\": \"User-Agent\",\n",
        "                                                     \"value\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:73.0) Gecko/20100101 Firefox/73.0\"},\n",
        "               {\"name\": \"X-Requested-By-React\", \"value\": \"true\"},\n",
        "               {\"name\": \"X-Requested-With\", \"value\": \"XMLHttpRequest\"}]\n",
        "    headers_ok = {}\n",
        "    for header in headers:\n",
        "        temp = {\n",
        "            header['name']: header['value']\n",
        "        }\n",
        "        headers_ok.update(temp)\n",
        "\n",
        "    x = 0\n",
        "    reviews_list = []\n",
        "    position = 1\n",
        "    url = url_business + \"/review_feed?rl=\" + lang + \"&sort_by=\" + sort + \"&q=\" + query\n",
        "\n",
        "    while 1:\n",
        "        if x == 0:\n",
        "            page_load = requests.get(url + '&start=', headers=headers_ok)\n",
        "        else:\n",
        "            page_load = requests.get(url + '&start=' + str(x), headers=headers_ok)\n",
        "        print(page_load)\n",
        "        x = x + 20\n",
        "        reviews = page_load.json()['reviews']\n",
        "        # print(json.dumps(reviews, indent=4, sort_keys=True))\n",
        "        if not reviews:\n",
        "            break\n",
        "        for review in reviews:\n",
        "            reviews_list.append((position, review['userId'], review['user'],#['reviewCount'],\n",
        "                                 datetime.datetime.strptime(review['localizedDate'], '%m/%d/%Y')))\n",
        "            position = position + 1\n",
        "    df_reviews = pd.DataFrame(reviews_list, columns=[\"position\", \"user_id\", \"user\", \"date\"])\n",
        "    return df_reviews\n",
        "\n",
        "\n",
        "def retrieve_rankings(business_id):\n",
        "    df_rel_ranking = get_ranking_from_call(\"https://www.yelp.com/biz/\" + business_id, \"en\", \"relevance_desc\", \"\")\n",
        "    df_date_ranking = df_rel_ranking.sort_values(by=['date']).reset_index(drop=True)\n",
        "    df_date_ranking['position'] = df_date_ranking.index + 1\n",
        "    df_rand_ranking = df_rel_ranking.sample(frac=1).reset_index(drop=True)\n",
        "    df_rand_ranking['position'] = df_rand_ranking.index + 1\n",
        "\n",
        "    df_rel_ranking.to_csv(\"rel_ranking_\" + business_id + \".csv\")\n",
        "    df_date_ranking.to_csv(\"date_ranking_\" + business_id + \".csv\")\n",
        "    df_rand_ranking.to_csv(\"rand_ranking_\" + business_id + \".csv\")\n",
        "\n",
        "\n",
        "rest_ids = []\n",
        "\n",
        "with open('rest_ids.txt', 'r') as f:\n",
        "  for line in f:\n",
        "    rest_ids.append(line[:-1])\n",
        "\n",
        "print(rest_ids)\n",
        "for id in rest_ids:\n",
        "    retrieve_rankings(id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "070u7qOzHsiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# JOIN USER FROM YELP WITH USER FROM DATASET AND PRINT LOST USERS\n",
        "def filter_user_from_dataset(df, users):\n",
        "  df = df.rename(columns={'Position':'position','User_Id': 'user_id',\n",
        "                          'Date':'date'})\n",
        "  df = df[['position','user_id','date']]\n",
        "  df_merged = df.merge(users, on='user_id')\n",
        "  total_review = df['position'].max()\n",
        "  print('Utenti persi: totali ' + str(total_review) + ' - utenti nel dataset ' +\n",
        "        str(len(df_merged.index)) + ' = ' + str(total_review - len(df_merged.index)))\n",
        "  df_merged['position'] = df_merged.index + 1\n",
        "\n",
        "  cols = df_merged.columns.tolist()\n",
        "\n",
        "  df_merged = df_merged[['position', 'user_id', 'date', 'fans', 'average_stars', 'review_count']]\n",
        "\n",
        "  return df_merged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RAaBHLaVMDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ADD REVIEW INFO IN RANKING DATAFRAME\n",
        "def integrate_review_info(df, reviews, business_id):\n",
        "  business_reviews = reviews[reviews['business_id'] == business_id]\n",
        "  df_merged = business_reviews.merge(df, on='user_id')\n",
        "  del df_merged['date_y']  # it's date from yelp website (not updated in dataset)\n",
        "  df_merged = df_merged.rename(columns={'date_x':'date'})\n",
        "  # drop duplicates reviews from same user\n",
        "  df_merged = df_merged.sort_values('date').drop_duplicates('user_id',keep='last')\n",
        "  df_merged = df_merged.sort_values(by=['position']).reset_index(drop=True)\n",
        "  print('Review perse: ', len(df.index) - len(df_merged.index))\n",
        "  df_merged['position'] = df_merged.index + 1\n",
        "\n",
        "  df_merged = df_merged[['position', 'user_id', 'review_id', 'date', 'text', 'fans', 'average_stars', 'review_count', 'business_id']]\n",
        "  \n",
        "  return df_merged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezxCXIZBkcAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ADD USER DATA TO GROUP USERS\n",
        "def create_vectors(df_users, reviews, business, business_id, list_of_attributes):\n",
        "  vectors = df_users[['user_id', 'review_count', 'fans' , 'average_stars']]\n",
        "  vectors[\"useful\"] = np.NaN\n",
        "  vectors[\"funny\"] = np.NaN\n",
        "  vectors[\"cool\"] = np.NaN\n",
        "  vectors[\"loc1\"] = np.NaN\n",
        "  vectors[\"loc2\"] = np.NaN\n",
        "  vectors[\"loc3\"] = np.NaN\n",
        "  for index, user in vectors.iterrows():\n",
        "    print(index)\n",
        "    # TOP THREE LOCATION\n",
        "    location_list = get_top_three_loc(user, reviews, business)\n",
        "    i = 0\n",
        "    while i < len(location_list):\n",
        "      vectors.loc[index, 'loc'+str(i+1)] = location_list[i]\n",
        "      i = i + 1\n",
        "\n",
        "    # USEFUL FUNNY COOL\n",
        "    useful, funny, cool = get_details_user(user, reviews)\n",
        "    vectors.loc[index, 'useful'] = useful\n",
        "    vectors.loc[index, 'funny'] = funny\n",
        "    vectors.loc[index, 'cool'] = cool\n",
        "\n",
        "  # DEMOGRAPHICS\n",
        "  vectors = get_demographics(vectors, business_id)\n",
        "    \n",
        "  # UPLOAD VECTORS IN DRIVE\n",
        "  destination = set_file_destination(list_of_attributes, business_id)\n",
        "  vectors.to_csv('user_vectors_' + business_id + '.csv')\n",
        "  upload_file('user_vectors_' + business_id + '.csv',destination)\n",
        "  return vectors\n",
        "\n",
        "\n",
        "def get_demographics(vectors, id):\n",
        "  df_demographics = pd.read_csv('demographics_' + id + '.csv')\n",
        "  new_vectors = pd.merge(vectors, df_demographics, on='user_id', how='left')\n",
        "  return new_vectors\n",
        "\n",
        "\n",
        "def get_details_user(user, reviews):\n",
        "  user_id = user['user_id']\n",
        "  user_reviews = reviews[reviews['user_id'] == user_id]\n",
        "  return user_reviews['useful'].sum(), user_reviews['funny'].sum(), user_reviews['cool'].sum()\n",
        "\n",
        "\n",
        "def get_top_three_loc(user, reviews, business):\n",
        "  user_id = user['user_id']\n",
        "  user_reviews = reviews[reviews['user_id'] == user_id]\n",
        "  result = user_reviews.merge(business, on='business_id')\n",
        "  top_loc = result['state'].value_counts().index.tolist()[:3]\n",
        "  top_zip = []\n",
        "  for location in top_loc:\n",
        "    # exclude postal_code of Canada, that is strings\n",
        "    temp_list = result[result['state']==location]['postal_code'].value_counts().index.tolist()\n",
        "    if temp_list != []:\n",
        "      temp_list = [elem for elem in temp_list if str(elem).isdigit()]\n",
        "      if temp_list != []:\n",
        "        top_zip.append(int(str(temp_list[0])[:3]))\n",
        "  return top_zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY33HeAn7Xq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_groups_percents(df_groups, N_of_groups):\n",
        "  total = len(df_groups.index)\n",
        "  percents = []\n",
        "  i = 0\n",
        "  while i < N_of_groups:\n",
        "    current_length = len(df_groups[df_groups['group_id'] == i].index)\n",
        "    percents.append((current_length/total)*100)\n",
        "    i = i + 1\n",
        "  print(percents)\n",
        "  return percents\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW2AKZ8lHgoB",
        "colab_type": "code",
        "outputId": "54305e91-5b19-4118-a72c-6be58939c434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# PIPELINE\n",
        "N_of_groups = 5\n",
        "id_list = ['WbJ1LRQdOuYYlRLyTkuuxw','T2tEMLpTeSMxLKpxwFdS3g','ALwAlxItASeEs2vYAeLXHA',\n",
        "          'OVTZNSkSfbl3gVB9XQIJfw','Sovgwq-E-n6wLqNh3X_rXg','j5nPiTwWEFr-VsePew7Sjg',\n",
        "          'aiX_WP7NKPTdF9CfI-M-wg', 'e4NQLZynhSmvwl38hC4m-A']\n",
        "#id_list = ['aiX_WP7NKPTdF9CfI-M-wg', 'e4NQLZynhSmvwl38hC4m-A']\n",
        "#          'OVTZNSkSfbl3gVB9XQIJfw','Sovgwq-E-n6wLqNh3X_rXg','j5nPiTwWEFr-VsePew7Sjg',\n",
        "#          'aiX_WP7NKPTdF9CfI-M-wg', 'e4NQLZynhSmvwl38hC4m-A']\n",
        "\n",
        "#list_of_attributes = ['review_count']\n",
        "#list_of_attributes = ['review_count', 'fans', 'average_stars', 'useful', 'funny', 'cool']\n",
        "#list_of_attributes = ['loc1', 'loc2', 'loc3']\n",
        "#list_of_attributes = ['age', 'gender', 'ethnicity']\n",
        "#list_of_attributes = ['fans']\n",
        "list_of_attributes = ['useful', 'funny', 'cool']\n",
        "\n",
        "for id in id_list:\n",
        "  authenticate()\n",
        "  #df_rel_ranking, df_date_ranking, df_rand_ranking = pipeline1(id, users, reviews)\n",
        "  df_rel_ranking = pd.read_csv(\"dataset_rel_ranking_\" + id + \".csv\")\n",
        "  df_date_ranking = pd.read_csv(\"dataset_date_ranking_\" + id + \".csv\")\n",
        "  df_rand_ranking = pd.read_csv(\"dataset_rand_ranking_\" + id + \".csv\")\n",
        "  group_list, method, percents = pipeline2(df_rel_ranking, reviews, business, id,\n",
        "                                           N_of_groups, list_of_attributes)\n",
        "\n",
        "  pipeline3(id, method, df_rel_ranking, df_date_ranking, df_rand_ranking, reviews,\n",
        "            percents, list_of_attributes)\n",
        "  "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "++++++++++++++++ GROUPS CREATION ++++++++++++++++++\n",
            "\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "1215\n",
            "1216\n",
            "1217\n",
            "1218\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1222\n",
            "1223\n",
            "1224\n",
            "1225\n",
            "1226\n",
            "1227\n",
            "1228\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1234\n",
            "1235\n",
            "1236\n",
            "1237\n",
            "1238\n",
            "1239\n",
            "1240\n",
            "1241\n",
            "1242\n",
            "1243\n",
            "1244\n",
            "1245\n",
            "1246\n",
            "1247\n",
            "1248\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1254\n",
            "1255\n",
            "1256\n",
            "1257\n",
            "1258\n",
            "1259\n",
            "1260\n",
            "1261\n",
            "1262\n",
            "1263\n",
            "1264\n",
            "1265\n",
            "1266\n",
            "1267\n",
            "1268\n",
            "1269\n",
            "1270\n",
            "1271\n",
            "1272\n",
            "1273\n",
            "1274\n",
            "1275\n",
            "1276\n",
            "1277\n",
            "1278\n",
            "1279\n",
            "1280\n",
            "1281\n",
            "1282\n",
            "1283\n",
            "1284\n",
            "1285\n",
            "1286\n",
            "1287\n",
            "1288\n",
            "1289\n",
            "1290\n",
            "1291\n",
            "1292\n",
            "1293\n",
            "1294\n",
            "1295\n",
            "1296\n",
            "1297\n",
            "1298\n",
            "1299\n",
            "1300\n",
            "1301\n",
            "1302\n",
            "1303\n",
            "1304\n",
            "1305\n",
            "1306\n",
            "1307\n",
            "1308\n",
            "1309\n",
            "1310\n",
            "1311\n",
            "1312\n",
            "1313\n",
            "1314\n",
            "1315\n",
            "1316\n",
            "1317\n",
            "1318\n",
            "1319\n",
            "1320\n",
            "1321\n",
            "1322\n",
            "1323\n",
            "1324\n",
            "1325\n",
            "1326\n",
            "1327\n",
            "1328\n",
            "1329\n",
            "1330\n",
            "1331\n",
            "1332\n",
            "1333\n",
            "1334\n",
            "1335\n",
            "1336\n",
            "1337\n",
            "1338\n",
            "1339\n",
            "1340\n",
            "1341\n",
            "1342\n",
            "1343\n",
            "1344\n",
            "1345\n",
            "1346\n",
            "1347\n",
            "1348\n",
            "1349\n",
            "1350\n",
            "1351\n",
            "1352\n",
            "1353\n",
            "1354\n",
            "1355\n",
            "1356\n",
            "1357\n",
            "1358\n",
            "1359\n",
            "1360\n",
            "1361\n",
            "1362\n",
            "1363\n",
            "1364\n",
            "1365\n",
            "1366\n",
            "1367\n",
            "1368\n",
            "1369\n",
            "1370\n",
            "1371\n",
            "1372\n",
            "1373\n",
            "1374\n",
            "1375\n",
            "1376\n",
            "1377\n",
            "1378\n",
            "1379\n",
            "1380\n",
            "1381\n",
            "1382\n",
            "1383\n",
            "1384\n",
            "1385\n",
            "1386\n",
            "1387\n",
            "1388\n",
            "1389\n",
            "1390\n",
            "1391\n",
            "1392\n",
            "1393\n",
            "1394\n",
            "1395\n",
            "1396\n",
            "1397\n",
            "1398\n",
            "1399\n",
            "1400\n",
            "1401\n",
            "1402\n",
            "1403\n",
            "1404\n",
            "1405\n",
            "1406\n",
            "1407\n",
            "1408\n",
            "1409\n",
            "1410\n",
            "1411\n",
            "1412\n",
            "1413\n",
            "1414\n",
            "1415\n",
            "1416\n",
            "1417\n",
            "1418\n",
            "1419\n",
            "1420\n",
            "1421\n",
            "1422\n",
            "1423\n",
            "1424\n",
            "1425\n",
            "1426\n",
            "1427\n",
            "1428\n",
            "1429\n",
            "1430\n",
            "1431\n",
            "1432\n",
            "1433\n",
            "1434\n",
            "1435\n",
            "1436\n",
            "1437\n",
            "1438\n",
            "1439\n",
            "1440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[94.79528105482305, 0.13879250520471895, 0.4163775156141568, 0.7633587786259541, 3.8861901457321304]\n",
            "                     user_id  group_id\n",
            "0     Csry0fCH7CHzNWiODqLpyQ       0.0\n",
            "1     BpJygDyhzDf7Pw1Is_5zSA       3.0\n",
            "2     98F1MRVrJP4WefdFTIVjTA       0.0\n",
            "3     _uZmgP8l4MbGKil4JK5Jcg       0.0\n",
            "4     Qco6eJS_9pMKMuMG9MXavA       0.0\n",
            "...                      ...       ...\n",
            "1436  qxQ30DOEcpqyFs897oTwmQ       0.0\n",
            "1437  -XMlwjKlrt7oyhEKy54v2g       0.0\n",
            "1438  B9I7ZvAQzfvhFScvXEH9dw       0.0\n",
            "1439  OzOwwv655qbjvNj96SHNlg       0.0\n",
            "1440  xMf_Kp0xp4-cL47Rno6dDQ       0.0\n",
            "\n",
            "[1441 rows x 2 columns]\n",
            "\n",
            "++++++++++++++++ EXPOSURE CALCULATION ++++++++++++++++++\n",
            "\n",
            "----------------DEMOGRAPHIC PARITY EXP------------------\n",
            "\n",
            "------------Ranking by Yelp filter:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.164349\n",
            "1        1  0.170653\n",
            "2        2  0.210178\n",
            "3        3  0.223239\n",
            "4        4   0.19869\n",
            "\n",
            "\n",
            "------------Ranking by Date:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0   0.16571\n",
            "1        1  0.174374\n",
            "2        2  0.179358\n",
            "3        3  0.174221\n",
            "4        4  0.178302\n",
            "\n",
            "\n",
            "------------Ranking Random:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.166318\n",
            "1        1  0.192596\n",
            "2        2   0.18146\n",
            "3        3  0.179579\n",
            "4        4  0.161526\n",
            "\n",
            "\n",
            "[0.16434918621997024, 0.17065301146556056, 0.21017827704958525, 0.223239340828845, 0.19869016505500267]\n",
            "----------------DISPARATE IMPACT EXP------------------\n",
            "\n",
            "------------Ranking by Yelp filter:------------\n",
            "\n",
            "  group_id   exposure\n",
            "0        0  0.0909556\n",
            "1        1   0.542921\n",
            "2        2    1.00534\n",
            "3        3   0.820501\n",
            "4        4    0.43336\n",
            "\n",
            "\n",
            "------------Ranking by Date:------------\n",
            "\n",
            "  group_id   exposure\n",
            "0        0  0.0959199\n",
            "1        1   0.542832\n",
            "2        2     0.7422\n",
            "3        3   0.540328\n",
            "4        4   0.344741\n",
            "\n",
            "\n",
            "------------Ranking Random:------------\n",
            "\n",
            "  group_id   exposure\n",
            "0        0  0.0871864\n",
            "1        1   0.638125\n",
            "2        2    0.74732\n",
            "3        3   0.543806\n",
            "4        4   0.312528\n",
            "\n",
            "\n",
            "[0.09095559868999854, 0.5429206340752014, 1.005343470748401, 0.8205010023807661, 0.43335996098650803]\n",
            "\n",
            "++++++++++++++++ GROUPS CREATION ++++++++++++++++++\n",
            "\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[97.74109470026065, 0.08688097306689835, 0.1737619461337967, 0.3475238922675934, 1.6507384882710685]\n",
            "                     user_id  group_id\n",
            "0     HiPoDtmoywssiHWP-qkSuw       0.0\n",
            "1     PcvbBOCOcs6_suRDH7TSTg       2.0\n",
            "2     yqa2qWN6acpmDuDL3U61UA       4.0\n",
            "3     G3g5OdmKI3kWTZCnLXJ0Nw       0.0\n",
            "4     7fsw7xwm-eamdoQgx4r3_Q       0.0\n",
            "...                      ...       ...\n",
            "1146  tHFyvWmVggLkAvZG9vj5zg       0.0\n",
            "1147  dgkUMwsa1yb-uq4G9gud0g       0.0\n",
            "1148  X_At0DP-9eTxWgkDypdCgg       0.0\n",
            "1149  ZCAudC377qgiqniEhKAoBg       0.0\n",
            "1150  iZffjmXRWJqXQCe3aHyxLQ       0.0\n",
            "\n",
            "[1151 rows x 2 columns]\n",
            "\n",
            "++++++++++++++++ EXPOSURE CALCULATION ++++++++++++++++++\n",
            "\n",
            "----------------DEMOGRAPHIC PARITY EXP------------------\n",
            "\n",
            "------------Ranking by Yelp filter:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.170694\n",
            "1        1  0.256949\n",
            "2        2  0.578259\n",
            "3        3  0.238712\n",
            "4        4  0.253444\n",
            "\n",
            "\n",
            "------------Ranking by Date:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.173126\n",
            "1        1  0.152187\n",
            "2        2  0.153636\n",
            "3        3  0.190569\n",
            "4        4  0.169771\n",
            "\n",
            "\n",
            "------------Ranking Random:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.173506\n",
            "1        1   0.14747\n",
            "2        2  0.145237\n",
            "3        3  0.149038\n",
            "4        4  0.157127\n",
            "\n",
            "\n",
            "[0.1706936059588101, 0.25694917118487537, 0.5782588862206659, 0.2387120968747448, 0.25344396866024094]\n",
            "----------------DISPARATE IMPACT EXP------------------\n",
            "\n",
            "------------Ranking by Yelp filter:------------\n",
            "\n",
            "  group_id   exposure\n",
            "0        0  0.0691642\n",
            "1        1     1.8345\n",
            "2        2    3.50082\n",
            "3        3     1.4031\n",
            "4        4   0.959165\n",
            "\n",
            "\n",
            "------------Ranking by Date:------------\n",
            "\n",
            "  group_id   exposure\n",
            "0        0  0.0779672\n",
            "1        1    1.08654\n",
            "2        2   0.907832\n",
            "3        3    1.13365\n",
            "4        4   0.618055\n",
            "\n",
            "\n",
            "------------Ranking Random:------------\n",
            "\n",
            "  group_id   exposure\n",
            "0        0  0.0686226\n",
            "1        1    1.05287\n",
            "2        2   0.860699\n",
            "3        3   0.890379\n",
            "4        4   0.577684\n",
            "\n",
            "\n",
            "[0.06916416944938832, 1.834501802630726, 3.500818533147769, 1.4030981203059851, 0.9591654096053811]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX8ibEsAIxCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pipeline1(business_id, users, reviews):\n",
        "  ### READ THE RANKING FROM CSV\n",
        "  df_rel_ranking = pd.read_csv(\"rel_ranking_\" + business_id + \".csv\")\n",
        "  df_date_ranking = pd.read_csv(\"date_ranking_\" + business_id + \".csv\")\n",
        "  df_rand_ranking = pd.read_csv(\"rand_ranking_\" + business_id + \".csv\")\n",
        "  ###\n",
        "\n",
        "  df_rel_ranking = filter_user_from_dataset(df_rel_ranking, users)\n",
        "  df_date_ranking = filter_user_from_dataset(df_date_ranking, users)\n",
        "  df_rand_ranking = filter_user_from_dataset(df_rand_ranking, users)\n",
        "\n",
        "  df_rel_ranking = integrate_review_info(df_rel_ranking, reviews, business_id)\n",
        "  df_date_ranking = integrate_review_info(df_date_ranking, reviews, business_id)\n",
        "  df_rand_ranking = integrate_review_info(df_rand_ranking, reviews, business_id)  \n",
        "\n",
        "  print(\"\\n++++++++++++++++ RANKING ++++++++++++++++++\\n\")\n",
        "\n",
        "  print(\"Ranking by Yelp filter:\")\n",
        "  pd.set_option('display.max_columns', None)\n",
        "  print(df_rel_ranking)\n",
        "  print('\\n')\n",
        "  print(\"Ranking by Date:\")\n",
        "  print(df_date_ranking)\n",
        "  print('\\n')\n",
        "  print(\"Ranking Random:\")\n",
        "  print(df_rand_ranking)\n",
        "  print('\\n')\n",
        "\n",
        "  df_rel_ranking.to_csv('dataset_rel_ranking_' + business_id + '.csv')\n",
        "  df_date_ranking.to_csv('dataset_date_ranking_' + business_id + '.csv')\n",
        "  df_rand_ranking.to_csv('dataset_rand_ranking_' + business_id + '.csv')\n",
        "  upload_file('dataset_rel_ranking_' + business_id + '.csv',\n",
        "                  FOLDER[business_id]['FID_RANKING'])\n",
        "  upload_file('dataset_date_ranking_' + business_id + '.csv',\n",
        "                  FOLDER[business_id]['FID_RANKING'])\n",
        "  upload_file('dataset_rand_ranking_' + business_id + '.csv',\n",
        "                  FOLDER[business_id]['FID_RANKING'])\n",
        "\n",
        "  return df_rel_ranking, df_date_ranking, df_rand_ranking\n",
        "\n",
        "\n",
        "def pipeline2(df_ranking_by_relevance, reviews, business, id, N_of_groups, local_list_of_attributes):\n",
        "  print(\"\\n++++++++++++++++ GROUPS CREATION ++++++++++++++++++\\n\")\n",
        "\n",
        "  # ------ SINGLE ATTRIBUTE ---------\n",
        "  if len(local_list_of_attributes) == 1:\n",
        "    attribute = local_list_of_attributes[0]\n",
        "    df_groups = create_groups_by_percentile(df_ranking_by_relevance, attribute, N_of_groups, id)\n",
        "    method = attribute\n",
        "  \n",
        "  # ------ MULTIPLE ATTRIBUTES ---------\n",
        "  # TO BUILD VECTORS, it saves a csv file\n",
        "  else:\n",
        "    method = 'kmeans'\n",
        "    # method = 'spectral'\n",
        "    df_vectors = create_vectors(df_ranking_by_relevance, reviews, business, id, list_of_attributes)\n",
        "    df_groups = create_groups_by_kmeans_clustering(df_ranking_by_relevance,N_of_groups,local_list_of_attributes,id)\n",
        "    # df_groups = create_groups_by_spectral_clustering(df_ranking_by_relevance, N_of_groups, id)\n",
        "  \n",
        "  percents = compute_groups_percents(df_groups, N_of_groups)\n",
        "  \n",
        "  print(df_groups)\n",
        "  return df_groups, method, percents\n",
        "\n",
        "\n",
        "def pipeline3(business_id, method, df_ranking_by_relevance, df_ranking_by_date, \n",
        "              df_ranking_by_random, reviews, percents, list_of_attributes):\n",
        "  print(\"\\n++++++++++++++++ EXPOSURE CALCULATION ++++++++++++++++++\\n\")\n",
        "  \n",
        "  print(\"----------------DEMOGRAPHIC PARITY EXP------------------\\n\")\n",
        "  print(\"------------Ranking by Yelp filter:------------\\n\")\n",
        "  yelp_exposures = print_demographic_parity_exposure(business_id, method, df_ranking_by_relevance,\n",
        "                                                     \"yelp_\", list_of_attributes)\n",
        "  print(\"------------Ranking by Date:------------\\n\")\n",
        "  date_exposures = print_demographic_parity_exposure(business_id, method, df_ranking_by_date,\n",
        "                                                     \"date_\", list_of_attributes)\n",
        "  print(\"------------Ranking Random:------------\\n\")\n",
        "  random_exposures = print_demographic_parity_exposure(business_id, method, df_ranking_by_random,\n",
        "                                                       \"random_\", list_of_attributes)\n",
        "  get_plots(yelp_exposures, date_exposures, random_exposures, percents,\n",
        "            'plot_demgr_' + method + '_' + business_id, list_of_attributes, business_id)\n",
        "\n",
        "  print(\"----------------DISPARATE IMPACT EXP------------------\\n\")\n",
        "  print(\"------------Ranking by Yelp filter:------------\\n\")\n",
        "  yelp_exposures = print_disparate_impact_exposure(business_id, method, df_ranking_by_relevance,\n",
        "                                                   reviews, \"yelp_\", list_of_attributes)\n",
        "  \n",
        "  print(\"------------Ranking by Date:------------\\n\")\n",
        "  date_exposures = print_disparate_impact_exposure(business_id, method, df_ranking_by_date,\n",
        "                                                   reviews, \"date_\", list_of_attributes)\n",
        "  \n",
        "  print(\"------------Ranking Random:------------\\n\")\n",
        "  random_exposures = print_disparate_impact_exposure(business_id, method, df_ranking_by_random,\n",
        "                                                     reviews, \"random_\", list_of_attributes)\n",
        "  get_plots(yelp_exposures, date_exposures, random_exposures, percents,\n",
        "            'plot_dispimp_' + method + '_' + business_id, list_of_attributes, business_id)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRs30-Z9heM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_groups_by_kmeans_clustering(df_users, N_of_groups, list_of_attributes, id):\n",
        "  df_vectors = pd.read_csv(\"user_vectors_\" + id + \".csv\")\n",
        "  \n",
        "  # FOR NOW WE EXCLUDE TEXTUAL ATTRIBUTES\n",
        "  text_attribute_list = ['gender', 'ethnicity']\n",
        "  df_vectors, dummy_columns_name = generate_dummies(df_vectors, text_attribute_list)\n",
        "  \n",
        "  local_list_of_attributes = list_of_attributes\n",
        "  # list_of_attributes - text_attribute_list + dummy_columns_name\n",
        "  # subtraction\n",
        "  temp = [item for item in list_of_attributes if item not in text_attribute_list]\n",
        "  list_of_attributes = temp\n",
        "  list_of_attributes = list_of_attributes + dummy_columns_name\n",
        "\n",
        "  list_vectors = df_vectors[list_of_attributes].values.tolist()\n",
        "  # ex. ['review_count', 'fans', 'average_stars', 'useful', 'funny', 'cool']\n",
        "  # ex. ['loc1', 'loc2', 'loc3']\n",
        "  # Convert list of lists in list of arrays\n",
        "  list_of_arrays = []\n",
        "  for vect in list_vectors:\n",
        "      current_array = np.array([])\n",
        "      for value in vect:\n",
        "          temp = np.array(value).flatten()\n",
        "          current_array = np.concatenate((current_array, temp))\n",
        "      list_of_arrays.append(current_array)\n",
        "  \n",
        "  X = np.array(list_of_arrays)\n",
        "  where_are_NaNs = np.isnan(X)\n",
        "  X[where_are_NaNs] = 0\n",
        "  kmeans = KMeans(n_clusters=N_of_groups, random_state=0).fit(X)\n",
        "  labels = kmeans.labels_\n",
        "  # kmeans.predict([[0, 0, 20], [12, 3, 5]]))\n",
        "  centroids = kmeans.cluster_centers_\n",
        "  temp_df = pd.DataFrame(data=centroids)\n",
        "  temp_df.columns = list_of_attributes\n",
        "  destination = set_file_destination(local_list_of_attributes, id)\n",
        "  temp_df.to_csv(\"centroids_kmeans_\" + id + \".csv\", float_format=\"%.3f\")\n",
        "  upload_file(\"centroids_kmeans_\" + id + \".csv\",destination)\n",
        "\n",
        "  # CONVERT CENTROID IN CUTE FORMAT ONLY FOR FLOATS!!!\n",
        "  #pd.options.display.float_format = '{:.3f}'.format\n",
        "  # pd.reset_option('^display.', silent=True)\n",
        "  #df_centroids = pd.read_csv('centroids_kmeans_' + id + '.csv', float_precision='round_trip')\n",
        "  #pd.set_option('display.max_columns', None)\n",
        "  #print(df_centroids)\n",
        "  #values = [float(x) for x in df_centroids.columns.values]\n",
        "  #df_centroids.loc[-1] = values # adding a row\n",
        "  #df_centroids.index = df_centroids.index + 1  # shifting index\n",
        "  #df_centroids.sort_index(inplace=True)\n",
        "  #df_centroids.columns = list_of_attributes  \n",
        "  #df_centroids.to_csv('centroids_kmeans_' + id + '.csv', float_format='%.3f')\n",
        "  #---\n",
        "\n",
        "  new_df_users = df_users[['user_id']]\n",
        "  new_df_users['group_id'] = np.NaN\n",
        "  for i, user in new_df_users.iterrows():\n",
        "    new_df_users.loc[i, 'group_id'] = labels[i]\n",
        "  new_df_users.to_csv('groups_kmeans_' + id + '.csv')\n",
        "  upload_file('groups_kmeans_' + id + '.csv',destination)\n",
        "  return new_df_users\n",
        "\n",
        "\n",
        "def generate_dummies(df, text_attribute_list):\n",
        "  dummy_columns = []\n",
        "  for attr in text_attribute_list:\n",
        "    gender_dummies = pd.get_dummies(df[attr])\n",
        "    dummy_columns = dummy_columns + list(gender_dummies.columns)\n",
        "    df = pd.merge(df, gender_dummies, how=\"left\",left_index=True, right_index=True)\n",
        "    \n",
        "    # drop all the unnamed columns\n",
        "    cols = [c for c in df.columns if c.lower()[:7] != 'unnamed']\n",
        "    df=df[cols]\n",
        "  return df, dummy_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU_zGBsWzAC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_groups_by_spectral_clustering(df_users, N_of_groups, id):\n",
        "  df_vectors = pd.read_csv(\"user_vectors_\" + id + \".csv\")\n",
        "  text_attribute_list = ['top_location']\n",
        "  df_vectors = one_hot_encoding(df_vectors, text_attribute_list)\n",
        "  \n",
        "  list_vectors = df_vectors[['review_count', 'fans', 'average_stars', 'top_location',\n",
        "                             'useful', 'funny', 'cool']].values.tolist()\n",
        "  # Convert list of list in list of arrays\n",
        "  list_of_arrays = []\n",
        "  for vect in list_vectors:\n",
        "      current_array = np.array([])\n",
        "      for value in vect:\n",
        "          temp = np.array(value).flatten()\n",
        "          current_array = np.concatenate((current_array, temp))\n",
        "      list_of_arrays.append(current_array)\n",
        "  mat = cosine_similarity(list_of_arrays)\n",
        "  group_array = SpectralClustering(n_clusters=N_of_groups, affinity='precomputed').fit_predict(mat)\n",
        "  new_df_users = df_users[['user_id']]\n",
        "  new_df_users['group_id'] = np.NaN\n",
        "  for i, user in new_df_users.iterrows():\n",
        "    new_df_users.loc[i, 'group_id'] = group_array[i]\n",
        "  new_df_users.to_csv('groups_spectral_' + id + '.csv')\n",
        "  return new_df_users\n",
        "\n",
        "def one_hot_encoding(df, text_attribute_list):\n",
        "  for attr in text_attribute_list:\n",
        "    text = list(df[attr])\n",
        "    vectorizer = CountVectorizer().fit_transform(text)\n",
        "    embeddings = vectorizer.toarray()\n",
        "    for i, user in df.iterrows():\n",
        "      df.at[i, attr] = embeddings[i]\n",
        "  return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awAE4AWWxEFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_groups_by_percentile(df_users, attribute, N_of_groups, business_id):\n",
        "  values = df_users[attribute].tolist()\n",
        "\n",
        "  print(df_users)\n",
        "\n",
        "  # Create array of percents to define limit of group \n",
        "  scale = 100/N_of_groups\n",
        "  percents = []\n",
        "  current_percent = 0\n",
        "  while current_percent < 100:\n",
        "    current_percent = current_percent + scale\n",
        "    '''if current_percent > 100:\n",
        "      current_percent = 100\n",
        "      percents.append(current_percent)\n",
        "      break'''\n",
        "    percents.append(current_percent)\n",
        "  # ex. percents = [20, 40, 60, 80, 100]\n",
        "  print(percents)\n",
        "\n",
        "  # Create array with limit values (max) of each group\n",
        "  i = 0\n",
        "  limit_values = []\n",
        "  while i < len(percents):\n",
        "    limit_values.append(np.percentile(values, percents[i]))\n",
        "    i = i + 1\n",
        "  # ex. limit_values = [5.0, 13.0, 27.0, 73.0, 10022.0]\n",
        "  print(limit_values)\n",
        "  with open('descr_groups_' + attribute + '_' + business_id + '.txt', 'w') as output:\n",
        "    output.write(str(percents) + '\\n' + str(limit_values))\n",
        "\n",
        "  new_df_users = df_users[['user_id']]\n",
        "  new_df_users['group_id'] = np.NaN\n",
        "  \n",
        "  for i, user in df_users.iterrows():\n",
        "    id_group = 0\n",
        "\n",
        "    if (user[attribute] >= 0) and (user[attribute] <= limit_values[id_group]):\n",
        "      new_df_users.loc[i, 'group_id'] = id_group\n",
        "    id_group = id_group + 1\n",
        "    while id_group < len(percents):\n",
        "      if (user[attribute] > limit_values[id_group - 1]) and (user[attribute] <= limit_values[id_group]):\n",
        "        new_df_users.loc[i, 'group_id'] = id_group\n",
        "      id_group = id_group + 1\n",
        "  \n",
        "  destination = set_file_destination([attribute], business_id)\n",
        "  new_df_users.to_csv('groups_' + attribute + '_' + business_id + '.csv')\n",
        "  upload_file('groups_' + attribute + '_' + business_id + '.csv',destination)\n",
        "  return new_df_users\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbpLTiPSWuL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_disparate_impact_exposure(business_id, method,  df_ranking, reviews,\n",
        "                                    filename, list_of_attributes):\n",
        "  df_groups = pd.read_csv('groups_' + method + '_' + business_id + '.csv')\n",
        "  i = 0\n",
        "  exposures = pd.DataFrame(columns=['group_id', 'exposure'])\n",
        "  while i <= df_groups['group_id'].max():\n",
        "      current_exp = disparate_impact_exposure(df_groups[df_groups['group_id'] == i], df_ranking, reviews, business_id)\n",
        "      exposures.loc[i, 'group_id'] = i\n",
        "      exposures.loc[i, 'exposure'] = current_exp\n",
        "      i = i + 1\n",
        "  \n",
        "  destination = set_file_destination(list_of_attributes, business_id)\n",
        "  \n",
        "  exposures.to_csv('exp_dispimp_' + method + '_' + filename + business_id + '.csv')\n",
        "  upload_file('exp_dispimp_' + method + '_' + filename + business_id + '.csv',\n",
        "                  destination)\n",
        "  \n",
        "  print(exposures)\n",
        "  print('\\n')\n",
        "  return exposures\n",
        "\n",
        "\n",
        "def print_demographic_parity_exposure(business_id, method, df_ranking, filename, list_of_attributes):\n",
        "  df_groups = pd.read_csv('groups_' + method + '_' + business_id + '.csv')\n",
        "  i = 0\n",
        "  exposures = pd.DataFrame(columns=['group_id', 'exposure'])\n",
        "  while i <= df_groups['group_id'].max():\n",
        "      current_exp = demographic_parity_exposure(df_groups[df_groups['group_id'] == i], df_ranking)\n",
        "      exposures.loc[i, 'group_id'] = i\n",
        "      exposures.loc[i, 'exposure'] = current_exp\n",
        "      i = i + 1\n",
        "\n",
        "  destination = set_file_destination(list_of_attributes, business_id)\n",
        "  \n",
        "  exposures.to_csv('exp_demgr_' + method + '_' + filename + business_id + '.csv')\n",
        "  upload_file('exp_demgr_' + method + '_' + filename + business_id + '.csv',\n",
        "                  destination)\n",
        "  \n",
        "  print(exposures)\n",
        "  print('\\n')\n",
        "  return exposures\n",
        "\n",
        "\n",
        "def disparate_impact_exposure(df_group, ranking, reviews, business_id):\n",
        "    if len(df_group.index) == 0:\n",
        "      return 0\n",
        "    return dmp_sommatory(df_group, ranking, business_id, reviews)/(len(df_group.index))\n",
        "\n",
        "\n",
        "def demographic_parity_exposure(df_group, ranking):\n",
        "    if len(df_group.index) == 0:\n",
        "      return 0\n",
        "    return demgr_sommatory(df_group, ranking)/(len(df_group.index))\n",
        "\n",
        "\n",
        "def dmp_sommatory(df_group, ranking, business_id, reviews):\n",
        "    sum = 0\n",
        "    for i, user in df_group.iterrows():\n",
        "        user_id = user['user_id']\n",
        "\n",
        "        #Integrate reviews info for clicks counting\n",
        "        df_temp = reviews[(reviews['business_id'] == business_id) & (reviews['user_id'] == user_id)]\n",
        "        useful = df_temp[df_temp['date'] == df_temp['date'].max()].iloc[0]['useful']\n",
        "        funny = df_temp[df_temp['date'] == df_temp['date'].max()].iloc[0]['funny']\n",
        "        cool = df_temp[df_temp['date'] == df_temp['date'].max()].iloc[0]['cool']\n",
        "        counts = useful + funny + cool + 1\n",
        "        base = 2  # con 10 i valori sono troppo bassi\n",
        "        counts = math.log(counts, base) \n",
        "\n",
        "        position = ranking.loc[ranking['user_id'] == user_id, 'position'].tolist()[0] # at??\n",
        "        addend = exp(position) * counts\n",
        "        sum = sum + addend\n",
        "    return sum\n",
        "\n",
        "\n",
        "def demgr_sommatory(df_group, ranking):\n",
        "    sum = 0\n",
        "    for i, user in df_group.iterrows():\n",
        "        user_id = user['user_id']\n",
        "        position = ranking.loc[ranking['user_id'] == user_id, 'position'].tolist()[0] # at??\n",
        "        sum = sum + exp(position)\n",
        "    return sum\n",
        "\n",
        "\n",
        "def exp(position):\n",
        "    if position == 'no match':\n",
        "        return 0\n",
        "    else:\n",
        "        return 1/np.log(1 + position)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPGOC05EljLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_plots(yelp_exposures, date_exposures, random_exposures, percents, title,\n",
        "              list_of_attributes, business_id):\n",
        "  width = 0.20\n",
        "  y_min = 0.0\n",
        "  y_max = 0.5\n",
        "\n",
        "  x1 = [el['group_id'] - width for i, el in yelp_exposures[['group_id']].iterrows()]\n",
        "  x2 = [el['group_id'] for i, el in date_exposures[['group_id']].iterrows()]\n",
        "  x3 = [el['group_id'] + width for i, el in random_exposures[['group_id']].iterrows()]\n",
        "\n",
        "  y1 = [el['exposure'] for i, el in yelp_exposures[['exposure']].iterrows()]\n",
        "  y2 = [el['exposure'] for i, el in date_exposures[['exposure']].iterrows()]\n",
        "  y3 = [el['exposure'] for i, el in random_exposures[['exposure']].iterrows()]\n",
        "\n",
        "  print(y1)\n",
        "\n",
        "  plt.bar(x1,y1,width=width,align='center', color='red', label='yelp')\n",
        "  plt.bar(x2,y2,width=width,align='center', color='green', label='date')\n",
        "  plt.bar(x3,y3,width=width,align='center', color='blue', label='random')\n",
        "  plt.legend(loc=\"upper center\")\n",
        "  plt.xlabel('Group id')\n",
        "  plt.ylabel('Exposure')\n",
        "  this_range = [str(int(id)) + \":\" + \"{:.{}f}\".format(percent,1) + \"%\" for id, percent in zip(np.arange(min(x2), max(x2)+1, 1.0), percents)]\n",
        "  plt.xticks(np.arange(min(x2), max(x2)+1, 1.0),this_range)\n",
        "  plt.yticks(np.arange(y_min, y_max, 0.05))\n",
        "  axes = plt.gca()\n",
        "  axes.set_ylim([y_min,y_max])\n",
        "  axes.yaxis.grid()\n",
        "\n",
        "  destination = set_file_destination(list_of_attributes, business_id)\n",
        "  \n",
        "  #plt.show()\n",
        "  plt.savefig(title + '.png')\n",
        "  upload_file(title + '.png', destination)\n",
        "  plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12Iq3ciMMcZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO UPDATE CENTROIDS\n",
        "id_list = ['WbJ1LRQdOuYYlRLyTkuuxw','T2tEMLpTeSMxLKpxwFdS3g','ALwAlxItASeEs2vYAeLXHA',\n",
        "          'OVTZNSkSfbl3gVB9XQIJfw','Sovgwq-E-n6wLqNh3X_rXg'] \n",
        "method = 'kmeans'\n",
        "for id in id_list:\n",
        "  pd.options.display.float_format = '{:.3f}'.format\n",
        "  centroids = pd.read_csv('centroids_' + method + '_' + id + '.csv')\n",
        "  values = [float(x) for x in centroids.columns.values]\n",
        "  centroids.loc[-1] = values # adding a row\n",
        "  centroids.index = centroids.index + 1  # shifting index\n",
        "  centroids.sort_index(inplace=True)\n",
        "  centroids.columns = ['loc1', 'loc2', 'loc3']  \n",
        "  centroids.to_csv('centroids_' + method + '_' + id + '.csv', float_format='%.3f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22E0H3eY8Vb3",
        "colab_type": "code",
        "outputId": "5116c13a-fb95-4c8f-a24f-ef34ddfd0c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# TO UPDATE EXPOSURE\n",
        "id_list = ['WbJ1LRQdOuYYlRLyTkuuxw','T2tEMLpTeSMxLKpxwFdS3g','ALwAlxItASeEs2vYAeLXHA']\n",
        "#          'OVTZNSkSfbl3gVB9XQIJfw','Sovgwq-E-n6wLqNh3X_rXg'] #RICALCOLARE DA CAPO\n",
        "# id_list = ['WbJ1LRQdOuYYlRLyTkuuxw']\n",
        "for id in id_list:\n",
        "  df_rel_ranking = pd.read_csv('dataset_rel_ranking_'+id+'.csv')\n",
        "  df_date_ranking = pd.read_csv('dataset_date_ranking_'+id+'.csv')\n",
        "  df_rand_ranking = pd.read_csv('dataset_rand_ranking_'+id+'.csv')\n",
        "\n",
        "  method = 'kmeans'\n",
        "  N_of_groups = 5\n",
        "  df_groups = pd.read_csv('groups_' + method + '_'+id+'.csv')\n",
        "  percents = compute_groups_percents(df_groups, N_of_groups)\n",
        "\n",
        "  pipeline3(id, method, df_rel_ranking, df_date_ranking, df_rand_ranking, reviews, percents)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[92.94037011651817, 0.06854009595613435, 1.0281014393420151, 5.68882796435915, 0.2741603838245374]\n",
            "\n",
            "++++++++++++++++ EXPOSURE CALCULATION ++++++++++++++++++\n",
            "\n",
            "----------------DEMOGRAPHIC PARITY EXP------------------\n",
            "\n",
            "------------Ranking by Yelp filter:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.162933\n",
            "1        1  0.220105\n",
            "2        2  0.240493\n",
            "3        3  0.200643\n",
            "4        4  0.185087\n",
            "\n",
            "\n",
            "------------Ranking by Date:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0   0.16376\n",
            "1        1  0.152814\n",
            "2        2  0.172153\n",
            "3        3  0.201048\n",
            "4        4  0.169292\n",
            "\n",
            "\n",
            "------------Ranking Random:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0   0.16606\n",
            "1        1  0.156778\n",
            "2        2  0.165594\n",
            "3        3  0.164798\n",
            "4        4  0.165478\n",
            "\n",
            "\n",
            "[0.16293274380030887, 0.2201045822301589, 0.2404932137794746, 0.20064345885486787, 0.1850865033952374]\n",
            "----------------DISPARATE IMPACT EXP------------------\n",
            "\n",
            "------------Ranking by Yelp filter:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.070566\n",
            "1        1   1.11977\n",
            "2        2  0.714228\n",
            "3        3  0.329566\n",
            "4        4  0.366383\n",
            "\n",
            "\n",
            "------------Ranking by Date:------------\n",
            "\n",
            "  group_id   exposure\n",
            "0        0  0.0740012\n",
            "1        1   0.777435\n",
            "2        2   0.466203\n",
            "3        3    0.39857\n",
            "4        4   0.300483\n",
            "\n",
            "\n",
            "------------Ranking Random:------------\n",
            "\n",
            "  group_id   exposure\n",
            "0        0  0.0673801\n",
            "1        1   0.797605\n",
            "2        2   0.473072\n",
            "3        3    0.28051\n",
            "4        4   0.303709\n",
            "\n",
            "\n",
            "[0.0705660245314008, 1.1197738832848634, 0.714228081159378, 0.3295657039859884, 0.3663834882008638]\n",
            "[93.1098696461825, 0.0931098696461825, 0.74487895716946, 0.186219739292365, 5.865921787709497]\n",
            "\n",
            "++++++++++++++++ EXPOSURE CALCULATION ++++++++++++++++++\n",
            "\n",
            "----------------DEMOGRAPHIC PARITY EXP------------------\n",
            "\n",
            "------------Ranking by Yelp filter:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.173895\n",
            "1        1  0.621335\n",
            "2        2   0.21503\n",
            "3        3  0.228349\n",
            "4        4  0.183252\n",
            "\n",
            "\n",
            "------------Ranking by Date:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.173915\n",
            "1        1  0.144723\n",
            "2        2  0.182823\n",
            "3        3  0.171159\n",
            "4        4  0.196404\n",
            "\n",
            "\n",
            "------------Ranking Random:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.175771\n",
            "1        1  0.151612\n",
            "2        2  0.170644\n",
            "3        3  0.167176\n",
            "4        4  0.168518\n",
            "\n",
            "\n",
            "[0.17389513349465582, 0.6213349345596119, 0.2150297612553226, 0.2283487263806268, 0.18325220317761595]\n",
            "----------------DISPARATE IMPACT EXP------------------\n",
            "\n",
            "------------Ranking by Yelp filter:------------\n",
            "\n",
            "  group_id   exposure\n",
            "0        0  0.0948298\n",
            "1        1    3.07822\n",
            "2        2   0.537432\n",
            "3        3   0.469229\n",
            "4        4   0.283128\n",
            "\n",
            "\n",
            "------------Ranking by Date:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0   0.10486\n",
            "1        1  0.716986\n",
            "2        2  0.406378\n",
            "3        3  0.326073\n",
            "4        4  0.334458\n",
            "\n",
            "\n",
            "------------Ranking Random:------------\n",
            "\n",
            "  group_id   exposure\n",
            "0        0  0.0938564\n",
            "1        1   0.751116\n",
            "2        2   0.378691\n",
            "3        3   0.318491\n",
            "4        4   0.263216\n",
            "\n",
            "\n",
            "[0.09482980330121404, 3.0782152403097, 0.5374321645605649, 0.46922881898353463, 0.28312772973154576]\n",
            "[93.4054054054054, 0.10810810810810811, 0.9729729729729729, 5.297297297297297, 0.21621621621621623]\n",
            "\n",
            "++++++++++++++++ EXPOSURE CALCULATION ++++++++++++++++++\n",
            "\n",
            "----------------DEMOGRAPHIC PARITY EXP------------------\n",
            "\n",
            "------------Ranking by Yelp filter:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.176476\n",
            "1        1  0.200383\n",
            "2        2  0.208942\n",
            "3        3  0.228386\n",
            "4        4  0.460329\n",
            "\n",
            "\n",
            "------------Ranking by Date:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.178995\n",
            "1        1  0.234594\n",
            "2        2  0.224002\n",
            "3        3   0.19136\n",
            "4        4  0.194405\n",
            "\n",
            "\n",
            "------------Ranking Random:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.180793\n",
            "1        1  0.166559\n",
            "2        2  0.185239\n",
            "3        3   0.16935\n",
            "4        4  0.165265\n",
            "\n",
            "\n",
            "[0.17647606219677034, 0.20038343021591398, 0.20894189258758333, 0.22838557398304843, 0.4603293537434925]\n",
            "----------------DISPARATE IMPACT EXP------------------\n",
            "\n",
            "------------Ranking by Yelp filter:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.114704\n",
            "1        1   1.01081\n",
            "2        2  0.727906\n",
            "3        3  0.548388\n",
            "4        4   2.27585\n",
            "\n",
            "\n",
            "------------Ranking by Date:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.124164\n",
            "1        1   1.18339\n",
            "2        2  0.761529\n",
            "3        3  0.483666\n",
            "4        4  0.957387\n",
            "\n",
            "\n",
            "------------Ranking Random:------------\n",
            "\n",
            "  group_id  exposure\n",
            "0        0  0.111639\n",
            "1        1  0.840188\n",
            "2        2  0.633305\n",
            "3        3  0.414278\n",
            "4        4  0.814873\n",
            "\n",
            "\n",
            "[0.11470445783168728, 1.0108129969980315, 0.7279060122864212, 0.5483878282837408, 2.2758477067956013]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FcLo9mPIeHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO UPDATE PLOTS\n",
        "id = 'WbJ1LRQdOuYYlRLyTkuuxw'\n",
        "grouping = 'review_count'\n",
        "exp = 'demgr'\n",
        "y = pd.read_csv('exp_' + exp + '_' + grouping + '_yelp_' + id + '.csv')\n",
        "d = pd.read_csv('exp_' + exp + '_' + grouping + '_date_' + id + '.csv')\n",
        "r = pd.read_csv('exp_' + exp + '_' + grouping + '_random_' + id + '.csv')\n",
        "get_plots(y,d,r, [93.42, 0.17, 0.003, 5.81, 0.188], \"title\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbUr0D9xWp5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_objective_groups_by_size(df_users, attribute, range):\n",
        "    # order df_users by review_count\n",
        "    df_users = df_users.sort_values(attribute).reset_index(drop=True)\n",
        "    group_list = [[]]\n",
        "    i = 0\n",
        "    group_index = 0\n",
        "    prec = -1\n",
        "    for index, user in df_users.iterrows():\n",
        "        if i == range:\n",
        "            i = 0\n",
        "            group_list.append([])\n",
        "            group_index = group_index + 1\n",
        "        temp = user[attribute]\n",
        "        if temp != prec:\n",
        "            prec = temp\n",
        "            i = i + 1\n",
        "        group_list[group_index].append(user)\n",
        "    print(\"Number of groups created: \" + str(group_index+1))\n",
        "    return group_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovYumnpYHecF",
        "colab_type": "code",
        "outputId": "e54f518e-730b-47d2-c8dd-a165910cde70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "### UNIQUE VALUE OF state, city AND categories OF BUSINESS\n",
        "# To filter only RESTAURANTS\n",
        "# is_restaurant = business['categories'].str.contains('Restaurants', regex=False, na=False)\n",
        "# restaurants = business[is_restaurant]\n",
        "\n",
        "print('UNIQUE VALUE OF \\'state\\' ATTRIBUTE IN RESTAURANTS = ', business['state'].nunique())\n",
        "print('UNIQUE VALUE OF \\'city\\' ATTRIBUTE IN RESTAURANTS = ', business['city'].nunique())\n",
        "df_cat = business[['categories']]\n",
        "distinct_categories_list = []\n",
        "for index, row in df_cat.iterrows():\n",
        "  if row['categories'] != None:\n",
        "    lst = [item.strip() for item in row['categories'].split(',')]\n",
        "    distinct_categories_list = list(set(distinct_categories_list + lst))\n",
        "print('UNIQUE VALUE OF \\'categories\\' ATTRIBUTE distinct values ', len(distinct_categories_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNIQUE VALUE OF 'state' ATTRIBUTE IN RESTAURANTS =  36\n",
            "UNIQUE VALUE OF 'city' ATTRIBUTE IN RESTAURANTS =  1204\n",
            "UNIQUE VALUE OF 'categories' ATTRIBUTE distinct values  1300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C05AeyBn2gGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PRINT THE state OF EACH user FOR HIS RESTAURANT reviews\n",
        "def statistics(users, reviews, business):\n",
        "  res = pd.DataFrame()\n",
        "  cont = 0\n",
        "  prec_user_id = '0'\n",
        "\n",
        "  for i, user in users.iterrows():\n",
        "    if cont == 1000:\n",
        "      break\n",
        "    user_id = user['user_id']  # 4, 9, 16, 21!, 22!, 23, 24\n",
        "    # Get all reviews of one user\n",
        "    # 'https://www.yelp.com/user_details_reviews_self?userid=NQffx45eJaeqhFcMadKUQA&rec_pagestart=90'??? no\n",
        "    user_reviews = reviews[reviews['user_id'] == user_id]\n",
        "    # Get all restaurants\n",
        "    business_ids = user_reviews[['business_id']]\n",
        "    result = business_ids.merge(business)\n",
        "    is_restaurant = result['categories'].str.contains('Restaurants', regex=False, na=False)\n",
        "    user_restaurant_reviews = result[is_restaurant]\n",
        "    user_restaurant_reviews['user_id'] = user_id\n",
        "    #user_restaurant_reviews.to_csv('user_restaurant_reviews' + str(cont) + '.csv')\n",
        "    res = res.append(user_restaurant_reviews.groupby(['user_id', 'state'])['user_id'].count().reset_index(name=\"review_count\"))\n",
        "    if (user_id != prec_user_id) and not user_restaurant_reviews.empty:\n",
        "      cont = cont + 1\n",
        "    # print(res)\n",
        "    prec_user_id = user_id\n",
        "\n",
        "  res.to_csv('result.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0M0ETqjMrqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_df_users(ranking):\n",
        "  df_ranking = pd.DataFrame(ranking, columns=['position', 'user_id', 'review_count', 'date']).sort_values('position')\n",
        "  return df_ranking"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6gUlnqBZ9eoa",
        "colab": {}
      },
      "source": [
        "# TODO: get review_count from web page\n",
        "def get_ranking(url):\n",
        "\n",
        "  i=1\n",
        "  reviews_text = []\n",
        "  reviews_date = []\n",
        "  reviews_userid = []\n",
        "  x=0\n",
        "\n",
        "  while 1:\n",
        "    if x == 0:\n",
        "      page_content = requests.get(url)\n",
        "    else:\n",
        "        page_content = requests.get(url + '?start=' + str(x))\n",
        "    x = x + 20\n",
        "    \n",
        "    tree = html.fromstring(page_content.content)\n",
        "    recommended_reviews_text = \"Recommended Reviews\"\n",
        "    reviews_list = tree.xpath('//section[div[div[h3[text()=\"%s\"]]]]/div/div/ul/*' % recommended_reviews_text)\n",
        "    if not reviews_list:\n",
        "      break\n",
        "    else:\n",
        "      # Index for ranking\n",
        "      j=1\n",
        "      for review in reviews_list:\n",
        "          reviews_text.append((i, tree.xpath('//section[div[div[h3[text()=\"%s\"]]]]/div/div/ul/li[%d]/div/div[last()]/div[p]/p/span' % (recommended_reviews_text, j))[0].text))\n",
        "          reviews_date.append((i, tree.xpath('//section[div[div[h3[text()=\"%s\"]]]]/div/div/ul/li[%d]/div/div[last()]/div[1]/div/div[2]/span' % (recommended_reviews_text, j))[0].text))\n",
        "          user_link = tree.xpath('//section[div[div[h3[text()=\"%s\"]]]]/div/div/ul/li[%d]/div/div/div/div/div/div/div/a/@href' % (recommended_reviews_text, j))[0]\n",
        "          reviews_userid.append((i,user_link[user_link.find('=')+1:]))\n",
        "          i = i + 1\n",
        "          j = j + 1\n",
        "\n",
        "\n",
        "  print(reviews_text)\n",
        "  print(\"N. of reviews = \" + str(len(reviews_text)))\n",
        "  print(reviews_date)\n",
        "  print(\"N. of reviews = \" + str(len(reviews_date)))\n",
        "  print(reviews_userid)\n",
        "  print(\"N. of reviews = \" + str(len(reviews_userid)))\n",
        "  return reviews_userid\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHl6bORqNzeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_users_in_dataset(users):\n",
        "    data = []\n",
        "    with open(\"user.json\", 'r') as file:\n",
        "        for line in file:\n",
        "            json_data = json.loads(line)\n",
        "            data.append(json_data)\n",
        "    df = pd.DataFrame(data)\n",
        "    df_ranking = pd.DataFrame(users, columns=['Position', 'user_id'])\n",
        "    df_merged = df_ranking.merge(df, on='user_id')\n",
        "    # temp = df[df['user_id'].isin(users)]\n",
        "    return df_merged\n",
        "\n",
        "\n",
        "def exists_in_dataset(userid):\n",
        "  found = False\n",
        "  with open(\"user.json\", 'r') as file:\n",
        "        for line in file:\n",
        "            json_data = json.loads(line)\n",
        "            if json_data['user_id'] == userid:\n",
        "              found = True\n",
        "  if found:\n",
        "    print(\"Trovato\")\n",
        "  else:\n",
        "    print(\"Non trovato\")\n",
        "  return found\n",
        "\n",
        "\n",
        "def find_users_in_chopped_dataset(users):\n",
        "    found = False\n",
        "    data = []\n",
        "    i = 1\n",
        "    j = 100000\n",
        "    df_users = pd.DataFrame()\n",
        "    while not found:\n",
        "        path = \"user\" + str(i) + \"-\" + str(j) + \".json\"\n",
        "        try:\n",
        "            with open(path, 'r') as file:\n",
        "                for line in file:\n",
        "                    json_data = json.loads(line)\n",
        "                    data.append(json_data)\n",
        "            df = pd.DataFrame(data)\n",
        "        except FileNotFoundError:\n",
        "            print(\"Cannot find all users into the dataset\")\n",
        "            return 0\n",
        "        else:\n",
        "            temp = df[df['user_id'].isin(users)]  # df of users of the ranking\n",
        "            df_users = df_users.append(temp)\n",
        "            if df_users.shape[0] == len(users):\n",
        "                found = True\n",
        "            else:\n",
        "                i = i + 100000\n",
        "                j = j + 100000\n",
        "    return df_users\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}