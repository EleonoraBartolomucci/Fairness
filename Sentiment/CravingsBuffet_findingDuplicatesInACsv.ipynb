{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrZtzy1mIaoYC/dE0pLRws",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EleonoraBartolomucci/Fairness/blob/master/Sentiment/CravingsBuffet_findingDuplicatesInACsv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqBUUswyzxvg",
        "colab_type": "code",
        "outputId": "6f533a5d-d7ab-442c-c5c8-4b3ed959a8af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# FUNZIONE CHE CARICA UN CSV DAL DRIVE, STAMPA I DUPLICATI SE PRESENTI E SALVA IL NUOVO CSV SENZA DUPLICATI\n",
        "\n",
        "#Da cambiare\n",
        "#nome_ristorante\n",
        "#id_csv\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import auth\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "nome_ristorante = 'CravingsBuffet'\n",
        "\n",
        "id_csv = '1KmL5j0nlwgB_DjKNxKSBvoGdqNGm5KPj'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': id_csv})\n",
        "download.GetContentFile('%s' % nome_ristorante + '_Random_ReviewSentiment.csv')\n",
        "\n",
        "#Csv originale\n",
        "df = pd.read_csv('%s' % nome_ristorante + '_Random_ReviewSentiment.csv')\n",
        "print(df)\n",
        "\n",
        "#Stampa duplicati\n",
        "print(df[df.duplicated(keep='first')])\n",
        "\n",
        "#Elimina i duplicati e salva il risultato in un csv\n",
        "df = pd.read_csv('%s' % nome_ristorante + '_Random_ReviewSentiment.csv').drop_duplicates(keep='first')\n",
        "print(df)\n",
        "df.to_csv('NODUP' + '%s' % nome_ristorante + '_Random_ReviewSentiment.csv', index=False)\n",
        "\n",
        "folder_id = '16fL1gZDVLxH7f6UfG5IJ2gwoVjiffQA0'    #cartella dove metto il csv\n",
        "file_metadata = {'title': 'NODUP' + '%s' % nome_ristorante +'_Random_ReviewSentiment.csv',\"parents\":[{\"id\": folder_id,\"kind\":\"drive#childList\"}]}\n",
        "folder = drive.CreateFile(file_metadata)\n",
        "folder.SetContentFile('NODUP' + '%s' % nome_ristorante +'_Random_ReviewSentiment.csv') #The contents of the file\n",
        "folder.Upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          id  review_sentiment\n",
            "0     xZDovqMdVGNOmjKK83VbUw  negative (0.584)\n",
            "1     4Xkk4WJhTGUEjCrMcQzJCg   positive (0.77)\n",
            "2     WtXa80CoDZFpOwL54T--bw  positive (0.533)\n",
            "3     AGpnVxWBOSsLw4VuC81q7A  negative (0.937)\n",
            "4     lurEQkg-9bQ1pb793KWV5w  negative (0.485)\n",
            "...                      ...               ...\n",
            "1526  WBHEgf3o62W2iKuuulqAuQ   neutral (0.454)\n",
            "1527  jUkfklC7mMEPBVLSOBeXNA  positive (0.489)\n",
            "1528  QM9bRogGOTK8mo45bQ6dtQ  positive (0.549)\n",
            "1529  QC13EpfxNDqTGkdgt05uJw  negative (0.602)\n",
            "1530  SBYq1zEWQsqEc8jjy329vg  positive (0.364)\n",
            "\n",
            "[1531 rows x 2 columns]\n",
            "                          id  review_sentiment\n",
            "178   xZDovqMdVGNOmjKK83VbUw  negative (0.584)\n",
            "179   4Xkk4WJhTGUEjCrMcQzJCg   positive (0.77)\n",
            "180   WtXa80CoDZFpOwL54T--bw  positive (0.533)\n",
            "181   AGpnVxWBOSsLw4VuC81q7A  negative (0.937)\n",
            "182   lurEQkg-9bQ1pb793KWV5w  negative (0.485)\n",
            "...                      ...               ...\n",
            "1393  52WCuyzkr59h0Hugv8u0Cg  positive (0.797)\n",
            "1394  6HA_4_O4XrhY83GOyfAf0Q  positive (0.879)\n",
            "1395  JsOZKgLrNq2XXPZu4Shesw  positive (0.409)\n",
            "1396  55JSQKPBoZP9GHf6squqIA  positive (0.618)\n",
            "1397  OBLLSu39l5jYvnvPbNyoZg  negative (0.367)\n",
            "\n",
            "[186 rows x 2 columns]\n",
            "                          id  review_sentiment\n",
            "0     xZDovqMdVGNOmjKK83VbUw  negative (0.584)\n",
            "1     4Xkk4WJhTGUEjCrMcQzJCg   positive (0.77)\n",
            "2     WtXa80CoDZFpOwL54T--bw  positive (0.533)\n",
            "3     AGpnVxWBOSsLw4VuC81q7A  negative (0.937)\n",
            "4     lurEQkg-9bQ1pb793KWV5w  negative (0.485)\n",
            "...                      ...               ...\n",
            "1526  WBHEgf3o62W2iKuuulqAuQ   neutral (0.454)\n",
            "1527  jUkfklC7mMEPBVLSOBeXNA  positive (0.489)\n",
            "1528  QM9bRogGOTK8mo45bQ6dtQ  positive (0.549)\n",
            "1529  QC13EpfxNDqTGkdgt05uJw  negative (0.602)\n",
            "1530  SBYq1zEWQsqEc8jjy329vg  positive (0.364)\n",
            "\n",
            "[1345 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}