{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "support_functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EleonoraBartolomucci/Fairness/blob/master/support_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-GtXfILY6qy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "9375db76-b572-4e0b-d8dc-748b8047412e"
      },
      "source": [
        "!pip install clarifai"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting clarifai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/1b/b7718c29f54ba7545551724461a8c2891304b7e68e5f415c30b49499f5e1/clarifai-2.6.2.tar.gz (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 1.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 1.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71kB 1.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: future<2,>=0.15 in /usr/local/lib/python3.6/dist-packages (from clarifai) (0.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.13 in /usr/local/lib/python3.6/dist-packages (from clarifai) (2.23.0)\n",
            "Collecting configparser<4,>=3.5\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/1a/ec151e5e703ac80041eaccef923611bbcec2b667c20383655a06962732e9/configparser-3.8.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jsonschema<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from clarifai) (2.6.0)\n",
            "Requirement already satisfied: grpcio<2,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from clarifai) (1.31.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.6 in /usr/local/lib/python3.6/dist-packages (from clarifai) (3.12.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from clarifai) (1.52.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.13->clarifai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.13->clarifai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.13->clarifai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.13->clarifai) (2020.6.20)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from grpcio<2,>=1.13.0->clarifai) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf<4,>=3.6->clarifai) (49.6.0)\n",
            "Building wheels for collected packages: clarifai\n",
            "  Building wheel for clarifai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clarifai: filename=clarifai-2.6.2-cp36-none-any.whl size=188404 sha256=38853afeea3fd23cb82f7cc826acb81099f1eb6c4e8020539354f51d66ad0fc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/2c/3b/d89ffd4572633f70872165cedf61813ac8047461ed5e1e3768\n",
            "Successfully built clarifai\n",
            "Installing collected packages: configparser, clarifai\n",
            "Successfully installed clarifai-2.6.2 configparser-3.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl0nPnD7VUxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "f9866f3a-5001-45b8-f412-f2f57106dab2"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from clarifai.rest import ClarifaiApp\n",
        "from clarifai.rest import ApiError\n",
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd\n",
        "import requests\n",
        "from lxml import html\n",
        "import shutil\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "\n",
        "# AUTHENTICATE IN GOOGLE DRIVE\n",
        "def authenticate():\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  return drive\n",
        "drive = authenticate()\n",
        "\n",
        "\n",
        "def create_folder_in_drive(gdrive, folder_name, parent_folder_id):\n",
        "  folder_metadata = {'title': folder_name,'mimeType': 'application/vnd.google-apps.folder',\n",
        "                    'parents': [{\"kind\": \"drive#fileLink\", \"id\": parent_folder_id}]\n",
        "                    }\n",
        "  folder = gdrive.CreateFile(folder_metadata)\n",
        "  folder.Upload()\n",
        "  print(folder)\n",
        "  # Return folder informations\n",
        "  print('title: %s, id: %s' % (folder['title'], folder['id']))\n",
        "  return folder['id']\n",
        "\n",
        "\n",
        "def drop_unnamed(df):\n",
        "  cols = [c for c in df.columns if c.lower()[:7] != 'unnamed']\n",
        "  return df[cols]\n",
        "\n",
        "\n",
        "def upload_file(filename, folder_id):\n",
        "  drive = authenticate()\n",
        "  fileList = drive.ListFile({'q': \"'\" + folder_id + \"' in parents and trashed=false\"}).GetList()\n",
        "  drive_file = drive.CreateFile({'title': filename, 'parents': [{'id': folder_id}]})\n",
        "  # Check if file already exists in Google Drive (prevents duplicates)\n",
        "  for file in fileList:\n",
        "      if file['title'] == filename:  # The file already exists, then overwrite it\n",
        "          fileID = file['id']\n",
        "          drive_file = drive.CreateFile({'id': fileID, 'title': filename, 'parents': [{'id': folder_id}]})\n",
        "  # Upload user picture on Google Drive\n",
        "  drive_file.SetContentFile(filename)  # path of local file content\n",
        "  drive_file.Upload()  # Upload the file.\n",
        "  return drive_file['id']\n",
        "\n",
        "\n",
        "def downloadUser(business_id, user_id, photo_folder, counter, ip_addresses):\n",
        "    authenticate()\n",
        "    \n",
        "    filename = user_id + '.jpg'\n",
        "    url = 'https://www.yelp.com/user_details?userid=' + user_id\n",
        "    folder_id = photo_folder\n",
        "\n",
        "    # CHECK DUPLICATE\n",
        "    fileList = drive.ListFile({'q': \"'\" + folder_id + \"' in parents and trashed=false\"}).GetList()\n",
        "    exists = False\n",
        "    # Check if file already exists in Google Drive (prevents duplicates)\n",
        "    for file in fileList:\n",
        "        if file['title'] == filename:  # The file already exists\n",
        "            exists = True\n",
        "    \n",
        "    if not exists:\n",
        "      downloaded = False\n",
        "      while len(ip_addresses) != 0 and not downloaded:\n",
        "        proxy_index = 0\n",
        "        proxy = {\"http\": ip_addresses[proxy_index], \"https\": ip_addresses[proxy_index]}\n",
        "        try:\n",
        "          # Check the proxy address\n",
        "          #response = requests.get('https://httpbin.org/ip',proxies=proxy, timeout=5)\n",
        "          #print(response.json())\n",
        "          \n",
        "          # Find user picture from web page\n",
        "          page_content = requests.get(url, proxies=proxy, timeout=10)\n",
        "          print(page_content)\n",
        "          if page_content.status_code != 503:\n",
        "            tree = html.fromstring(page_content.content)\n",
        "            if len(tree.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/div/div[2]/div[1]/div/div/div/a/img/@src')) == 0:\n",
        "              print('PICTURE NOT FOUND of user '+ user_id)\n",
        "            else: # Picture found\n",
        "              image_url = tree.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/div/div[2]/div[1]/div/div/div/a/img/@src')[0]\n",
        "\n",
        "              drive_file = drive.CreateFile({'title': filename, 'parents': [{'id': folder_id}]})\n",
        "              \n",
        "              response = requests.get(image_url, proxies=proxy, timeout=30, stream=True)\n",
        "              \n",
        "              # Create a local copy of user picture\n",
        "              with open(filename, 'wb') as out_file:\n",
        "                  shutil.copyfileobj(response.raw, out_file)\n",
        "              del response\n",
        "\n",
        "              # Upload user picture on Google Drive\n",
        "              drive_file.SetContentFile(filename)\n",
        "              drive_file.Upload()\n",
        "              if os.path.exists(filename):\n",
        "                  os.remove(filename)\n",
        "              else:\n",
        "                  print(\"The file does not exist\")\n",
        "              print(user_id + ' downloaded')\n",
        "              downloaded = True\n",
        "              ip_addresses.insert(0, ip_addresses.pop(proxy_index))\n",
        "          else:\n",
        "            print(\"Skipping. Connnection error\")\n",
        "            del ip_addresses[proxy_index]\n",
        "            print(\"Proxy rimanenti: \")\n",
        "            print(ip_addresses)\n",
        "            #restart_runtime()\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          print(\"Skipping. Connnection error\")\n",
        "          del ip_addresses[proxy_index]\n",
        "          print(\"Proxy rimanenti: \")\n",
        "          print(ip_addresses)\n",
        "      if len(ip_addresses)==0:\n",
        "        print(\"Nessun proxy disponibile\")\n",
        "\n",
        "\n",
        "def get_proxies():\n",
        "    url = 'https://free-proxy-list.net/'\n",
        "    response = requests.get(url)\n",
        "    parser = html.fromstring(response.content)\n",
        "    proxies = []\n",
        "    for i in parser.xpath('//tbody/tr')[:100]:\n",
        "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
        "            #Grabbing IP and corresponding PORT\n",
        "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
        "            proxies.append(proxy)\n",
        "    print(proxies)\n",
        "    return proxies"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2d960fc0546c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mdrive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdrive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-2d960fc0546c>\u001b[0m in \u001b[0;36mauthenticate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# AUTHENTICATE IN GOOGLE DRIVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mgauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclear_output\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m       \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mcolab_tpu_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# https://github.com/jupyter/notebook/issues/3159\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHBNPUGlbzWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "c51c0c7c-e5f4-4d6e-e51d-9964ab1735f3"
      },
      "source": [
        "################################################################################\n",
        "######################### DOWNLOAD RANKINGS ####################################\n",
        "\n",
        "def get_ranking_from_call(url_business, lang, sort, query):\n",
        "    headers = [{\"name\": \"Accept\", \"value\": \"*/*\"}, {\"name\": \"Accept-Encoding\", \"value\": \"gzip, deflate, br\"},\n",
        "               {\"name\": \"Accept-Language\", \"value\": \"it-IT,it;q=0.8,en-US;q=0.5,en;q=0.3\"},\n",
        "               {\"name\": \"Connection\", \"value\": \"keep-alive\"},\n",
        "               {\"name\": \"Content-Type\", \"value\": \"application/x-www-form-urlencoded; charset=utf-8\"}, {\"name\": \"Cookie\",\n",
        "                                                                                                       \"value\": \"qntcst=D; hl=en_US; wdi=1|3C26116D69138F61|0x1.78d019f71a444p+30|a7756ff94751d3a9; _ga=GA1.2.3C26116D69138F61; location=%7B%22city%22%3A+%22New+York%22%2C+%22state%22%3A+%22NY%22%2C+%22country%22%3A+%22US%22%2C+%22latitude%22%3A+40.713%2C+%22longitude%22%3A+-74.0072%2C+%22max_latitude%22%3A+40.8523%2C+%22min_latitude%22%3A+40.5597%2C+%22max_longitude%22%3A+-73.7938%2C+%22min_longitude%22%3A+-74.1948%2C+%22zip%22%3A+%22%22%2C+%22address1%22%3A+%22%22%2C+%22address2%22%3A+%22%22%2C+%22address3%22%3A+null%2C+%22neighborhood%22%3A+null%2C+%22borough%22%3A+null%2C+%22provenance%22%3A+%22YELP_GEOCODING_ENGINE%22%2C+%22display%22%3A+%22New+York%2C+NY%22%2C+%22unformatted%22%3A+%22New+York%2C+NY%2C+US%22%2C+%22accuracy%22%3A+4.0%2C+%22language%22%3A+null%7D; xcj=1|Ptt9P03gfc75x_PBT9zmqCkUuSuyB7PR-wWUBvABNi4; __qca=P0-60561249-1581956668708; G_ENABLED_IDPS=google; __cfduid=db8764ff59d8028a6c2e1b214867927d81583160194; _gid=GA1.2.2014867238.1583835527; bse=05dcd9d5de304ef0b1d9a76fa768b10f; sc=8a1ca0dbc2; pid=505721aa4569e7bb\"},\n",
        "               {\"name\": \"Host\", \"value\": \"www.yelp.com\"},\n",
        "               {\"name\": \"Referer\", \"value\": \"https://www.yelp.com/biz/noche-de-margaritas-new-york\"},\n",
        "               {\"name\": \"TE\", \"value\": \"Trailers\"}, {\"name\": \"User-Agent\",\n",
        "                                                     \"value\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:73.0) Gecko/20100101 Firefox/73.0\"},\n",
        "               {\"name\": \"X-Requested-By-React\", \"value\": \"true\"},\n",
        "               {\"name\": \"X-Requested-With\", \"value\": \"XMLHttpRequest\"}]\n",
        "    headers_ok = {}\n",
        "    for header in headers:\n",
        "        temp = {\n",
        "            header['name']: header['value']\n",
        "        }\n",
        "        headers_ok.update(temp)\n",
        "\n",
        "    x = 0\n",
        "    reviews_list = []\n",
        "    position = 1\n",
        "    url = url_business + \"/review_feed?rl=\" + lang + \"&sort_by=\" + sort + \"&q=\" + query\n",
        "\n",
        "    while 1:\n",
        "        if x == 0:\n",
        "            page_load = requests.get(url + '&start=', headers=headers_ok)\n",
        "        else:\n",
        "            page_load = requests.get(url + '&start=' + str(x), headers=headers_ok)\n",
        "        print(page_load)\n",
        "        x = x + 20\n",
        "        reviews = page_load.json()['reviews']\n",
        "        # print(json.dumps(reviews, indent=4, sort_keys=True))\n",
        "        if not reviews:\n",
        "            break\n",
        "        for review in reviews:\n",
        "            reviews_list.append((position, review['userId'], review['user'],\n",
        "                                 review['comment'], review['feedback'],\n",
        "                                 datetime.datetime.strptime(review['localizedDate'], '%m/%d/%Y')))\n",
        "            position = position + 1\n",
        "    df_reviews = pd.DataFrame(reviews_list, columns=[\"position\", \"user_id\", \"user\",\n",
        "                                                     \"comment\", \"feedback\", \"date\"])\n",
        "    return df_reviews\n",
        "\n",
        "\n",
        "def retrieve_rankings(business_id, folder_id):\n",
        "    df_rel_ranking = get_ranking_from_call(\"https://www.yelp.com/biz/\" + business_id, \"en\", \"relevance_desc\", \"\")\n",
        "    df_date_ranking = df_rel_ranking.sort_values(by=['date']).reset_index(drop=True)\n",
        "    df_date_ranking['position'] = df_date_ranking.index + 1\n",
        "    df_rand_ranking = df_rel_ranking.sample(frac=1).reset_index(drop=True)\n",
        "    df_rand_ranking['position'] = df_rand_ranking.index + 1\n",
        "\n",
        "    df_rel_ranking = drop_unnamed(df_rel_ranking)\n",
        "    df_rand_ranking = drop_unnamed(df_rand_ranking)\n",
        "    df_date_ranking = drop_unnamed(df_date_ranking)\n",
        "\n",
        "    df_rel_ranking.to_csv(\"rel_ranking_\" + business_id + \".csv\")\n",
        "    df_date_ranking.to_csv(\"date_ranking_\" + business_id + \".csv\")\n",
        "    df_rand_ranking.to_csv(\"rand_ranking_\" + business_id + \".csv\")\n",
        "\n",
        "    #destination = set_file_destination('', 'ranking', business_id)\n",
        "    upload_file(\"rel_ranking_\" + business_id + \".csv\", folder_id)\n",
        "    upload_file(\"date_ranking_\" + business_id + \".csv\", folder_id)\n",
        "    upload_file(\"rand_ranking_\" + business_id + \".csv\", folder_id)\n",
        "\n",
        "\n",
        "def create_folder_in_drive(gdrive, folder_name, parent_folder_id):\n",
        "  folder_metadata = {'title': folder_name,'mimeType': 'application/vnd.google-apps.folder',\n",
        "                    'parents': [{\"kind\": \"drive#fileLink\", \"id\": parent_folder_id}]\n",
        "                    }\n",
        "  folder = gdrive.CreateFile(folder_metadata)\n",
        "  folder.Upload()\n",
        "  print(folder)\n",
        "  # Return folder informations\n",
        "  print('title: %s, id: %s' % (folder['title'], folder['id']))\n",
        "  return folder['id']\n",
        "\n",
        "\n",
        "# DOWNLOAD risto2.txt FROM DRIVE\n",
        "restaurants_dataset_id = '1GMm3tvEkkNJnkNhNP9G3l6ibkUVG48nG'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': restaurants_dataset_id})\n",
        "download.GetContentFile('risto2.txt')\n",
        "with open('risto2.txt') as f:\n",
        "    content = f.readlines()\n",
        "restaurants_id_list = [x.strip() for x in content] \n",
        "\n",
        "print(restaurants_id_list)\n",
        "\n",
        "\n",
        "                                              # fairness_data folder id\n",
        "restaurant_folders = drive.ListFile({'q': \"'\" + '1p9X-C0p1191dYlRnrGUZZUkTXLymJ49_' + \"' in parents and trashed=false\"}).GetList()\n",
        "restaurant_folders_name = [folder['title'] for folder in restaurant_folders]\n",
        "\n",
        "numrest = 204\n",
        "id_lista = restaurants_id_list[numrest-1:]\n",
        "for id in id_lista:\n",
        "\n",
        "  download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "  download.GetContentFile('gtree.csv')\n",
        "  gtree = pd.read_csv('gtree.csv')\n",
        "  \n",
        "  if str(numrest)+' - '+id not in restaurant_folders_name:\n",
        "    gfolder_id = create_folder_in_drive(drive, str(numrest) + ' - ' + id, '1p9X-C0p1191dYlRnrGUZZUkTXLymJ49_')\n",
        "    gfolder_rankings = create_folder_in_drive(drive, '1_rankings', gfolder_id)\n",
        "    gfolder_groups = create_folder_in_drive(drive, '2_groups_exposure', gfolder_id)\n",
        "    new_row = {'business_id':id, 'gfolder_id':gfolder_id, 'gfolder_rankings':gfolder_rankings, \n",
        "                                'gfolder_groups':gfolder_groups, 'gfolder_#11':'', 'gfolder_#12':'',\n",
        "                                'gfolder_#14':'', 'gfolder_userphoto':'', 'gfolder_clarifai':'',\n",
        "                                'gfolder_#5':''}\n",
        "    gtree = gtree.append(new_row, ignore_index=True)\n",
        "    gtree = gtree.drop_duplicates('business_id',keep='last').reset_index(drop=True)\n",
        "    gtree = drop_unnamed(gtree)\n",
        "    gtree.to_csv('gtree.csv')\n",
        "    upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data\n",
        "    retrieve_rankings(id, gfolder_rankings)\n",
        "  numrest += 1\n",
        "  print(id)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['WbJ1LRQdOuYYlRLyTkuuxw', 'T2tEMLpTeSMxLKpxwFdS3g', 'ALwAlxItASeEs2vYAeLXHA', 'OVTZNSkSfbl3gVB9XQIJfw', 'Sovgwq-E-n6wLqNh3X_rXg', 'j5nPiTwWEFr-VsePew7Sjg', 'aiX_WP7NKPTdF9CfI-M-wg', 'e4NQLZynhSmvwl38hC4m-A', 'S-oLPRdhlyL5HAknBKTUcQ', 'VyVIneSU7XAWgMBllI6LnQ', 'pSQFynH1VxkfSmehRXlZWw', 'JzOp695tclcNCNMuBl7oxA', 'OgJ0KxwJcJ9R5bUK0ixCbg', '3l54GTr8-E3XPbIxnF_sAA', '9a3DrZvpYxVs3k_qwlCNSw', 'frCxZS7lPhEnQRJ3UY6m7A', 'yNPh5SO-7wr8HPpVCDPbXQ', '0FUtlsQrJI7LhqDPxLumEw', 'K-uQkfSUTwu5LIwPB4b_vg', 'L2p0vO3fsS2LC6hhQo3CzA', 'd10IxZPirVJlOSpdRZJczA', 'wUKzaS1MHg94RGM6z8u9mw', 'z6-reuC5BYf_Rth9gMBfgQ', '0CjK3esfpFcxIopebzjFxA', '3C5Z9homtzkWHouH2BHXYQ', 'C8D_GU9cDDjbOJfCaGXxDQ', 'Yl05MqCs9xRzrJFkGWLpgA', 'eS29S_06lvsDW04wVrIVxg', 'IsoLzudHC50oJLiEWpwV-w', '3N9U549Zse8UP-MwKZAjAQ', '_XN-GwzZwAyIqLKJsl2htg', 'r5PLDU-4mSbde5XekTXSCA', 'Iq7NqQD-sESu3vr9iEGuTA', 'u-SJ5QUwrNquL9VnXwl8cg', 'sJNcipFYElitBrtiJx0ezQ', '7m1Oa1VYV98UUuo_6i0EZg', 'WIhm0W9197f_rRtDziq5qQ', 'k1QpHAkzKTrFYfk6u--VgQ', '-6tvduBzjLI1ISfs3F_qTg', 'jcasci3gjbsSuTEVzvDQKg', 'Ch7NAhB_MWSDwcNbcptEKg', 'eZDXz_RylvdD0tHEA8I0NA', 'tCSlpwJQ4CZsUEMZeH2SFg', 'yWUBX9Pe6pzh1PjVj04UmQ', 'k-drEjxKmfqllwfY90STfA', 'y1eeVRfJa22CCpUCeNfrSw', 'VH3WA7a-OVzFj2K_SP4BIw', 'osSwv6CJy5hDKQdOKeyTow', 'o5QDrg_kb4hgsWxV6cV_Uw', 'XgRljuEUyaHBKIpIz-PRAA', 'wArcCMVnrl_tc9MULW-0CQ', 'SHFlELFcEcAOJv_fTAKChQ', 'aBLx9JlAMq_AuW6VAImSwg', 'd8lmIZIqmBC9oPM8y1dc7Q', 'bzbNGyrTwWHAgg1CqkSgeg', 'ADgacmZ-qXrSOhMfU6bmTA', 'gChmBjLSe3qa8rzEngoDLQ', 'D2ojX9bvE0_-aIj9BhdZZA', 'hggVnGwA5042-ABxqeJX-A', '9dqdzRzjSfbnMvjUGqWBAw', 'DyOzNIeXUksPNLXYHnB-oQ', 'mC39IrCp36QIVFRZIw9PTQ', 'sdYkVaTy7EJwUkO8Ie_qPg', 'a0IET3_yCFcO36OqGSsisg', '01fuY2NNscttoTxOYbuZXw', 'QbAfrOxbuYKU248SDXHZEQ', 'RVQE2Z2uky4c0-njFQO66g', 'UA2M9QFZghe-9th2KwLoWQ', 'RAh9WCQAuocM7hYM5_6tnw', '3kdSl5mo9dWC4clrQjEDGg', '7sPNbCx7vGAaH7SbNPZ6oA', 'Cni2l-VKG_pdospJ6xliXQ', 'DkYS3arLOhA8si5uUEmHOw', 'f4x1YBxkLrZg652xt2KR5g', 'faPVqws-x-5k2CQKDNtHxw', 'fL-b760btOaGa85OJ9ut3w', 'G-5kEa6E6PD5fkBRuA7k9Q', 'g8OnV26ywJlZpezdBnOWUQ', 'HhVmDybpU7L50Kb5A0jXTg', 'hihud--QRriCYZw1zZvW4g', 'IWN2heYitkg-D4UdqfxcMA', 'JDZ6_yycNQFTpUZzLIKHUg', 'JpgVl3d20CMRNjf1DVnzGA', 'mDR12Hafvr84ctpsV6YLag', 'NvKNe9DnQavC9GstglcBJQ', 'OETh78qcgDltvHULowwhJg', 'P7pxQFqr7yBKMMI2J51udw', 'pH0BLkL4cbxKzu471VZnuA', 'QJatAcxYgK1Zp9BRZMAx7g', 'QXV3L_QFGj8r6nWX2kS2hA', 'RwMLuOkImBIqqYj4SSKSPg', 'ujHiaprwCQ5ewziu0Vi9rw', 'UPIYuRaZvknINOd1w8kqRQ', 'xkVMIk_Vqh17f48ZQ_6b0w', 'XXW_OFaYQkkGOGniujZFHg', 'XZbuPXdyA0ZtTu3AzqtQhg', 'yfxDa8RFOvJPQh0rNtakHA', 'YJ8ljUhLsz6CtT_2ORNFmg', 'ZkGDCVKSdf8m76cnnalL-A', 'NFm869_w6cvVaWaNpAzjeA', 'aO1gAp41n8w8zpxTiHdLNA', 'yMopev-RPxfEXgqkJOvCGA', 'MU66syW7PEAKbsWCSw8h4A', 'Uftnd7njdHNFxhz_6rpUrA', 'L8rJht4Jw_BuR8gsckEWYg', 'tTEtAzGbydufWtgOqCMquA', '22MYhTXwSXaS4rW2VOrR-w', 'MQEpDvkdL39hh1N0We3Vaw', 'eZDXz_RylvdD0tHEA8I0NA', 'TTFbaLpIwrjFx7YIL2pbJA', 'YOy1tOiMMOkrCQ4mO2i3eQ', 'tCSlpwJQ4CZsUEMZeH2SFg', 'tInrGCzll4k9hF34Ye1rvQ', '2um9bzTSvD3f2tkdBoA38g', 'LQI8R7yYXmWzWKd7wLCf2Q', 'WCqcYtJ4rUxA4bIzjOfzqg', 'bKKVa2WXYnMTtiUPd3sV7Q', 'R1jJQi2yR44D_2ileqr8kA', '4JNXUYY8wbaaDmk3BPzlWw', 'vHz2RLtfUMVRPFmd7VBEHA', 'iCQpiavjjPzJ5_3gPD5Ebg', 'rcaPajgKOJC2vo_l3xa42A', 'KskYqH1Bi7Z_61pH6Om8pg', '7sb2FYLS2sejZKxRYF9mtg', 'l_GV0hgEoTUf70uJVT0_hg', 'eLFfWcdb7VkqNyTONksHiQ', 'PXShA3JZMXr2mEH3on5clw', 'eJKnymd0BywNPrJw1IuXVw', 'SVGApDPNdpFlEjwRQThCxA', 'xVEtGucSRLk5pxxN0t4i6g', 'kRgAf6j2y1eR0wOFdzFAuw', 'nUpz0YiBsOK7ff9k3vUJ3A', 'ugLqbAvBdRDc-gS4hpslXw', 'uuGL8diLlHfeUeFuod3F-w', 'JPfi__QJAaRzmfh5aOyFEw', 'uW6UHfONAmm8QttPkbMewQ', '-ed0Yc9on37RoIoG2ZgxBA', 'GmdujALb1Nq2RHGr7jhCaA', 'beuVp5CZxCdNvQIIPBS2rw', 'oXoVJ0xKv82cBo9U6oEjlQ', 'eaNenRk_liZBERFFLCXqqQ', '_w5hBpkjHs5_Hv3pLeHtIw', 'gx2yPrOJSwF1ApJYdGBWIw', 'JyxHvtj-syke7m9rbza7mA', 'wl0QZqAzr1DelslQ02JGCQ', 'thLX_k20SPJ0KyusGTBIHw', 'LelAlfuj5oVRF9CQdWLsNQ', 'fKlr9qNoV37WQJwQ826POg', '9MVKjEMN5T59uzG1xoD2BQ', '5FIOXmUE3qMviX9GafGH-Q', 'ZCzey5aPhd7jYIoHsUfjmQ', 'XMMLRvV4IMxIGyc4H37LxA', 'mnwRtuVQEsIUomBchu0gwg', 'J07TDs6qnTIaxm48EL1cKQ', 'SurnOSM2bVVN4-Js3G23RQ', 'ohEnmKpF7i2_ujme1p_vUQ', 'j2bx_ctb_ED3zbfSaqhQmQ', 'cTJjTKz2huGZ-ElScC2pSw', 'cKgUCzMGuRgkbKXUsgeXUw', 'FsCujpVh9Za2Dl5MIYLCxA', 'fT6Uwl6abRQfiNgxre_qbg', 'N8uKQ5Vdb1LAh-qXT_25Rg', '2ggi1luerd3Mf_C82JvCYg', 'HfJhenvKDi-ds8SUJFwrLg', '_tHF8-3rbyMesgdkQzB2yQ', 'xt4sa64WOrpJvZBDPNPNYg', 'nI1UYDCYUTt23TpGxqnLKg', 'vyoA8dxwScuMV_AsTcjQcg', '22nKUyCIbpnzR6R3_g1ptQ', 'TN4RnyqHMSupRFot4Q-_EA', 'pfmAcS-g6SiNG0KlLvrqnA', 'C8j0q4Ma_S5hBGuAI-aaww', 'fxGpXRxFUDzlU3Cyszu4uQ', 'zj8Lq1T8KIC5zwFief15jg', 'kBZggrnSP1kcUMnsnfkTaQ', 'B3_K2kUVbYOU0VaLcj_LTw', 'NOh24SMS6k4pzNv8Ds7KDg', 'KgpOYAG-r_eDsQXFXt0nnQ', 'mQX9JxLMlhVxaUMP9ADUHw', 't1w4qyqyfEdTPhoy-5t3FA', 'b8a-8u_A51v2IzyjLVsx6w', 'jnEv25Y2DosTq2sNnvmC9g', 'dMhRafXdr765DHe0k-QfaQ', 'veq1Bl1DW3UWMekZJUsG1Q', 'FhXjAc6nKLf414KxYujUHw', 'QObHX0yR6zd0WfksRDbJTA', 'ETgJqJHV7BW6pIr9Ox74sA', 'IhSVn0TaX8xXb3wcQ-fgcA', 'C-8mGN7lt5rIraO5n-15ug', 'ogCC-lJJYnwXDvKGmKZ6Sw', 'TU_BU9HLflYI2xlyqVQdRA', 'uc5qQMzs96rzjK27epDCug', 'iBm8YTqNwrddsxWdqLPK-A', 'vRrVSB-LegwUwIxpkeRVtQ', 'MhceeLrM2_3mcKw5EGLY6A', 'Rc1lxc5lSKJYd162JHNMfQ', 'LvzN8TrUGJRj_UkJV0cAtQ', 'cCesIqo-LQt0cRlZAnrAZQ', '1Ed-tb_0dBGrXfsYyehmvg', '-hUvO0C0A-pGZdiSKvjoFw', 'L-IuiVoFMDSw2K6OAciP1g', 'B55Ocx5RBWxo6AGSucYSIA', 'FH978pIP1TLRuPAH-MbWIQ', 'dMU62c3NKm7AFy90sA-Xtw', 'DoSU8IPq-Py_YV3kYmXPfQ', '0L03onqNwxWLrbb_FCK79A', 'al9HKZ3kCJipAJW4uxzj4A', 'OwV-MtDBC2H08rVcBqP2mA', 'JEQ00qBAepe0oSiUBdfIew', 'WG639VkTjmK5dzydd1BBJA', '44SY464xDHbvOcjDzRbKkQ']\n",
            "dMU62c3NKm7AFy90sA-Xtw\n",
            "DoSU8IPq-Py_YV3kYmXPfQ\n",
            "0L03onqNwxWLrbb_FCK79A\n",
            "al9HKZ3kCJipAJW4uxzj4A\n",
            "OwV-MtDBC2H08rVcBqP2mA\n",
            "JEQ00qBAepe0oSiUBdfIew\n",
            "WG639VkTjmK5dzydd1BBJA\n",
            "44SY464xDHbvOcjDzRbKkQ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O6PjjOHV0y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "###################### DOWNLOAD USER PHOTOS ####################################\n",
        "\n",
        "\n",
        "def scarica_tutti_utenti(business_id, df_utenti, photo_folder_id, startfrom):\n",
        "  df_utenti = df_utenti[startfrom:]\n",
        "  cnt = startfrom\n",
        "  for a, user in df_utenti.iterrows():\n",
        "    user_id = user['user_id']\n",
        "    completed = downloadUser(business_id, user_id, photo_folder_id, cnt)\n",
        "    if not completed:\n",
        "      print('ULTIMO SCARICATO:', cnt)\n",
        "      return False\n",
        "    print(cnt)\n",
        "    cnt = cnt + 1\n",
        "\n",
        "\n",
        "# DOWNLOAD restaurants.txt FROM DRIVE\n",
        "restaurants_dataset_id = '1BqMsph8flQMGmcE_WxYV0vSC_uqi-nge'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': restaurants_dataset_id})\n",
        "download.GetContentFile('restaurants.txt')\n",
        "with open('restaurants.txt') as f:\n",
        "    content = f.readlines()\n",
        "restaurants_id_list = [x.strip() for x in content] \n",
        "\n",
        "print(restaurants_id_list)\n",
        "\n",
        "\n",
        "numrest = 18\n",
        "id_lista = restaurants_id_list[(numrest-1):(numrest)]\n",
        "starting_from_photo = 2299\n",
        "\n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "gtree = pd.read_csv('gtree.csv')\n",
        "\n",
        "for id in id_lista:\n",
        "  print(id)\n",
        "  user_ranking_folder = gtree.loc[gtree['business_id']==id, 'gfolder_rankings'].tolist()[0]\n",
        "  ranking_file = drive.ListFile({'q': \"'\" + user_ranking_folder + \"' in parents and trashed=false\"}).GetList()[0]  \n",
        "  download = drive.CreateFile({'id': ranking_file['id']})\n",
        "  download.GetContentFile('ranking_' + id + '.csv')\n",
        "  ranking = pd.read_csv('ranking_' + id + '.csv')\n",
        "  if starting_from_photo == 0:\n",
        "    id_cartella = create_folder_in_drive(drive, str(numrest) + ' - ' + id,\n",
        "                                         '12OKc1s2VeJRv5kUS_fp9f4dFLn1LkSPG')  # folder face_data>Foto_User\n",
        "    gtree.loc[gtree['business_id']==id, 'gfolder_userphoto'] = id_cartella\n",
        "    gtree = gtree.drop_duplicates('business_id',keep='last').reset_index(drop=True)\n",
        "    gtree = drop_unnamed(gtree)\n",
        "    gtree.to_csv('gtree.csv')\n",
        "    upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data\n",
        "  else:\n",
        "    id_cartella = gtree.loc[gtree['business_id']==id, 'gfolder_userphoto'].tolist()[0]\n",
        "  \n",
        "  success = scarica_tutti_utenti(id, ranking[['user_id']], id_cartella, starting_from_photo)\n",
        "  if not success:\n",
        "    print('RISTORANTE:',id)\n",
        "    print(numrest)\n",
        "    break\n",
        "  else:\n",
        "    print(numrest)\n",
        "    print('FINE DOWNLOAD RISTORANTE ' + id)\n",
        "    numrest += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4CE8fLjjUZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "################## DOWNLOAD MISSING USER PHOTO #################################\n",
        "\n",
        "import json\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def scarica_utenti_mancanti(business_id, df_utenti, photo_folder_id):\n",
        "  cnt=0\n",
        "  proxy_list = get_proxies()\n",
        "  for user_id in df_utenti:\n",
        "    if proxy_list == []:\n",
        "      print(\"Nessun proxy disponibile\")\n",
        "      print(\"Ultimo utente non scaricato perché finiti i proxy: \" + user_id)\n",
        "      break\n",
        "    else:\n",
        "      downloadUser(business_id, user_id, photo_folder_id, cnt, proxy_list)\n",
        "      print(cnt)\n",
        "      cnt = cnt + 1\n",
        "\n",
        "\n",
        "# DOWNLOAD risto2.txt FROM DRIVE\n",
        "restaurants_dataset_id = '1GMm3tvEkkNJnkNhNP9G3l6ibkUVG48nG'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': restaurants_dataset_id})\n",
        "download.GetContentFile('risto2.txt')\n",
        "with open('risto2.txt') as f:\n",
        "    content = f.readlines()\n",
        "restaurants_id_list = [x.strip() for x in content] \n",
        "\n",
        "print(restaurants_id_list)\n",
        "\n",
        "numrest = 104\n",
        "while numrest<105:\n",
        "\n",
        "  id = restaurants_id_list[(numrest-1):(numrest)][0]\n",
        "  download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "  download.GetContentFile('gtree.csv')\n",
        "  gtree = pd.read_csv('gtree.csv')\n",
        "\n",
        "  print(id)\n",
        "  user_photo_folder = gtree.loc[gtree['business_id']==id, 'gfolder_userphoto'].tolist()[0]\n",
        "  if str(user_photo_folder)=='nan':\n",
        "    id_cartella = create_folder_in_drive(drive, str(numrest) + ' - ' + id,\n",
        "                                  '12OKc1s2VeJRv5kUS_fp9f4dFLn1LkSPG')  # folder face_data>Foto_User\n",
        "    gtree.loc[gtree['business_id']==id, 'gfolder_userphoto'] = id_cartella\n",
        "    gtree = gtree.drop_duplicates('business_id',keep='last').reset_index(drop=True)\n",
        "    gtree = drop_unnamed(gtree)\n",
        "    gtree.to_csv('gtree.csv')\n",
        "    upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data\n",
        "\n",
        "  user_photo_folder = gtree.loc[gtree['business_id']==id, 'gfolder_userphoto'].tolist()[0]\n",
        "  \n",
        "  photo_list = drive.ListFile({'q': \"'\" + user_photo_folder + \"' in parents and trashed=false\"}).GetList() \n",
        "  user_id_list2 = [photo['title'][0:22] for photo in photo_list]\n",
        "  print(user_id_list2)\n",
        "\n",
        "  user_ranking_folder = gtree.loc[gtree['business_id']==id, 'gfolder_rankings'].tolist()[0]\n",
        "  ranking_file = drive.ListFile({'q': \"'\" + user_ranking_folder + \"' in parents and trashed=false\"}).GetList()[0]  \n",
        "  download = drive.CreateFile({'id': ranking_file['id']})\n",
        "  download.GetContentFile('ranking_' + id + '.csv')\n",
        "  ranking = pd.read_csv('ranking_' + id + '.csv')\n",
        "  user_id_list = ranking['user_id'].values.tolist()\n",
        "  print(user_id_list)\n",
        "\n",
        "  difference = (list(set(user_id_list) - set(user_id_list2)))\n",
        "\n",
        "  print('Utenti mancanti:', len(difference))\n",
        "  print(difference)\n",
        "  if difference:\n",
        "    try:\n",
        "      scarica_utenti_mancanti(id, difference, user_photo_folder)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      print('ERRORE RISTORANTE:',id)\n",
        "      print(numrest)\n",
        "  else:\n",
        "    print(numrest)\n",
        "    print('FINE DOWNLOAD RISTORANTE ' + id)\n",
        "    numrest += 1\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUpRexALXusT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def restart_runtime():\n",
        "  os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuTTwMxTYKxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "################ ELABORATE USER PHOTOS WITH CLARIFAI ###########################\n",
        "\n",
        "def detect_clarifai(id, url_photo):\n",
        "  app = ClarifaiApp(api_key='e0dfe3e7a4cd4bfd8df072fdd2a1789c')\n",
        "  model = app.models.get(model_id=\"c0c0ac362b03416da06ab3fa36fb58e3\")\n",
        "  response = model.predict_by_url(url = '%s' % url_photo)\n",
        "  \n",
        "  df_result = pd.DataFrame(columns=['user_id', 'age', 'gender', 'ethnicity'])\n",
        "\n",
        "  if response['outputs'][0]['data'] != {}:\n",
        "    x = 0\n",
        "    while (x < len(response['outputs'][0]['data']['regions'])):\n",
        "      age = response['outputs'][0]['data']['regions'][x]['data']['concepts'][0]['name']\n",
        "      gender = response['outputs'][0]['data']['regions'][x]['data']['concepts'][20]['name']\n",
        "      ethnicity = response['outputs'][0]['data']['regions'][x]['data']['concepts'][22]['name']\n",
        "\n",
        "      new_row = {'user_id':id,\n",
        "                 'age':age,\n",
        "                 'gender':gender,\n",
        "                 'ethnicity':ethnicity}\n",
        "      df_result = df_result.append(new_row, ignore_index=True)\n",
        "      x = x + 1\n",
        "  else:\n",
        "    new_row = {'user_id':id,\n",
        "              'age':np.NaN,\n",
        "              'gender':np.NaN,\n",
        "              'ethnicity':np.NaN}\n",
        "    df_result = df_result.append(new_row, ignore_index=True)\n",
        "  return df_result\n",
        "\n",
        "\n",
        "# LEGGO GTREE\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "gtree = pd.read_csv('gtree.csv')\n",
        "gtree = drop_unnamed(gtree)\n",
        "id_clarifai_folder = '1wfZ0d3cTufosLRhPKkShf7kQbJlUbBvH' # folder data > Clarifai\n",
        "\n",
        "# DOWNLOAD restaurants.txt FROM DRIVE\n",
        "restaurants_dataset_id = '1BqMsph8flQMGmcE_WxYV0vSC_uqi-nge'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': restaurants_dataset_id})\n",
        "download.GetContentFile('restaurants.txt')\n",
        "with open('restaurants.txt') as f:\n",
        "    content = f.readlines()\n",
        "restaurants_id_list = [x.strip() for x in content] \n",
        "\n",
        "print(restaurants_id_list)\n",
        "\n",
        "numrest = 83\n",
        "id_restaurant = restaurants_id_list[(numrest-1):(numrest)][0]\n",
        "startfrom = 2796  # BE CAREFUL, IF 0 OVERWRITE THE CSV IN DRIVE\n",
        "\n",
        "id_photo_folder = gtree.loc[gtree['business_id'] == id_restaurant, 'gfolder_userphoto'].tolist()[0]\n",
        "print(id_restaurant)\n",
        "print(id_photo_folder)\n",
        "\n",
        "if startfrom == 0:\n",
        "  df_clarifai = pd.DataFrame(columns=['user_id', 'age', 'gender', 'ethnicity'])\n",
        "  df_clarifai.to_csv(str(numrest) + ' - ' + id_restaurant + '.csv')\n",
        "  id_new_file = upload_file(str(numrest) + ' - ' + id_restaurant + '.csv', id_clarifai_folder)\n",
        "  gtree.loc[gtree['business_id']==id_restaurant, 'gfolder_clarifai'] = id_new_file\n",
        "  gtree.to_csv('gtree.csv')\n",
        "  upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD')\n",
        "else:\n",
        "  id_clarifai_file = gtree.loc[gtree['business_id']==id_restaurant, 'gfolder_clarifai'].tolist()[0]\n",
        "  print(id_clarifai_file)\n",
        "  download = drive.CreateFile({'id': id_clarifai_file})\n",
        "  download.GetContentFile(str(numrest) + ' - ' + id_restaurant + '.csv')\n",
        "  df_clarifai = pd.read_csv(str(numrest) + ' - ' + id_restaurant + '.csv')\n",
        "\n",
        "file_list = drive.ListFile({'q': \"'\" + id_photo_folder + \"' in parents and trashed=false\"}).GetList()    #cartella da cui prendo le foto\n",
        "\n",
        "count = 0\n",
        "\n",
        "for photo in file_list[startfrom:]:\n",
        "  user_id = photo['title'][0:22] \n",
        "  count = count + 1\n",
        "  if user_id not in df_clarifai['user_id'].values:\n",
        "    minidf_result = detect_clarifai(user_id, photo['thumbnailLink'])\n",
        "    df_clarifai = df_clarifai.append(minidf_result, ignore_index=True)\n",
        "    df_clarifai = drop_unnamed(df_clarifai)\n",
        "    if count == 100:\n",
        "      count = 0\n",
        "      df_clarifai.to_csv(str(numrest) + ' - ' + id_restaurant + '.csv')\n",
        "      id_new_file = upload_file(str(numrest) + ' - ' + id_restaurant + '.csv', id_clarifai_folder)\n",
        "      print('csv caricato: ' + id_new_file)\n",
        "      \n",
        "    print(startfrom)\n",
        "    startfrom = startfrom + 1\n",
        "  else:\n",
        "    if count == 100:\n",
        "      count = 0\n",
        "    print(str(startfrom) + ' già fatto')\n",
        "    startfrom = startfrom + 1\n",
        "      \n",
        "df_clarifai.to_csv(str(numrest) + ' - ' + id_restaurant + '.csv')\n",
        "id_new_file = upload_file(str(numrest) + ' - ' + id_restaurant + '.csv', id_clarifai_folder)\n",
        "print('csv caricato: ' + id_new_file) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3g-ePyz_VHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "############################### CHECK NUMBERS ##################################\n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "gtree = pd.read_csv('gtree.csv')\n",
        "gtree = drop_unnamed(gtree)\n",
        "\n",
        "# DOWNLOAD restaurants.txt FROM DRIVE\n",
        "restaurants_dataset_id = '1BqMsph8flQMGmcE_WxYV0vSC_uqi-nge'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': restaurants_dataset_id})\n",
        "download.GetContentFile('restaurants.txt')\n",
        "with open('restaurants.txt') as f:\n",
        "    content = f.readlines()\n",
        "restaurants_id_list = [x.strip() for x in content] \n",
        "\n",
        "print(restaurants_id_list)\n",
        "\n",
        "numero_risto = 78\n",
        "\n",
        "while numero_risto < 85:\n",
        "  print(numero_risto)\n",
        "  id_risto = restaurants_id_list[(numero_risto-1):(numero_risto)][0]\n",
        "  print(id_risto)\n",
        "\n",
        "  ########################## RANKING ##############################\n",
        "  user_ranking_folder = gtree.loc[gtree['business_id']==id_risto, 'gfolder_rankings'].tolist()[0]\n",
        "  ranking_file = drive.ListFile({'q': \"'\" + user_ranking_folder + \"' in parents and trashed=false\"}).GetList()[0]  \n",
        "  download = drive.CreateFile({'id': ranking_file['id']})\n",
        "  download.GetContentFile('ranking_' + id_risto + '.csv')\n",
        "  file_ranking = pd.read_csv('ranking_' + id_risto + '.csv')\n",
        "  ranking_lista = file_ranking['user_id'].values.tolist()\n",
        "\n",
        "  ########################## PHOTO ##############################\n",
        "  user_photo_folder = gtree.loc[gtree['business_id']==id_risto, 'gfolder_userphoto'].tolist()[0]\n",
        "  photo_lista = drive.ListFile({'q': \"'\" + user_photo_folder + \"' in parents and trashed=false\"}).GetList() \n",
        "  photo_lista = [photo['title'][0:22] for photo in photo_lista]\n",
        "  seen = set()\n",
        "  print('duplicates:')\n",
        "  for x in photo_lista:\n",
        "    if x not in seen:\n",
        "        seen.add(x)\n",
        "    else:\n",
        "      print(x)\n",
        "\n",
        "  ########################## CLARIFAI ##############################\n",
        "  user_clarifai_id = gtree.loc[gtree['business_id']==id_risto, 'gfolder_clarifai'].tolist()[0]\n",
        "  download = drive.CreateFile({'id': user_clarifai_id})\n",
        "  download.GetContentFile('clarifai_' + id_risto + '.csv')\n",
        "  file_clarifai = pd.read_csv('clarifai_' + id_risto + '.csv')\n",
        "  clarifai_without_duplicates = file_clarifai.drop_duplicates(subset=('user_id')).reset_index()\n",
        "  clarifai_lista = clarifai_without_duplicates['user_id'].values.tolist()\n",
        "\n",
        "  print('tot ranking = tot foto = tot clarifai')\n",
        "  tot_ranking = len(file_ranking.index)\n",
        "  tot_foto = len(photo_lista)\n",
        "  tot_clarifai = len(clarifai_without_duplicates.index)\n",
        "  toomuch = False\n",
        "  print(str(tot_ranking) + ' = ' + str(tot_foto) + ' = ' + str(tot_clarifai))\n",
        "  #if tot_ranking!=tot_foto or tot_ranking!=tot_clarifai or tot_foto!=tot_clarifai:\n",
        "  print('FOTO CHE NON STANNO NEL RANKING:')\n",
        "  for unid in photo_lista:\n",
        "    if unid not in ranking_lista:\n",
        "      print(unid)\n",
        "  print('FOTO ANCORA DA SCARICARE (CHE STANNO NEL RANKING):')\n",
        "  for unid in ranking_lista:\n",
        "    if unid not in photo_lista:\n",
        "      print(unid)\n",
        "  print('CLARIFAI ANCORA DA ELABORARE (CHE STANNO NEL RANKING):')\n",
        "  for unid in ranking_lista:\n",
        "    if unid not in clarifai_lista:\n",
        "      print(unid)\n",
        "  print('CLARIFAI CHE NON STANNO NEL RANKING:')\n",
        "  for unid in clarifai_lista:\n",
        "    if unid not in ranking_lista:\n",
        "      print(unid)\n",
        "      toomuch = True\n",
        "      file_clarifai = file_clarifai[file_clarifai['user_id'] != unid]\n",
        "  if toomuch:\n",
        "    file_clarifai = drop_unnamed(file_clarifai)\n",
        "    file_clarifai.to_csv(str(numero_risto) + ' - ' + id_risto + '.csv')\n",
        "    upload_file(str(numero_risto) + ' - ' + id_risto + '.csv', '1wfZ0d3cTufosLRhPKkShf7kQbJlUbBvH')\n",
        "  numero_risto += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uADbgKK-9U9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#################### MODIFY SOME VALUES IN GTREE ###############################\n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "df = pd.read_csv('gtree.csv')\n",
        "df = drop_unnamed(df)\n",
        "\n",
        "#BE CAREFUL AT THE INDEX\n",
        "#indice = 31  # IF RESTAURANT 20, THEN 10 IN GTREE\n",
        "#df.loc[indice, 'business_id'] = ''\n",
        "#df.loc[indice, 'gfolder_id'] = ''\n",
        "#df.loc[indice, 'gfolder_rankings'] = ''\n",
        "#df.loc[indice, 'gfolder_groups'] = ''\n",
        "#df.loc[indice, 'gfolder_userphoto'] = ''\n",
        "#df.loc[indice, 'gfolder_clarifai'] = ''\n",
        "df.loc[df['business_id']=='pSQFynH1VxkfSmehRXlZWw', 'gfolder_#14'] = '1trP01BYem2Qc0enPnmxwRmKdKR-lU7G3'\n",
        "#df.loc[df['business_id']=='RwMLuOkImBIqqYj4SSKSPg', 'gfolder_userphoto'] = '1KtHm3_fXyGReGZ1zIIhmKXhAjMLwhlei'\n",
        "#df.loc[df['business_id']=='ujHiaprwCQ5ewziu0Vi9rw', 'gfolder_userphoto'] = '1PsSO6dcpfj20frHxMrmDgDEf4in5pWcL'\n",
        "\n",
        "gtree = drop_unnamed(df)\n",
        "gtree.to_csv('gtree.csv')\n",
        "upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRNS1d5oV_3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "######################## INSERT ONE ROW IN GTREE ###############################\n",
        "\n",
        "def Insert_row(row_number, df, row_value):\n",
        "    start_upper = 0\n",
        "    end_upper = row_number\n",
        "    start_lower = row_number\n",
        "    end_lower = df.shape[0]\n",
        "    upper_half = [*range(start_upper, end_upper, 1)]\n",
        "    lower_half = [*range(start_lower, end_lower, 1)]\n",
        "    lower_half = [x.__add__(1) for x in lower_half]\n",
        "    index_ = upper_half + lower_half\n",
        "    df.index = index_\n",
        "    df.loc[row_number] = row_value\n",
        "    df = df.sort_index()\n",
        "    return df \n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "df = pd.read_csv('gtree.csv')\n",
        "print(df)\n",
        "df = drop_unnamed(df)\n",
        " \n",
        "row_number = 66\n",
        "row_value = ['fL-b760btOaGa85OJ9ut3w', '1DhrpTWJygfaPrYkHNH1xuz-HxWZBZe__',\n",
        "             '1Vm5kyWMQQCSMBLSGpDwVfHIR4bp5-JIt', '19bUEYHBUGKxt7DjStk0qJIlqq4NKslw8',\n",
        "             '','','','','']\n",
        "  \n",
        "if row_number > df.index.max()+1: \n",
        "  print(\"Invalid row_number\") \n",
        "else:\n",
        "  df = Insert_row(row_number, df, row_value) \n",
        "  print(df[row_number-1:])\n",
        "\n",
        "gtree = drop_unnamed(df)\n",
        "gtree.to_csv('gtree.csv')\n",
        "upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzJX2f82v1e_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "##################### INSERT ROWS AT BEGIN IN GTREE ############################\n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "gtree = pd.read_csv('gtree.csv')\n",
        "\n",
        "values = [['WbJ1LRQdOuYYlRLyTkuuxw','1DFANWg2Io81FaV_GxlwBWfpG9Bx-Dgr7','1U0Ml5puObfOk3qHCKhO9bQ06WyhJoffW','1Ba-IYi1icz5tuO_AYN-f-FvjXjA5NmJi','','','','19r7YGFp7oAqItv63TZOPyAt4hDa_UyRr',''],\n",
        "          ['T2tEMLpTeSMxLKpxwFdS3g','1ENW6Pyiyt7v6p54Uhn9zrM9HQ28MB1-G','136FZ0Y90Zx-4UYDyW50cX8zUa_DhN3XS','1wAgWQ6Vmy3fe-RJ8_Ezwow75ftvOFP5_','','','','1f1NhSvHMwyJOxIrGbDix1lQ5NN4eHoG4',''],\n",
        "          ['ALwAlxItASeEs2vYAeLXHA','1oEws_0F-s4hS6CpBxqxuzoJ2Wo-Nf8eL','12zXi3XyQaNgukGHW_805cyrkHhSdF7Df','1lZKqsV-sTAEOnLv-MQxpdao7eBWkjKP1','','','','1mWA3-mH9Kl0Xho24he8__4nZJBVPx9Qh',''],\n",
        "          ['OVTZNSkSfbl3gVB9XQIJfw','1hgql_Ey5epZKj-SuB4F5Fu1eYOd2P8RX','1ZyNQavpG0akr3ca3PJjjl_D89IA5wlcc','1-drKKIaitJ0tjEY1W80B3kRXI5Ive5lC','','','','1OqlKSXZUvZCOOmTAONENS9Sq0twMCRM8',''],\n",
        "          ['Sovgwq-E-n6wLqNh3X_rXg','10fJv8tOFOwBiAZBVEedsqxi3g6zYLxjD','1EZqvt9x5PN07BgUad1RtNIUXTVqujA0g','1QcSsJsvQne8a9jMvL9_1VAmeGIrsq8R8','','','','1ArjfNsamdhSpG7BJwnJZ_qULh_aklp62',''],\n",
        "          ['j5nPiTwWEFr-VsePew7Sjg','1yRDL_lrQFsCijdyvDssRgdZ5a2wyjCXj','18bQVXYZ03vIpfEFLPh8I2i7cPTlokGxv','1VysI0VkliBEU8Y1sCX0PU9eKYE6GaCzC','','','','1KW9VPvY33rbkgPfzrREpxMfSQJg4xxoL',''],\n",
        "          ['aiX_WP7NKPTdF9CfI-M-wg','1lQu_nXTCrzMFOm3uuXmCNVzx0PmYv0Of','1nl6A997UnuR5ceYRZS1242JJCvK-Sf_u','12Z4PEBlcTkz6kjeJ0JYRKI3WCrjRi4bF','','','','11H38dweaCKJ4-TD88nuzV70lMF5n4yzG',''],\n",
        "          ['e4NQLZynhSmvwl38hC4m-A','1f3bGHoK6Hy44pKRqSsnhN8KM-W3AAChW','1K566Y5Q2N6Lw7S6yDicKC_R-zFVRqnFr','1reeSQL8MfkxOQg-NsVxazVdKfG1XNPEF','','','','1fVLmOBbg44H8q_UcwAOQiX6CeN6hf84Z',''],\n",
        "          ['S-oLPRdhlyL5HAknBKTUcQ','1bG_50_Yyh9vq7YDQ3zSNTqS4acm1Cs7x','1FJqfJgaJinXS3oIvdA53FMuO9O7bCDVn','17QEFZUC_rhrLk9mSDXoegq7TSCI2_JLS','','','','1CMUT4RhSeuPi0j4VGoLCe-iP9-Aj5Fsy','']]\n",
        "          \n",
        "df1=pd.DataFrame(values, columns=['business_id', 'gfolder_id', 'gfolder_rankings', \n",
        "                              'gfolder_groups', 'gfolder_#11', 'gfolder_#12',\n",
        "                              'gfolder_#14','gfolder_userphoto','gfolder_clarifai'])\n",
        "df2=gtree\n",
        "\n",
        "df3 = pd.concat([df1, df2]).reset_index(drop=True)\n",
        "df3 = drop_unnamed(df3)\n",
        "print(df3)\n",
        "df3.to_csv('gtree.csv')\n",
        "gtree = drop_unnamed(gtree)\n",
        "print(gtree)\n",
        "upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_T7KPQkFat3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "##################### ADD AND REORDER COLUMNS IN GTREE #########################\n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "gtree = pd.read_csv('gtree.csv')\n",
        "\n",
        "gtree['#restaurant'] = gtree.index + 1\n",
        "cols = gtree.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "gtree = gtree[cols]\n",
        "\n",
        "gtree = drop_unnamed(gtree)\n",
        "print(gtree)\n",
        "upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuU0JHYLcrYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "############################### PROXY ROTATION #################################\n",
        "\n",
        "import requests\n",
        "import random\n",
        "\n",
        "url = 'https://httpbin.org/ip'\n",
        "\n",
        "\n",
        "# DOWNLOAD ip_addresses.txt FROM DRIVE\n",
        "ip_addresses_file_id = '186-JlWVZMz4YH6jwpvYMrJ4uHQAxbOCl'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': ip_addresses_file_id})\n",
        "download.GetContentFile('ip_addresses.txt')\n",
        "with open('ip_addresses.txt') as f:\n",
        "    content = f.readlines()\n",
        "ip_addresses = [x.strip() for x in content]\n",
        "\n",
        "while len(ip_addresses) != 0:\n",
        "    try:\n",
        "        proxy_index = random.randint(0, len(ip_addresses) - 1)\n",
        "        proxy = {\"http\": ip_addresses[proxy_index], \"https\": ip_addresses[proxy_index]}\n",
        "        response = requests.get(url, proxies=proxy, timeout=10)\n",
        "        print(response.json())\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        # implement here what to do when there’s a connection error\n",
        "        # for example: remove the used proxy from the pool and retry the request using another one\n",
        "        del ip_addresses[proxy_index]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kddu-X6Un2gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}