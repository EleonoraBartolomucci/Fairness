{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "support_functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EleonoraBartolomucci/Fairness/blob/master/support_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-GtXfILY6qy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "44e18a5a-9591-440d-af86-2d7e4e4322a9"
      },
      "source": [
        "!pip install clarifai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting clarifai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/1b/b7718c29f54ba7545551724461a8c2891304b7e68e5f415c30b49499f5e1/clarifai-2.6.2.tar.gz (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: future<2,>=0.15 in /usr/local/lib/python3.6/dist-packages (from clarifai) (0.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.13 in /usr/local/lib/python3.6/dist-packages (from clarifai) (2.23.0)\n",
            "Collecting configparser<4,>=3.5\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/1a/ec151e5e703ac80041eaccef923611bbcec2b667c20383655a06962732e9/configparser-3.8.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jsonschema<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from clarifai) (2.6.0)\n",
            "Requirement already satisfied: grpcio<2,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from clarifai) (1.30.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.6 in /usr/local/lib/python3.6/dist-packages (from clarifai) (3.10.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from clarifai) (1.52.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.13->clarifai) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.13->clarifai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.13->clarifai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.13->clarifai) (2.9)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from grpcio<2,>=1.13.0->clarifai) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf<4,>=3.6->clarifai) (47.3.1)\n",
            "Building wheels for collected packages: clarifai\n",
            "  Building wheel for clarifai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clarifai: filename=clarifai-2.6.2-cp36-none-any.whl size=188403 sha256=60a487e56e628cb88526655a729bd4bd52d95a9f5e6397bfe1b323f1376c3e7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/2c/3b/d89ffd4572633f70872165cedf61813ac8047461ed5e1e3768\n",
            "Successfully built clarifai\n",
            "Installing collected packages: configparser, clarifai\n",
            "Successfully installed clarifai-2.6.2 configparser-3.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl0nPnD7VUxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from clarifai.rest import ClarifaiApp\n",
        "from clarifai.rest import ApiError\n",
        "import numpy as np\n",
        "import time\n",
        "import json\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd\n",
        "import requests\n",
        "from lxml import html\n",
        "import shutil\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "# AUTHENTICATE IN GOOGLE DRIVE\n",
        "def authenticate():\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  return drive\n",
        "drive = authenticate()\n",
        "\n",
        "\n",
        "def create_folder_in_drive(gdrive, folder_name, parent_folder_id):\n",
        "  folder_metadata = {'title': folder_name,'mimeType': 'application/vnd.google-apps.folder',\n",
        "                    'parents': [{\"kind\": \"drive#fileLink\", \"id\": parent_folder_id}]\n",
        "                    }\n",
        "  folder = gdrive.CreateFile(folder_metadata)\n",
        "  folder.Upload()\n",
        "  print(folder)\n",
        "  # Return folder informations\n",
        "  print('title: %s, id: %s' % (folder['title'], folder['id']))\n",
        "  return folder['id']\n",
        "\n",
        "\n",
        "def drop_unnamed(df):\n",
        "  cols = [c for c in df.columns if c.lower()[:7] != 'unnamed']\n",
        "  return df[cols]\n",
        "\n",
        "\n",
        "def upload_file(filename, folder_id):\n",
        "  drive = authenticate()\n",
        "  fileList = drive.ListFile({'q': \"'\" + folder_id + \"' in parents and trashed=false\"}).GetList()\n",
        "  drive_file = drive.CreateFile({'title': filename, 'parents': [{'id': folder_id}]})\n",
        "  # Check if file already exists in Google Drive (prevents duplicates)\n",
        "  for file in fileList:\n",
        "      if file['title'] == filename:  # The file already exists, then overwrite it\n",
        "          fileID = file['id']\n",
        "          drive_file = drive.CreateFile({'id': fileID, 'title': filename, 'parents': [{'id': folder_id}]})\n",
        "  # Upload user picture on Google Drive\n",
        "  drive_file.SetContentFile(filename)  # path of local file content\n",
        "  drive_file.Upload()  # Upload the file.\n",
        "  return drive_file['id']\n",
        "\n",
        "\n",
        "def downloadUser(business_id, user_id, photo_folder, counter):\n",
        "    authenticate()\n",
        "    \n",
        "    filename = user_id + '.jpg'\n",
        "    url = 'https://www.yelp.com/user_details?userid=' + user_id\n",
        "    folder_id = photo_folder\n",
        "\n",
        "    # CHECK DUPLICATE\n",
        "    fileList = drive.ListFile({'q': \"'\" + folder_id + \"' in parents and trashed=false\"}).GetList()\n",
        "    exists = False\n",
        "    # Check if file already exists in Google Drive (prevents duplicates)\n",
        "    for file in fileList:\n",
        "        if file['title'] == filename:  # The file already exists\n",
        "            exists = True\n",
        "    \n",
        "    if exists:\n",
        "      return True\n",
        "    else:\n",
        "      # Find user picture from web page\n",
        "      page_content = requests.get(url)\n",
        "      print(page_content)\n",
        "      if not page_content.ok:\n",
        "        return False\n",
        "      tree = html.fromstring(page_content.content)\n",
        "      if len(tree.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/div/div[2]/div[1]/div/div/div/a/img/@src')) == 0:\n",
        "        print('PICTURE NOT FOUND')\n",
        "        print(user_id)\n",
        "        return False\n",
        "      else: # Picture found\n",
        "        image_url = tree.xpath('//*[@id=\"wrap\"]/div[2]/div[1]/div/div[2]/div[1]/div/div/div/a/img/@src')[0]\n",
        "\n",
        "        drive_file = drive.CreateFile({'title': filename, 'parents': [{'id': folder_id}]})\n",
        "      \n",
        "        response = requests.get(image_url, stream=True)\n",
        "\n",
        "        # Create a local copy of user picture\n",
        "        with open(filename, 'wb') as out_file:\n",
        "            shutil.copyfileobj(response.raw, out_file)\n",
        "        del response\n",
        "\n",
        "        # Upload user picture on Google Drive\n",
        "        drive_file.SetContentFile(filename)\n",
        "        drive_file.Upload()\n",
        "        if os.path.exists(filename):\n",
        "            os.remove(filename)\n",
        "        else:\n",
        "            print(\"The file does not exist\")\n",
        "        return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHBNPUGlbzWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "######################### DOWNLOAD RANKINGS ####################################\n",
        "\n",
        "def get_ranking_from_call(url_business, lang, sort, query):\n",
        "    headers = [{\"name\": \"Accept\", \"value\": \"*/*\"}, {\"name\": \"Accept-Encoding\", \"value\": \"gzip, deflate, br\"},\n",
        "               {\"name\": \"Accept-Language\", \"value\": \"it-IT,it;q=0.8,en-US;q=0.5,en;q=0.3\"},\n",
        "               {\"name\": \"Connection\", \"value\": \"keep-alive\"},\n",
        "               {\"name\": \"Content-Type\", \"value\": \"application/x-www-form-urlencoded; charset=utf-8\"}, {\"name\": \"Cookie\",\n",
        "                                                                                                       \"value\": \"qntcst=D; hl=en_US; wdi=1|3C26116D69138F61|0x1.78d019f71a444p+30|a7756ff94751d3a9; _ga=GA1.2.3C26116D69138F61; location=%7B%22city%22%3A+%22New+York%22%2C+%22state%22%3A+%22NY%22%2C+%22country%22%3A+%22US%22%2C+%22latitude%22%3A+40.713%2C+%22longitude%22%3A+-74.0072%2C+%22max_latitude%22%3A+40.8523%2C+%22min_latitude%22%3A+40.5597%2C+%22max_longitude%22%3A+-73.7938%2C+%22min_longitude%22%3A+-74.1948%2C+%22zip%22%3A+%22%22%2C+%22address1%22%3A+%22%22%2C+%22address2%22%3A+%22%22%2C+%22address3%22%3A+null%2C+%22neighborhood%22%3A+null%2C+%22borough%22%3A+null%2C+%22provenance%22%3A+%22YELP_GEOCODING_ENGINE%22%2C+%22display%22%3A+%22New+York%2C+NY%22%2C+%22unformatted%22%3A+%22New+York%2C+NY%2C+US%22%2C+%22accuracy%22%3A+4.0%2C+%22language%22%3A+null%7D; xcj=1|Ptt9P03gfc75x_PBT9zmqCkUuSuyB7PR-wWUBvABNi4; __qca=P0-60561249-1581956668708; G_ENABLED_IDPS=google; __cfduid=db8764ff59d8028a6c2e1b214867927d81583160194; _gid=GA1.2.2014867238.1583835527; bse=05dcd9d5de304ef0b1d9a76fa768b10f; sc=8a1ca0dbc2; pid=505721aa4569e7bb\"},\n",
        "               {\"name\": \"Host\", \"value\": \"www.yelp.com\"},\n",
        "               {\"name\": \"Referer\", \"value\": \"https://www.yelp.com/biz/noche-de-margaritas-new-york\"},\n",
        "               {\"name\": \"TE\", \"value\": \"Trailers\"}, {\"name\": \"User-Agent\",\n",
        "                                                     \"value\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:73.0) Gecko/20100101 Firefox/73.0\"},\n",
        "               {\"name\": \"X-Requested-By-React\", \"value\": \"true\"},\n",
        "               {\"name\": \"X-Requested-With\", \"value\": \"XMLHttpRequest\"}]\n",
        "    headers_ok = {}\n",
        "    for header in headers:\n",
        "        temp = {\n",
        "            header['name']: header['value']\n",
        "        }\n",
        "        headers_ok.update(temp)\n",
        "\n",
        "    x = 0\n",
        "    reviews_list = []\n",
        "    position = 1\n",
        "    url = url_business + \"/review_feed?rl=\" + lang + \"&sort_by=\" + sort + \"&q=\" + query\n",
        "\n",
        "    while 1:\n",
        "        if x == 0:\n",
        "            page_load = requests.get(url + '&start=', headers=headers_ok)\n",
        "        else:\n",
        "            page_load = requests.get(url + '&start=' + str(x), headers=headers_ok)\n",
        "        print(page_load)\n",
        "        x = x + 20\n",
        "        reviews = page_load.json()['reviews']\n",
        "        # print(json.dumps(reviews, indent=4, sort_keys=True))\n",
        "        if not reviews:\n",
        "            break\n",
        "        for review in reviews:\n",
        "            reviews_list.append((position, review['userId'], review['user'],\n",
        "                                 review['comment'], review['feedback'],\n",
        "                                 datetime.datetime.strptime(review['localizedDate'], '%m/%d/%Y')))\n",
        "            position = position + 1\n",
        "    df_reviews = pd.DataFrame(reviews_list, columns=[\"position\", \"user_id\", \"user\",\n",
        "                                                     \"comment\", \"feedback\", \"date\"])\n",
        "    return df_reviews\n",
        "\n",
        "\n",
        "def retrieve_rankings(business_id, folder_id):\n",
        "    df_rel_ranking = get_ranking_from_call(\"https://www.yelp.com/biz/\" + business_id, \"en\", \"relevance_desc\", \"\")\n",
        "    df_date_ranking = df_rel_ranking.sort_values(by=['date']).reset_index(drop=True)\n",
        "    df_date_ranking['position'] = df_date_ranking.index + 1\n",
        "    df_rand_ranking = df_rel_ranking.sample(frac=1).reset_index(drop=True)\n",
        "    df_rand_ranking['position'] = df_rand_ranking.index + 1\n",
        "\n",
        "    df_rel_ranking = drop_unnamed(df_rel_ranking)\n",
        "    df_rand_ranking = drop_unnamed(df_rand_ranking)\n",
        "    df_date_ranking = drop_unnamed(df_date_ranking)\n",
        "\n",
        "    df_rel_ranking.to_csv(\"rel_ranking_\" + business_id + \".csv\")\n",
        "    df_date_ranking.to_csv(\"date_ranking_\" + business_id + \".csv\")\n",
        "    df_rand_ranking.to_csv(\"rand_ranking_\" + business_id + \".csv\")\n",
        "\n",
        "    #destination = set_file_destination('', 'ranking', business_id)\n",
        "    upload_file(\"rel_ranking_\" + business_id + \".csv\", folder_id)\n",
        "    upload_file(\"date_ranking_\" + business_id + \".csv\", folder_id)\n",
        "    upload_file(\"rand_ranking_\" + business_id + \".csv\", folder_id)\n",
        "\n",
        "\n",
        "def create_folder_in_drive(gdrive, folder_name, parent_folder_id):\n",
        "  folder_metadata = {'title': folder_name,'mimeType': 'application/vnd.google-apps.folder',\n",
        "                    'parents': [{\"kind\": \"drive#fileLink\", \"id\": parent_folder_id}]\n",
        "                    }\n",
        "  folder = gdrive.CreateFile(folder_metadata)\n",
        "  folder.Upload()\n",
        "  print(folder)\n",
        "  # Return folder informations\n",
        "  print('title: %s, id: %s' % (folder['title'], folder['id']))\n",
        "  return folder['id']\n",
        "\n",
        "\n",
        "numrest = 87\n",
        "id_lista = restaurants_id_list[numrest-1:]\n",
        "for id in id_lista:\n",
        "\n",
        "  download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "  download.GetContentFile('gtree.csv')\n",
        "  gtree = pd.read_csv('gtree.csv')\n",
        "\n",
        "  gfolder_id = create_folder_in_drive(drive, str(numrest) + ' - ' + id, '1p9X-C0p1191dYlRnrGUZZUkTXLymJ49_')\n",
        "  gfolder_rankings = create_folder_in_drive(drive, '1_rankings', gfolder_id)\n",
        "  gfolder_groups = create_folder_in_drive(drive, '2_groups_exposure', gfolder_id)\n",
        "  new_row = {'business_id':id, 'gfolder_id':gfolder_id, 'gfolder_rankings':gfolder_rankings, \n",
        "                              'gfolder_groups':gfolder_groups, 'gfolder_#11':'', 'gfolder_#12':'',\n",
        "                              'gfolder_#14':'', 'gfolder_userphoto':'', 'gfolder_clarifai':''}\n",
        "  gtree = gtree.append(new_row, ignore_index=True)\n",
        "  gtree = gtree.drop_duplicates('business_id',keep='last').reset_index(drop=True)\n",
        "  gtree = drop_unnamed(gtree)\n",
        "  gtree.to_csv('gtree.csv')\n",
        "  upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data\n",
        "  retrieve_rankings(id, gfolder_rankings)\n",
        "  numrest += 1\n",
        "  print(id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O6PjjOHV0y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "###################### DOWNLOAD USER PHOTOS ####################################\n",
        "\n",
        "\n",
        "def scarica_tutti_utenti(business_id, df_utenti, photo_folder_id, startfrom):\n",
        "  df_utenti = df_utenti[startfrom:]\n",
        "  cnt = startfrom\n",
        "  for a, user in df_utenti.iterrows():\n",
        "    user_id = user['user_id']\n",
        "    completed = downloadUser(business_id, user_id, photo_folder_id, cnt)\n",
        "    if not completed:\n",
        "      print('ULTIMO SCARICATO:', cnt)\n",
        "      return False\n",
        "    print(cnt)\n",
        "    cnt = cnt + 1\n",
        "\n",
        "\n",
        "# DOWNLOAD restaurants.txt FROM DRIVE\n",
        "restaurants_dataset_id = '1BqMsph8flQMGmcE_WxYV0vSC_uqi-nge'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': restaurants_dataset_id})\n",
        "download.GetContentFile('restaurants.txt')\n",
        "with open('restaurants.txt') as f:\n",
        "    content = f.readlines()\n",
        "restaurants_id_list = [x.strip() for x in content] \n",
        "\n",
        "print(restaurants_id_list)\n",
        "\n",
        "\n",
        "numrest = 18\n",
        "id_lista = restaurants_id_list[(numrest-1):(numrest)]\n",
        "starting_from_photo = 2299\n",
        "\n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "gtree = pd.read_csv('gtree.csv')\n",
        "\n",
        "for id in id_lista:\n",
        "  print(id)\n",
        "  user_ranking_folder = gtree.loc[gtree['business_id']==id, 'gfolder_rankings'].tolist()[0]\n",
        "  ranking_file = drive.ListFile({'q': \"'\" + user_ranking_folder + \"' in parents and trashed=false\"}).GetList()[0]  \n",
        "  download = drive.CreateFile({'id': ranking_file['id']})\n",
        "  download.GetContentFile('ranking_' + id + '.csv')\n",
        "  ranking = pd.read_csv('ranking_' + id + '.csv')\n",
        "  if starting_from_photo == 0:\n",
        "    id_cartella = create_folder_in_drive(drive, str(numrest) + ' - ' + id,\n",
        "                                         '12OKc1s2VeJRv5kUS_fp9f4dFLn1LkSPG')  # folder face_data>Foto_User\n",
        "    gtree.loc[gtree['business_id']==id, 'gfolder_userphoto'] = id_cartella\n",
        "    gtree = gtree.drop_duplicates('business_id',keep='last').reset_index(drop=True)\n",
        "    gtree = drop_unnamed(gtree)\n",
        "    gtree.to_csv('gtree.csv')\n",
        "    upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data\n",
        "  else:\n",
        "    id_cartella = gtree.loc[gtree['business_id']==id, 'gfolder_userphoto'].tolist()[0]\n",
        "  \n",
        "  success = scarica_tutti_utenti(id, ranking[['user_id']], id_cartella, starting_from_photo)\n",
        "  if not success:\n",
        "    print('RISTORANTE:',id)\n",
        "    print(numrest)\n",
        "    break\n",
        "  else:\n",
        "    print(numrest)\n",
        "    print('FINE DOWNLOAD RISTORANTE ' + id)\n",
        "    numrest += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4CE8fLjjUZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "################## DOWNLOAD MISSING USER PHOTO #################################\n",
        "\n",
        "import json\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def scarica_utenti_mancanti(business_id, df_utenti, photo_folder_id):\n",
        "  cnt=0\n",
        "  for user_id in df_utenti:\n",
        "    completed = downloadUser(business_id, user_id, photo_folder_id, cnt)\n",
        "    if not completed:\n",
        "      print('ULTIMO NON SCARICATO:', user_id)\n",
        "      return False\n",
        "    print(cnt)\n",
        "    cnt = cnt + 1\n",
        "  return True\n",
        "\n",
        "\n",
        "# DOWNLOAD restaurants.txt FROM DRIVE\n",
        "restaurants_dataset_id = '1BqMsph8flQMGmcE_WxYV0vSC_uqi-nge'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': restaurants_dataset_id})\n",
        "download.GetContentFile('restaurants.txt')\n",
        "with open('restaurants.txt') as f:\n",
        "    content = f.readlines()\n",
        "restaurants_id_list = [x.strip() for x in content] \n",
        "\n",
        "print(restaurants_id_list)\n",
        "\n",
        "numrest = 89\n",
        "while numrest<90:\n",
        "\n",
        "  id = restaurants_id_list[(numrest-1):(numrest)][0]\n",
        "  download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "  download.GetContentFile('gtree.csv')\n",
        "  gtree = pd.read_csv('gtree.csv')\n",
        "\n",
        "  print(id)\n",
        "\n",
        "  user_photo_folder = gtree.loc[gtree['business_id']==id, 'gfolder_userphoto'].tolist()[0]\n",
        "  photo_list = drive.ListFile({'q': \"'\" + user_photo_folder + \"' in parents and trashed=false\"}).GetList() \n",
        "  user_id_list2 = [photo['title'][0:22] for photo in photo_list]\n",
        "  print(user_id_list2)\n",
        "\n",
        "  user_ranking_folder = gtree.loc[gtree['business_id']==id, 'gfolder_rankings'].tolist()[0]\n",
        "  ranking_file = drive.ListFile({'q': \"'\" + user_ranking_folder + \"' in parents and trashed=false\"}).GetList()[0]  \n",
        "  download = drive.CreateFile({'id': ranking_file['id']})\n",
        "  download.GetContentFile('ranking_' + id + '.csv')\n",
        "  ranking = pd.read_csv('ranking_' + id + '.csv')\n",
        "  user_id_list = ranking['user_id'].values.tolist()\n",
        "  print(user_id_list)\n",
        "\n",
        "  difference = (list(set(user_id_list) - set(user_id_list2)))\n",
        "\n",
        "  print('Utenti mancanti:', len(difference))\n",
        "  print(difference)\n",
        "  if difference:\n",
        "    success = scarica_utenti_mancanti(id, difference, user_photo_folder)\n",
        "  else:\n",
        "    success = True\n",
        "  if not success:\n",
        "    print('ERRORE RISTORANTE:',id)\n",
        "    print(numrest)\n",
        "    break\n",
        "  else:\n",
        "    print(numrest)\n",
        "    print('FINE DOWNLOAD RISTORANTE ' + id)\n",
        "    numrest += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuTTwMxTYKxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "678e3470-4300-42f8-c459-1100945ac53c"
      },
      "source": [
        "################################################################################\n",
        "################ ELABORATE USER PHOTOS WITH CLARIFAI ###########################\n",
        "\n",
        "def detect_clarifai(id, url_photo):\n",
        "  app = ClarifaiApp(api_key='e0dfe3e7a4cd4bfd8df072fdd2a1789c')\n",
        "  model = app.models.get(model_id=\"c0c0ac362b03416da06ab3fa36fb58e3\")\n",
        "  response = model.predict_by_url(url = '%s' % url_photo)\n",
        "  \n",
        "  df_result = pd.DataFrame(columns=['user_id', 'age', 'gender', 'ethnicity'])\n",
        "\n",
        "  if response['outputs'][0]['data'] != {}:\n",
        "    x = 0\n",
        "    while (x < len(response['outputs'][0]['data']['regions'])):\n",
        "      age = response['outputs'][0]['data']['regions'][x]['data']['concepts'][0]['name']\n",
        "      gender = response['outputs'][0]['data']['regions'][x]['data']['concepts'][20]['name']\n",
        "      ethnicity = response['outputs'][0]['data']['regions'][x]['data']['concepts'][22]['name']\n",
        "\n",
        "      new_row = {'user_id':id,\n",
        "                 'age':age,\n",
        "                 'gender':gender,\n",
        "                 'ethnicity':ethnicity}\n",
        "      df_result = df_result.append(new_row, ignore_index=True)\n",
        "      x = x + 1\n",
        "  else:\n",
        "    new_row = {'user_id':id,\n",
        "              'age':np.NaN,\n",
        "              'gender':np.NaN,\n",
        "              'ethnicity':np.NaN}\n",
        "    df_result = df_result.append(new_row, ignore_index=True)\n",
        "  return df_result\n",
        "\n",
        "\n",
        "# LEGGO GTREE\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "gtree = pd.read_csv('gtree.csv')\n",
        "gtree = drop_unnamed(gtree)\n",
        "id_clarifai_folder = '1wfZ0d3cTufosLRhPKkShf7kQbJlUbBvH' # folder data > Clarifai\n",
        "\n",
        "# DOWNLOAD restaurants.txt FROM DRIVE\n",
        "restaurants_dataset_id = '1BqMsph8flQMGmcE_WxYV0vSC_uqi-nge'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': restaurants_dataset_id})\n",
        "download.GetContentFile('restaurants.txt')\n",
        "with open('restaurants.txt') as f:\n",
        "    content = f.readlines()\n",
        "restaurants_id_list = [x.strip() for x in content] \n",
        "\n",
        "print(restaurants_id_list)\n",
        "\n",
        "numrest = 83\n",
        "id_restaurant = restaurants_id_list[(numrest-1):(numrest)][0]\n",
        "startfrom = 2796  # BE CAREFUL, IF 0 OVERWRITE THE CSV IN DRIVE\n",
        "\n",
        "id_photo_folder = gtree.loc[gtree['business_id'] == id_restaurant, 'gfolder_userphoto'].tolist()[0]\n",
        "print(id_restaurant)\n",
        "print(id_photo_folder)\n",
        "\n",
        "if startfrom == 0:\n",
        "  df_clarifai = pd.DataFrame(columns=['user_id', 'age', 'gender', 'ethnicity'])\n",
        "  df_clarifai.to_csv(str(numrest) + ' - ' + id_restaurant + '.csv')\n",
        "  id_new_file = upload_file(str(numrest) + ' - ' + id_restaurant + '.csv', id_clarifai_folder)\n",
        "  gtree.loc[gtree['business_id']==id_restaurant, 'gfolder_clarifai'] = id_new_file\n",
        "  gtree.to_csv('gtree.csv')\n",
        "  upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD')\n",
        "else:\n",
        "  id_clarifai_file = gtree.loc[gtree['business_id']==id_restaurant, 'gfolder_clarifai'].tolist()[0]\n",
        "  print(id_clarifai_file)\n",
        "  download = drive.CreateFile({'id': id_clarifai_file})\n",
        "  download.GetContentFile(str(numrest) + ' - ' + id_restaurant + '.csv')\n",
        "  df_clarifai = pd.read_csv(str(numrest) + ' - ' + id_restaurant + '.csv')\n",
        "\n",
        "file_list = drive.ListFile({'q': \"'\" + id_photo_folder + \"' in parents and trashed=false\"}).GetList()    #cartella da cui prendo le foto\n",
        "\n",
        "count = 0\n",
        "\n",
        "for photo in file_list[startfrom:]:\n",
        "  user_id = photo['title'][0:22] \n",
        "  count = count + 1\n",
        "  if user_id not in df_clarifai['user_id'].values:\n",
        "    minidf_result = detect_clarifai(user_id, photo['thumbnailLink'])\n",
        "    df_clarifai = df_clarifai.append(minidf_result, ignore_index=True)\n",
        "    df_clarifai = drop_unnamed(df_clarifai)\n",
        "    if count == 100:\n",
        "      count = 0\n",
        "      df_clarifai.to_csv(str(numrest) + ' - ' + id_restaurant + '.csv')\n",
        "      id_new_file = upload_file(str(numrest) + ' - ' + id_restaurant + '.csv', id_clarifai_folder)\n",
        "      print('csv caricato: ' + id_new_file)\n",
        "      \n",
        "    print(startfrom)\n",
        "    startfrom = startfrom + 1\n",
        "  else:\n",
        "    if count == 100:\n",
        "      count = 0\n",
        "    print(str(startfrom) + ' già fatto')\n",
        "    startfrom = startfrom + 1\n",
        "      \n",
        "df_clarifai.to_csv(str(numrest) + ' - ' + id_restaurant + '.csv')\n",
        "id_new_file = upload_file(str(numrest) + ' - ' + id_restaurant + '.csv', id_clarifai_folder)\n",
        "print('csv caricato: ' + id_new_file) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['WbJ1LRQdOuYYlRLyTkuuxw', 'T2tEMLpTeSMxLKpxwFdS3g', 'ALwAlxItASeEs2vYAeLXHA', 'OVTZNSkSfbl3gVB9XQIJfw', 'Sovgwq-E-n6wLqNh3X_rXg', 'j5nPiTwWEFr-VsePew7Sjg', 'aiX_WP7NKPTdF9CfI-M-wg', 'e4NQLZynhSmvwl38hC4m-A', 'S-oLPRdhlyL5HAknBKTUcQ', 'VyVIneSU7XAWgMBllI6LnQ', 'pSQFynH1VxkfSmehRXlZWw', 'JzOp695tclcNCNMuBl7oxA', 'OgJ0KxwJcJ9R5bUK0ixCbg', '3l54GTr8-E3XPbIxnF_sAA', '9a3DrZvpYxVs3k_qwlCNSw', 'frCxZS7lPhEnQRJ3UY6m7A', 'yNPh5SO-7wr8HPpVCDPbXQ', '0FUtlsQrJI7LhqDPxLumEw', 'K-uQkfSUTwu5LIwPB4b_vg', 'L2p0vO3fsS2LC6hhQo3CzA', 'd10IxZPirVJlOSpdRZJczA', 'wUKzaS1MHg94RGM6z8u9mw', 'z6-reuC5BYf_Rth9gMBfgQ', 'aiX_WP7NKPTdF9CfI-M-wg', '3C5Z9homtzkWHouH2BHXYQ', 'C8D_GU9cDDjbOJfCaGXxDQ', 'Yl05MqCs9xRzrJFkGWLpgA', 'eS29S_06lvsDW04wVrIVxg', 'IsoLzudHC50oJLiEWpwV-w', '3N9U549Zse8UP-MwKZAjAQ', '_XN-GwzZwAyIqLKJsl2htg', 'r5PLDU-4mSbde5XekTXSCA', 'Iq7NqQD-sESu3vr9iEGuTA', 'u-SJ5QUwrNquL9VnXwl8cg', 'sJNcipFYElitBrtiJx0ezQ', '7m1Oa1VYV98UUuo_6i0EZg', 'e4NQLZynhSmvwl38hC4m-A', 'k1QpHAkzKTrFYfk6u--VgQ', '-6tvduBzjLI1ISfs3F_qTg', 'jcasci3gjbsSuTEVzvDQKg', 'Ch7NAhB_MWSDwcNbcptEKg', 'eZDXz_RylvdD0tHEA8I0NA', 'tCSlpwJQ4CZsUEMZeH2SFg', 'yWUBX9Pe6pzh1PjVj04UmQ', 'k-drEjxKmfqllwfY90STfA', 'y1eeVRfJa22CCpUCeNfrSw', 'VH3WA7a-OVzFj2K_SP4BIw', 'osSwv6CJy5hDKQdOKeyTow', 'o5QDrg_kb4hgsWxV6cV_Uw', 'XgRljuEUyaHBKIpIz-PRAA', 'wArcCMVnrl_tc9MULW-0CQ', 'SHFlELFcEcAOJv_fTAKChQ', 'aBLx9JlAMq_AuW6VAImSwg', 'd8lmIZIqmBC9oPM8y1dc7Q', 'bzbNGyrTwWHAgg1CqkSgeg', 'ADgacmZ-qXrSOhMfU6bmTA', 'gChmBjLSe3qa8rzEngoDLQ', 'D2ojX9bvE0_-aIj9BhdZZA', 'hggVnGwA5042-ABxqeJX-A', '9dqdzRzjSfbnMvjUGqWBAw', 'DyOzNIeXUksPNLXYHnB-oQ', 'mC39IrCp36QIVFRZIw9PTQ', 'sdYkVaTy7EJwUkO8Ie_qPg', 'ALwAlxItASeEs2vYAeLXHA', '01fuY2NNscttoTxOYbuZXw', 'T2tEMLpTeSMxLKpxwFdS3g', 'RVQE2Z2uky4c0-njFQO66g', 'WbJ1LRQdOuYYlRLyTkuuxw', 'RAh9WCQAuocM7hYM5_6tnw', '3kdSl5mo9dWC4clrQjEDGg', '7sPNbCx7vGAaH7SbNPZ6oA', 'Cni2l-VKG_pdospJ6xliXQ', 'DkYS3arLOhA8si5uUEmHOw', 'f4x1YBxkLrZg652xt2KR5g', 'faPVqws-x-5k2CQKDNtHxw', 'fL-b760btOaGa85OJ9ut3w', 'G-5kEa6E6PD5fkBRuA7k9Q', 'g8OnV26ywJlZpezdBnOWUQ', 'HhVmDybpU7L50Kb5A0jXTg', 'hihud--QRriCYZw1zZvW4g', 'IWN2heYitkg-D4UdqfxcMA', 'JDZ6_yycNQFTpUZzLIKHUg', 'JpgVl3d20CMRNjf1DVnzGA', 'mDR12Hafvr84ctpsV6YLag', 'NvKNe9DnQavC9GstglcBJQ', 'OETh78qcgDltvHULowwhJg', 'P7pxQFqr7yBKMMI2J51udw', 'pH0BLkL4cbxKzu471VZnuA', 'QJatAcxYgK1Zp9BRZMAx7g', 'QXV3L_QFGj8r6nWX2kS2hA', 'RwMLuOkImBIqqYj4SSKSPg', 'ujHiaprwCQ5ewziu0Vi9rw', 'UPIYuRaZvknINOd1w8kqRQ', 'xkVMIk_Vqh17f48ZQ_6b0w', 'XXW_OFaYQkkGOGniujZFHg', 'XZbuPXdyA0ZtTu3AzqtQhg', 'yfxDa8RFOvJPQh0rNtakHA', 'YJ8ljUhLsz6CtT_2ORNFmg', 'ZkGDCVKSdf8m76cnnalL-A']\n",
            "JpgVl3d20CMRNjf1DVnzGA\n",
            "1eSBpx_IMnkb026lcUmXhrbVr5D76QALa\n",
            "1Lf0VsTDMK-NSQ2znXY75vK_dInhTM33T\n",
            "2796 già fatto\n",
            "2797 già fatto\n",
            "2798\n",
            "2799\n",
            "2800\n",
            "2801\n",
            "2802\n",
            "2803\n",
            "2804\n",
            "2805\n",
            "2806\n",
            "2807\n",
            "2808\n",
            "2809\n",
            "2810\n",
            "2811\n",
            "2812\n",
            "2813\n",
            "2814\n",
            "2815\n",
            "2816\n",
            "2817\n",
            "2818\n",
            "2819\n",
            "2820\n",
            "2821\n",
            "2822\n",
            "2823\n",
            "2824\n",
            "2825\n",
            "2826\n",
            "2827\n",
            "2828\n",
            "2829\n",
            "2830\n",
            "2831\n",
            "2832\n",
            "2833\n",
            "2834\n",
            "2835\n",
            "2836\n",
            "2837\n",
            "2838\n",
            "2839\n",
            "2840\n",
            "2841\n",
            "2842\n",
            "2843\n",
            "2844\n",
            "2845\n",
            "2846\n",
            "2847\n",
            "2848\n",
            "2849\n",
            "2850\n",
            "2851\n",
            "2852\n",
            "2853\n",
            "2854\n",
            "2855\n",
            "2856\n",
            "2857\n",
            "2858\n",
            "2859\n",
            "2860\n",
            "2861\n",
            "2862\n",
            "2863\n",
            "2864\n",
            "2865\n",
            "2866\n",
            "2867\n",
            "2868\n",
            "2869\n",
            "2870\n",
            "2871\n",
            "2872\n",
            "2873\n",
            "2874\n",
            "2875\n",
            "2876\n",
            "2877\n",
            "2878\n",
            "2879\n",
            "2880\n",
            "2881\n",
            "2882\n",
            "2883\n",
            "2884\n",
            "2885\n",
            "2886\n",
            "2887\n",
            "2888\n",
            "2889\n",
            "2890\n",
            "2891\n",
            "2892\n",
            "2893\n",
            "2894\n",
            "csv caricato: 1Lf0VsTDMK-NSQ2znXY75vK_dInhTM33T\n",
            "2895\n",
            "2896\n",
            "2897\n",
            "2898\n",
            "2899\n",
            "2900\n",
            "2901\n",
            "2902\n",
            "2903\n",
            "2904\n",
            "2905\n",
            "2906\n",
            "2907\n",
            "2908\n",
            "2909\n",
            "2910\n",
            "2911\n",
            "2912\n",
            "2913\n",
            "2914\n",
            "2915\n",
            "2916\n",
            "2917\n",
            "2918\n",
            "2919\n",
            "2920\n",
            "2921\n",
            "2922\n",
            "2923\n",
            "2924\n",
            "2925\n",
            "2926\n",
            "2927\n",
            "2928\n",
            "2929\n",
            "2930\n",
            "2931\n",
            "2932\n",
            "2933\n",
            "2934\n",
            "2935\n",
            "2936\n",
            "2937\n",
            "2938\n",
            "2939\n",
            "2940\n",
            "2941\n",
            "2942\n",
            "2943\n",
            "2944\n",
            "2945\n",
            "2946\n",
            "2947\n",
            "2948\n",
            "2949\n",
            "2950\n",
            "2951\n",
            "2952\n",
            "2953\n",
            "2954\n",
            "2955\n",
            "2956\n",
            "2957\n",
            "2958\n",
            "2959\n",
            "2960\n",
            "2961\n",
            "2962\n",
            "2963\n",
            "2964\n",
            "2965\n",
            "2966\n",
            "2967\n",
            "2968\n",
            "2969\n",
            "2970\n",
            "2971\n",
            "2972\n",
            "2973\n",
            "2974\n",
            "2975\n",
            "2976\n",
            "2977\n",
            "2978\n",
            "2979\n",
            "2980\n",
            "2981\n",
            "2982\n",
            "2983\n",
            "2984\n",
            "2985\n",
            "2986\n",
            "2987\n",
            "2988\n",
            "2989\n",
            "2990\n",
            "2991\n",
            "2992\n",
            "2993\n",
            "2994\n",
            "csv caricato: 1Lf0VsTDMK-NSQ2znXY75vK_dInhTM33T\n",
            "2995\n",
            "2996\n",
            "2997\n",
            "2998\n",
            "2999\n",
            "3000\n",
            "3001\n",
            "3002\n",
            "3003\n",
            "3004\n",
            "3005\n",
            "3006\n",
            "3007\n",
            "3008\n",
            "3009\n",
            "3010\n",
            "3011\n",
            "3012\n",
            "3013\n",
            "3014\n",
            "3015\n",
            "3016\n",
            "3017\n",
            "3018\n",
            "3019\n",
            "3020\n",
            "3021\n",
            "3022\n",
            "3023\n",
            "3024\n",
            "3025\n",
            "3026\n",
            "3027\n",
            "3028\n",
            "3029\n",
            "3030\n",
            "3031\n",
            "3032\n",
            "3033\n",
            "3034\n",
            "3035\n",
            "3036\n",
            "3037\n",
            "3038\n",
            "3039\n",
            "3040\n",
            "3041\n",
            "3042\n",
            "3043\n",
            "3044\n",
            "3045\n",
            "3046\n",
            "3047\n",
            "3048\n",
            "3049\n",
            "3050\n",
            "3051\n",
            "3052\n",
            "3053\n",
            "3054\n",
            "3055\n",
            "3056\n",
            "3057\n",
            "3058\n",
            "3059\n",
            "3060\n",
            "3061\n",
            "3062\n",
            "3063\n",
            "3064\n",
            "3065\n",
            "3066\n",
            "3067\n",
            "3068\n",
            "3069\n",
            "3070\n",
            "3071\n",
            "3072\n",
            "3073\n",
            "3074\n",
            "3075\n",
            "3076\n",
            "3077\n",
            "3078\n",
            "3079\n",
            "3080\n",
            "3081\n",
            "3082\n",
            "3083\n",
            "3084\n",
            "3085\n",
            "3086\n",
            "3087\n",
            "3088\n",
            "3089\n",
            "3090\n",
            "3091\n",
            "3092\n",
            "3093\n",
            "3094\n",
            "csv caricato: 1Lf0VsTDMK-NSQ2znXY75vK_dInhTM33T\n",
            "3095\n",
            "3096\n",
            "3097\n",
            "3098\n",
            "3099\n",
            "3100\n",
            "3101\n",
            "3102\n",
            "3103\n",
            "3104\n",
            "3105\n",
            "3106\n",
            "3107\n",
            "3108\n",
            "3109\n",
            "3110\n",
            "3111\n",
            "3112\n",
            "3113\n",
            "3114\n",
            "3115\n",
            "3116\n",
            "3117\n",
            "3118\n",
            "3119\n",
            "3120\n",
            "3121\n",
            "3122\n",
            "3123\n",
            "3124\n",
            "3125\n",
            "3126\n",
            "3127\n",
            "3128\n",
            "3129\n",
            "3130\n",
            "3131\n",
            "3132\n",
            "3133\n",
            "3134\n",
            "3135\n",
            "3136\n",
            "3137\n",
            "3138\n",
            "3139\n",
            "3140\n",
            "3141\n",
            "3142\n",
            "3143\n",
            "3144\n",
            "3145\n",
            "3146\n",
            "3147\n",
            "3148\n",
            "3149\n",
            "3150\n",
            "3151\n",
            "3152\n",
            "3153\n",
            "3154\n",
            "3155\n",
            "3156\n",
            "3157\n",
            "3158\n",
            "3159\n",
            "3160\n",
            "3161\n",
            "3162\n",
            "3163\n",
            "3164\n",
            "3165\n",
            "3166\n",
            "3167\n",
            "3168\n",
            "3169\n",
            "3170\n",
            "3171\n",
            "3172\n",
            "3173\n",
            "csv caricato: 1Lf0VsTDMK-NSQ2znXY75vK_dInhTM33T\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3g-ePyz_VHi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afacab8f-a6bb-4d77-9a96-3fd566f3229f"
      },
      "source": [
        "################################################################################\n",
        "############################### CHECK NUMBERS ##################################\n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "gtree = pd.read_csv('gtree.csv')\n",
        "gtree = drop_unnamed(gtree)\n",
        "\n",
        "# DOWNLOAD restaurants.txt FROM DRIVE\n",
        "restaurants_dataset_id = '1BqMsph8flQMGmcE_WxYV0vSC_uqi-nge'  # FILE ID, got on google drive with condivision link\n",
        "download = drive.CreateFile({'id': restaurants_dataset_id})\n",
        "download.GetContentFile('restaurants.txt')\n",
        "with open('restaurants.txt') as f:\n",
        "    content = f.readlines()\n",
        "restaurants_id_list = [x.strip() for x in content] \n",
        "\n",
        "print(restaurants_id_list)\n",
        "\n",
        "numero_risto = 78\n",
        "\n",
        "while numero_risto < 85:\n",
        "  print(numero_risto)\n",
        "  id_risto = restaurants_id_list[(numero_risto-1):(numero_risto)][0]\n",
        "  print(id_risto)\n",
        "\n",
        "  ########################## RANKING ##############################\n",
        "  user_ranking_folder = gtree.loc[gtree['business_id']==id_risto, 'gfolder_rankings'].tolist()[0]\n",
        "  ranking_file = drive.ListFile({'q': \"'\" + user_ranking_folder + \"' in parents and trashed=false\"}).GetList()[0]  \n",
        "  download = drive.CreateFile({'id': ranking_file['id']})\n",
        "  download.GetContentFile('ranking_' + id_risto + '.csv')\n",
        "  file_ranking = pd.read_csv('ranking_' + id_risto + '.csv')\n",
        "  ranking_lista = file_ranking['user_id'].values.tolist()\n",
        "\n",
        "  ########################## PHOTO ##############################\n",
        "  user_photo_folder = gtree.loc[gtree['business_id']==id_risto, 'gfolder_userphoto'].tolist()[0]\n",
        "  photo_lista = drive.ListFile({'q': \"'\" + user_photo_folder + \"' in parents and trashed=false\"}).GetList() \n",
        "  photo_lista = [photo['title'][0:22] for photo in photo_lista]\n",
        "  seen = set()\n",
        "  print('duplicates:')\n",
        "  for x in photo_lista:\n",
        "    if x not in seen:\n",
        "        seen.add(x)\n",
        "    else:\n",
        "      print(x)\n",
        "\n",
        "  ########################## CLARIFAI ##############################\n",
        "  user_clarifai_id = gtree.loc[gtree['business_id']==id_risto, 'gfolder_clarifai'].tolist()[0]\n",
        "  download = drive.CreateFile({'id': user_clarifai_id})\n",
        "  download.GetContentFile('clarifai_' + id_risto + '.csv')\n",
        "  file_clarifai = pd.read_csv('clarifai_' + id_risto + '.csv')\n",
        "  clarifai_without_duplicates = file_clarifai.drop_duplicates(subset=('user_id')).reset_index()\n",
        "  clarifai_lista = clarifai_without_duplicates['user_id'].values.tolist()\n",
        "\n",
        "  print('tot ranking = tot foto = tot clarifai')\n",
        "  tot_ranking = len(file_ranking.index)\n",
        "  tot_foto = len(photo_lista)\n",
        "  tot_clarifai = len(clarifai_without_duplicates.index)\n",
        "  toomuch = False\n",
        "  print(str(tot_ranking) + ' = ' + str(tot_foto) + ' = ' + str(tot_clarifai))\n",
        "  #if tot_ranking!=tot_foto or tot_ranking!=tot_clarifai or tot_foto!=tot_clarifai:\n",
        "  print('FOTO CHE NON STANNO NEL RANKING:')\n",
        "  for unid in photo_lista:\n",
        "    if unid not in ranking_lista:\n",
        "      print(unid)\n",
        "  print('FOTO ANCORA DA SCARICARE (CHE STANNO NEL RANKING):')\n",
        "  for unid in ranking_lista:\n",
        "    if unid not in photo_lista:\n",
        "      print(unid)\n",
        "  print('CLARIFAI ANCORA DA ELABORARE (CHE STANNO NEL RANKING):')\n",
        "  for unid in ranking_lista:\n",
        "    if unid not in clarifai_lista:\n",
        "      print(unid)\n",
        "  print('CLARIFAI CHE NON STANNO NEL RANKING:')\n",
        "  for unid in clarifai_lista:\n",
        "    if unid not in ranking_lista:\n",
        "      print(unid)\n",
        "      toomuch = True\n",
        "      file_clarifai = file_clarifai[file_clarifai['user_id'] != unid]\n",
        "  if toomuch:\n",
        "    file_clarifai = drop_unnamed(file_clarifai)\n",
        "    file_clarifai.to_csv(str(numero_risto) + ' - ' + id_risto + '.csv')\n",
        "    upload_file(str(numero_risto) + ' - ' + id_risto + '.csv', '1wfZ0d3cTufosLRhPKkShf7kQbJlUbBvH')\n",
        "  numero_risto += 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['WbJ1LRQdOuYYlRLyTkuuxw', 'T2tEMLpTeSMxLKpxwFdS3g', 'ALwAlxItASeEs2vYAeLXHA', 'OVTZNSkSfbl3gVB9XQIJfw', 'Sovgwq-E-n6wLqNh3X_rXg', 'j5nPiTwWEFr-VsePew7Sjg', 'aiX_WP7NKPTdF9CfI-M-wg', 'e4NQLZynhSmvwl38hC4m-A', 'S-oLPRdhlyL5HAknBKTUcQ', 'VyVIneSU7XAWgMBllI6LnQ', 'pSQFynH1VxkfSmehRXlZWw', 'JzOp695tclcNCNMuBl7oxA', 'OgJ0KxwJcJ9R5bUK0ixCbg', '3l54GTr8-E3XPbIxnF_sAA', '9a3DrZvpYxVs3k_qwlCNSw', 'frCxZS7lPhEnQRJ3UY6m7A', 'yNPh5SO-7wr8HPpVCDPbXQ', '0FUtlsQrJI7LhqDPxLumEw', 'K-uQkfSUTwu5LIwPB4b_vg', 'L2p0vO3fsS2LC6hhQo3CzA', 'd10IxZPirVJlOSpdRZJczA', 'wUKzaS1MHg94RGM6z8u9mw', 'z6-reuC5BYf_Rth9gMBfgQ', 'aiX_WP7NKPTdF9CfI-M-wg', '3C5Z9homtzkWHouH2BHXYQ', 'C8D_GU9cDDjbOJfCaGXxDQ', 'Yl05MqCs9xRzrJFkGWLpgA', 'eS29S_06lvsDW04wVrIVxg', 'IsoLzudHC50oJLiEWpwV-w', '3N9U549Zse8UP-MwKZAjAQ', '_XN-GwzZwAyIqLKJsl2htg', 'r5PLDU-4mSbde5XekTXSCA', 'Iq7NqQD-sESu3vr9iEGuTA', 'u-SJ5QUwrNquL9VnXwl8cg', 'sJNcipFYElitBrtiJx0ezQ', '7m1Oa1VYV98UUuo_6i0EZg', 'e4NQLZynhSmvwl38hC4m-A', 'k1QpHAkzKTrFYfk6u--VgQ', '-6tvduBzjLI1ISfs3F_qTg', 'jcasci3gjbsSuTEVzvDQKg', 'Ch7NAhB_MWSDwcNbcptEKg', 'eZDXz_RylvdD0tHEA8I0NA', 'tCSlpwJQ4CZsUEMZeH2SFg', 'yWUBX9Pe6pzh1PjVj04UmQ', 'k-drEjxKmfqllwfY90STfA', 'y1eeVRfJa22CCpUCeNfrSw', 'VH3WA7a-OVzFj2K_SP4BIw', 'osSwv6CJy5hDKQdOKeyTow', 'o5QDrg_kb4hgsWxV6cV_Uw', 'XgRljuEUyaHBKIpIz-PRAA', 'wArcCMVnrl_tc9MULW-0CQ', 'SHFlELFcEcAOJv_fTAKChQ', 'aBLx9JlAMq_AuW6VAImSwg', 'd8lmIZIqmBC9oPM8y1dc7Q', 'bzbNGyrTwWHAgg1CqkSgeg', 'ADgacmZ-qXrSOhMfU6bmTA', 'gChmBjLSe3qa8rzEngoDLQ', 'D2ojX9bvE0_-aIj9BhdZZA', 'hggVnGwA5042-ABxqeJX-A', '9dqdzRzjSfbnMvjUGqWBAw', 'DyOzNIeXUksPNLXYHnB-oQ', 'mC39IrCp36QIVFRZIw9PTQ', 'sdYkVaTy7EJwUkO8Ie_qPg', 'ALwAlxItASeEs2vYAeLXHA', '01fuY2NNscttoTxOYbuZXw', 'T2tEMLpTeSMxLKpxwFdS3g', 'RVQE2Z2uky4c0-njFQO66g', 'WbJ1LRQdOuYYlRLyTkuuxw', 'RAh9WCQAuocM7hYM5_6tnw', '3kdSl5mo9dWC4clrQjEDGg', '7sPNbCx7vGAaH7SbNPZ6oA', 'Cni2l-VKG_pdospJ6xliXQ', 'DkYS3arLOhA8si5uUEmHOw', 'f4x1YBxkLrZg652xt2KR5g', 'faPVqws-x-5k2CQKDNtHxw', 'fL-b760btOaGa85OJ9ut3w', 'G-5kEa6E6PD5fkBRuA7k9Q', 'g8OnV26ywJlZpezdBnOWUQ', 'HhVmDybpU7L50Kb5A0jXTg', 'hihud--QRriCYZw1zZvW4g', 'IWN2heYitkg-D4UdqfxcMA', 'JDZ6_yycNQFTpUZzLIKHUg', 'JpgVl3d20CMRNjf1DVnzGA', 'mDR12Hafvr84ctpsV6YLag', 'NvKNe9DnQavC9GstglcBJQ', 'OETh78qcgDltvHULowwhJg', 'P7pxQFqr7yBKMMI2J51udw', 'pH0BLkL4cbxKzu471VZnuA', 'QJatAcxYgK1Zp9BRZMAx7g', 'QXV3L_QFGj8r6nWX2kS2hA', 'RwMLuOkImBIqqYj4SSKSPg', 'ujHiaprwCQ5ewziu0Vi9rw', 'UPIYuRaZvknINOd1w8kqRQ', 'xkVMIk_Vqh17f48ZQ_6b0w', 'XXW_OFaYQkkGOGniujZFHg', 'XZbuPXdyA0ZtTu3AzqtQhg', 'yfxDa8RFOvJPQh0rNtakHA', 'YJ8ljUhLsz6CtT_2ORNFmg', 'ZkGDCVKSdf8m76cnnalL-A']\n",
            "78\n",
            "g8OnV26ywJlZpezdBnOWUQ\n",
            "duplicates:\n",
            "k-IcDN5P4LPifKvaDcXQNg\n",
            "tot ranking = tot foto = tot clarifai\n",
            "3498 = 3498 = 3497\n",
            "FOTO CHE NON STANNO NEL RANKING:\n",
            "FOTO ANCORA DA SCARICARE (CHE STANNO NEL RANKING):\n",
            "x6dEWnnRf2paBjR7a1ULHA\n",
            "CLARIFAI ANCORA DA ELABORARE (CHE STANNO NEL RANKING):\n",
            "x6dEWnnRf2paBjR7a1ULHA\n",
            "CLARIFAI CHE NON STANNO NEL RANKING:\n",
            "79\n",
            "HhVmDybpU7L50Kb5A0jXTg\n",
            "duplicates:\n",
            "tot ranking = tot foto = tot clarifai\n",
            "3871 = 3871 = 3871\n",
            "FOTO CHE NON STANNO NEL RANKING:\n",
            "FOTO ANCORA DA SCARICARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI ANCORA DA ELABORARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI CHE NON STANNO NEL RANKING:\n",
            "80\n",
            "hihud--QRriCYZw1zZvW4g\n",
            "duplicates:\n",
            "tot ranking = tot foto = tot clarifai\n",
            "3831 = 3831 = 3831\n",
            "FOTO CHE NON STANNO NEL RANKING:\n",
            "FOTO ANCORA DA SCARICARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI ANCORA DA ELABORARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI CHE NON STANNO NEL RANKING:\n",
            "81\n",
            "IWN2heYitkg-D4UdqfxcMA\n",
            "duplicates:\n",
            "tot ranking = tot foto = tot clarifai\n",
            "3483 = 3483 = 3483\n",
            "FOTO CHE NON STANNO NEL RANKING:\n",
            "FOTO ANCORA DA SCARICARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI ANCORA DA ELABORARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI CHE NON STANNO NEL RANKING:\n",
            "82\n",
            "JDZ6_yycNQFTpUZzLIKHUg\n",
            "duplicates:\n",
            "tot ranking = tot foto = tot clarifai\n",
            "4076 = 4076 = 4076\n",
            "FOTO CHE NON STANNO NEL RANKING:\n",
            "FOTO ANCORA DA SCARICARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI ANCORA DA ELABORARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI CHE NON STANNO NEL RANKING:\n",
            "83\n",
            "JpgVl3d20CMRNjf1DVnzGA\n",
            "duplicates:\n",
            "tot ranking = tot foto = tot clarifai\n",
            "3174 = 3174 = 3174\n",
            "FOTO CHE NON STANNO NEL RANKING:\n",
            "FOTO ANCORA DA SCARICARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI ANCORA DA ELABORARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI CHE NON STANNO NEL RANKING:\n",
            "84\n",
            "mDR12Hafvr84ctpsV6YLag\n",
            "duplicates:\n",
            "tot ranking = tot foto = tot clarifai\n",
            "3573 = 3573 = 3573\n",
            "FOTO CHE NON STANNO NEL RANKING:\n",
            "FOTO ANCORA DA SCARICARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI ANCORA DA ELABORARE (CHE STANNO NEL RANKING):\n",
            "CLARIFAI CHE NON STANNO NEL RANKING:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uADbgKK-9U9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1e122340-a172-4f82-c4bb-3e8570d9654f"
      },
      "source": [
        "################################################################################\n",
        "#################### MODIFY SOME VALUES IN GTREE ###############################\n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "df = pd.read_csv('gtree.csv')\n",
        "df = drop_unnamed(df)\n",
        "\n",
        "#BE CAREFUL AT THE INDEX\n",
        "#indice = 31  # IF RESTAURANT 20, THEN 10 IN GTREE\n",
        "#df.loc[indice, 'business_id'] = ''\n",
        "#df.loc[indice, 'gfolder_id'] = ''\n",
        "#df.loc[indice, 'gfolder_rankings'] = ''\n",
        "#df.loc[indice, 'gfolder_groups'] = ''\n",
        "#df.loc[indice, 'gfolder_userphoto'] = ''\n",
        "#df.loc[indice, 'gfolder_clarifai'] = ''\n",
        "df.loc[df['business_id']=='pSQFynH1VxkfSmehRXlZWw', 'gfolder_#14'] = '1trP01BYem2Qc0enPnmxwRmKdKR-lU7G3'\n",
        "#df.loc[df['business_id']=='RwMLuOkImBIqqYj4SSKSPg', 'gfolder_userphoto'] = '1KtHm3_fXyGReGZ1zIIhmKXhAjMLwhlei'\n",
        "#df.loc[df['business_id']=='ujHiaprwCQ5ewziu0Vi9rw', 'gfolder_userphoto'] = '1PsSO6dcpfj20frHxMrmDgDEf4in5pWcL'\n",
        "\n",
        "gtree = drop_unnamed(df)\n",
        "gtree.to_csv('gtree.csv')\n",
        "upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRNS1d5oV_3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "######################## INSERT ONE ROW IN GTREE ###############################\n",
        "\n",
        "def Insert_row(row_number, df, row_value):\n",
        "    start_upper = 0\n",
        "    end_upper = row_number\n",
        "    start_lower = row_number\n",
        "    end_lower = df.shape[0]\n",
        "    upper_half = [*range(start_upper, end_upper, 1)]\n",
        "    lower_half = [*range(start_lower, end_lower, 1)]\n",
        "    lower_half = [x.__add__(1) for x in lower_half]\n",
        "    index_ = upper_half + lower_half\n",
        "    df.index = index_\n",
        "    df.loc[row_number] = row_value\n",
        "    df = df.sort_index()\n",
        "    return df \n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "df = pd.read_csv('gtree.csv')\n",
        "print(df)\n",
        "df = drop_unnamed(df)\n",
        " \n",
        "row_number = 66\n",
        "row_value = ['fL-b760btOaGa85OJ9ut3w', '1DhrpTWJygfaPrYkHNH1xuz-HxWZBZe__',\n",
        "             '1Vm5kyWMQQCSMBLSGpDwVfHIR4bp5-JIt', '19bUEYHBUGKxt7DjStk0qJIlqq4NKslw8',\n",
        "             '','','','','']\n",
        "  \n",
        "if row_number > df.index.max()+1: \n",
        "  print(\"Invalid row_number\") \n",
        "else:\n",
        "  df = Insert_row(row_number, df, row_value) \n",
        "  print(df[row_number-1:])\n",
        "\n",
        "gtree = drop_unnamed(df)\n",
        "gtree.to_csv('gtree.csv')\n",
        "upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzJX2f82v1e_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "##################### INSERT ROWS AT BEGIN IN GTREE ############################\n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "gtree = pd.read_csv('gtree.csv')\n",
        "\n",
        "values = [['WbJ1LRQdOuYYlRLyTkuuxw','1DFANWg2Io81FaV_GxlwBWfpG9Bx-Dgr7','1U0Ml5puObfOk3qHCKhO9bQ06WyhJoffW','1Ba-IYi1icz5tuO_AYN-f-FvjXjA5NmJi','','','','19r7YGFp7oAqItv63TZOPyAt4hDa_UyRr',''],\n",
        "          ['T2tEMLpTeSMxLKpxwFdS3g','1ENW6Pyiyt7v6p54Uhn9zrM9HQ28MB1-G','136FZ0Y90Zx-4UYDyW50cX8zUa_DhN3XS','1wAgWQ6Vmy3fe-RJ8_Ezwow75ftvOFP5_','','','','1f1NhSvHMwyJOxIrGbDix1lQ5NN4eHoG4',''],\n",
        "          ['ALwAlxItASeEs2vYAeLXHA','1oEws_0F-s4hS6CpBxqxuzoJ2Wo-Nf8eL','12zXi3XyQaNgukGHW_805cyrkHhSdF7Df','1lZKqsV-sTAEOnLv-MQxpdao7eBWkjKP1','','','','1mWA3-mH9Kl0Xho24he8__4nZJBVPx9Qh',''],\n",
        "          ['OVTZNSkSfbl3gVB9XQIJfw','1hgql_Ey5epZKj-SuB4F5Fu1eYOd2P8RX','1ZyNQavpG0akr3ca3PJjjl_D89IA5wlcc','1-drKKIaitJ0tjEY1W80B3kRXI5Ive5lC','','','','1OqlKSXZUvZCOOmTAONENS9Sq0twMCRM8',''],\n",
        "          ['Sovgwq-E-n6wLqNh3X_rXg','10fJv8tOFOwBiAZBVEedsqxi3g6zYLxjD','1EZqvt9x5PN07BgUad1RtNIUXTVqujA0g','1QcSsJsvQne8a9jMvL9_1VAmeGIrsq8R8','','','','1ArjfNsamdhSpG7BJwnJZ_qULh_aklp62',''],\n",
        "          ['j5nPiTwWEFr-VsePew7Sjg','1yRDL_lrQFsCijdyvDssRgdZ5a2wyjCXj','18bQVXYZ03vIpfEFLPh8I2i7cPTlokGxv','1VysI0VkliBEU8Y1sCX0PU9eKYE6GaCzC','','','','1KW9VPvY33rbkgPfzrREpxMfSQJg4xxoL',''],\n",
        "          ['aiX_WP7NKPTdF9CfI-M-wg','1lQu_nXTCrzMFOm3uuXmCNVzx0PmYv0Of','1nl6A997UnuR5ceYRZS1242JJCvK-Sf_u','12Z4PEBlcTkz6kjeJ0JYRKI3WCrjRi4bF','','','','11H38dweaCKJ4-TD88nuzV70lMF5n4yzG',''],\n",
        "          ['e4NQLZynhSmvwl38hC4m-A','1f3bGHoK6Hy44pKRqSsnhN8KM-W3AAChW','1K566Y5Q2N6Lw7S6yDicKC_R-zFVRqnFr','1reeSQL8MfkxOQg-NsVxazVdKfG1XNPEF','','','','1fVLmOBbg44H8q_UcwAOQiX6CeN6hf84Z',''],\n",
        "          ['S-oLPRdhlyL5HAknBKTUcQ','1bG_50_Yyh9vq7YDQ3zSNTqS4acm1Cs7x','1FJqfJgaJinXS3oIvdA53FMuO9O7bCDVn','17QEFZUC_rhrLk9mSDXoegq7TSCI2_JLS','','','','1CMUT4RhSeuPi0j4VGoLCe-iP9-Aj5Fsy','']]\n",
        "          \n",
        "df1=pd.DataFrame(values, columns=['business_id', 'gfolder_id', 'gfolder_rankings', \n",
        "                              'gfolder_groups', 'gfolder_#11', 'gfolder_#12',\n",
        "                              'gfolder_#14','gfolder_userphoto','gfolder_clarifai'])\n",
        "df2=gtree\n",
        "\n",
        "df3 = pd.concat([df1, df2]).reset_index(drop=True)\n",
        "df3 = drop_unnamed(df3)\n",
        "print(df3)\n",
        "df3.to_csv('gtree.csv')\n",
        "gtree = drop_unnamed(gtree)\n",
        "print(gtree)\n",
        "upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_T7KPQkFat3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "##################### ADD AND REORDER COLUMNS IN GTREE #########################\n",
        "\n",
        "download = drive.CreateFile({'id': '1MIWS9uI9GKxsgAlzB0wXFBiutE025u2c'}) # id file gtree.csv\n",
        "download.GetContentFile('gtree.csv')\n",
        "gtree = pd.read_csv('gtree.csv')\n",
        "\n",
        "gtree['#restaurant'] = gtree.index + 1\n",
        "cols = gtree.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "gtree = gtree[cols]\n",
        "\n",
        "gtree = drop_unnamed(gtree)\n",
        "print(gtree)\n",
        "upload_file('gtree.csv', '1eUt2wyCOULW0-LdL6vyRJi1mUs_U46DD') # id folder data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}